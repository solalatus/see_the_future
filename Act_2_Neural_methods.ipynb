{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological motivation (recapitulation)\n",
    "\n",
    "### Representation\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1tedMjIowYM8Y68C8fRrZJ2JRsFRQx1P5\"><img src=\"https://drive.google.com/uc?export=view&id=1nF5EfVhgia0Zzpm5woRlBJ-KXSthV9e9\"></a>\n",
    "\n",
    "### Thresholding\n",
    "\n",
    "- Neurons do not \"fire\" continuously\n",
    "- Their activation has to be modeled with some kind of a step function\n",
    "\n",
    "<a href=\"http://www.saedsayad.com/images/ANN_Unit_step.png\"><img src=\"https://drive.google.com/uc?export=view&id=1XDNopwwsVTCLnC4ioN8tv1xbfLYlF9-e\"></a>\n",
    "\n",
    "Simplest \"nonlinearity\" - later we will encounter a plethora of others\n",
    "\n",
    "<a href=\"http://slideplayer.com/slide/5214241/16/images/5/Perceptron:+Linear+threshold+unit.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1Da8YDVCuy4wDyrLTBEcCySn8qBdOs3Yx\" width=55%></a>\n",
    "\n",
    "**Tricky notation**\n",
    "\n",
    "- $x_{1..n}$ are the input values, \"input activations\"\n",
    "- $x_{0}$ is also present! -- This is the  \"bias unit\", or \"bias term\"\n",
    "<a href=\"https://raw.githubusercontent.com/qingkaikong/blog/master/39_ANN_part2_step_by_step/figures/figure1_perceptron_structure.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1fGwrmYGp8D6mwI1ZgbVb5R33IqLS1P2z\" width=45%></a>\n",
    "- Shouldn't be confused with concept of \"bias\" met when discussing overfitting, although  semantics is similar: a general \"prejudice\" which determines the behavior of the system\n",
    "\n",
    "### \"Biological inspiration\"\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1D75C1LThbDYqs4gYUz5kC8cZJprQHBPB\"><img src=\"https://drive.google.com/uc?export=view&id=1EQa7ODziQoOVoLi1nZZ2yyJfOxBgrqr8\" width=55%></a>\n",
    "\n",
    "\n",
    "[source](https://www.facebook.com/photo.php?fbid=2063218160389423&set=gm.2075284019202050&type=3&theater)\n",
    "\n",
    "## Capable of modeling logical operations\n",
    "- Logic considered pinnacle of cognitive activities\n",
    "- \"It can learn, it models logic, what else would be needed?\"\n",
    "- Perceptron's problems with modeling certain logical functions had huge effect in history of AI. \n",
    "\n",
    "##  Artificial neuron -- mathematical model\n",
    "\n",
    "(the mathematical discussion follows mainly that of [Hal Daumé III](http://ciml.info/dl/v0_99/ciml-v0_99-ch04.pdf))\n",
    "\n",
    "### Earliest activation function\n",
    "\n",
    "with \n",
    "- $\\mathbf x = \\langle x_1,...,x_D \\rangle $ incoming activations, \n",
    "- $\\mathbf w = \\langle w_1,...,w_D \\rangle$ weights, and\n",
    "- $b$ bias\n",
    "\n",
    "the outgoing activation is\n",
    "\n",
    "$a(x_1,...,x_D) = \\sum_{d=1}^D w_d x_d +b$ where\n",
    "\n",
    "If $a(\\mathbf{x}) \\geq 0$ then the input is classified as a positive if $a(\\mathbf{x}) < 0$ then as a negative instance.\n",
    " \n",
    "\n",
    "## Later Sigmoid \"nonlinearity\"\n",
    "\n",
    "- An early idea\n",
    "- Firstly the role was played by the\n",
    "\n",
    "** Sigmoid (logistic) function**\n",
    "\n",
    "$${\\displaystyle S(x)={\\frac {1}{1+e^{-x}}}={\\frac {e^{x}}{e^{x}+1}}.}$$\n",
    "\n",
    "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/600px-Logistic-curve.svg.png\"><img src=\"https://drive.google.com/uc?export=view&id=17iKxq3jA3ZTBt5PX7HSjg6bHXQswmPam\" width=400 heighth=400></a>\n",
    "\n",
    "\n",
    "__And many, MANY more...__\n",
    "\n",
    "\n",
    "\n",
    "## For anything interesting: we need more layers! \n",
    "\n",
    "<a href=\"http://slideplayer.com/slide/778829/3/images/5/Minsky+&+Papert+(1969)+offered+solution+to+XOR+problem+by.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=10nkEXJlBBCV3Wj-24ywMKCaMy0TJu46e\" width=55%></a>\n",
    "\n",
    "### How does it look in practice?\n",
    "\n",
    "<a href=\"http://scikit-learn.org/stable/_images/multilayerperceptron_network.png\"><img src=\"https://drive.google.com/uc?export=view&id=1zKuJIjW-3lcySUNB4gIJqwCETctQBhij\" width=45%></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning method for deep architectures: Backpropagation\n",
    "\n",
    "Parameter optimization with Gradient Descent requires at every step of the process the calculation of\n",
    "+ The loss: value of  $L$ loss function on the training data set $D=\\{d_1,\\dots,d_N\\}$ with actual parameters $\\theta$: $$L_D(\\theta)$$\n",
    "+ The gradient of the loss with respect to a change for the actual parameters:\n",
    "$$\\frac{\\partial L_D(\\theta)}{\\partial \\theta}.$$\n",
    "\n",
    "Since the loss is typically the average of losses on the examples of the dataset, both calculation tasks can be reformulated in terms of the loss and gradient on individual examples:\n",
    "\n",
    "$$L_D(\\theta) = \\frac{1}{N}\\sum_d L_d(\\theta)$$\n",
    "\n",
    " $$\\frac{\\partial L_D(\\theta)}{\\partial \\theta}=\\frac{1}{N}\\sum_d\\frac{\\partial L_d(\\theta)}{\\partial \\theta}$$\n",
    "\n",
    "Note: the derivation task is NOT symbolic: we are not interested in derivative of $L$ in general (e.g. as a symbolic formula) but only its numerical value for the actual parameters.\n",
    "\n",
    "Key for the solution is that we can build a circuit-like _computational graph_ for the loss:\n",
    "- Parameters and training data are inputs entering at the leaves \n",
    "- Nodes are simple(r) _mathematical operations_ that act as gates transforming their numeric inputs to outputs\n",
    "- Mathematical operations in question typically (at least piecemeal) differentiable functions of inputs\n",
    "\n",
    "### A toy example\n",
    "\n",
    "Regression task with training data  $\\langle  x_1,y_1\\rangle, \\dots,\\langle x_N,y_N\\rangle$ using the \"network\"\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1xbYaI7j7AcBFvOyI80XJAlWmkeuxOCfH\"><img src=\"https://drive.google.com/uc?export=view&id=13tf4kpvfugbotPbpz-TEqN7h4ltehuRM\" width=\"150\"></a>\n",
    "\n",
    "which computes \n",
    "\n",
    "$$\\hat{y} = w\\cdot x  + b$$\n",
    "\n",
    "as a prediction for an $x$ input. Using squared loss, loss for a single $d=\\langle x, y\\rangle$ example:\n",
    "\n",
    "$$L_d(\\langle w, b \\rangle) = (\\hat y -y)^2 = (wx + b - y)^2\n",
    "$$\n",
    "corresponding computational graph can be \n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1517qyzShAbQ5flRIVXErIxmwI1GFwmDS\"><img src=\"https://drive.google.com/uc?export=view&id=1WtXYNEB2POwCf1H-gKE3c_S3pjFAz6dK\" width=\"500\"></a>\n",
    "\n",
    "### Forward pass\n",
    "\n",
    "Assume current parameter values are $w = 3$ and $b = 2$, and the current example is $x = 4, y = 5$. To calculate loss on this training example, have to calculate final output of graph by calculating output of all internal operation nodes/gates as values flow from left to right:\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1YRkPfxLl8vkaKANFz0yoxhv-jmY2fPrD\"><img src=\"https://drive.google.com/uc?export=view&id=14L2R6GqPme-P2gJbvPTedGkKZz-4c4xq\" width=\"500px\"></a>\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "%matplotlib inline\n",
    "\n",
    "x = 4; y = 5; w = 3; b = 2\n",
    "prod = x * w\n",
    "y_hat  = prod + b\n",
    "error = y_hat - y\n",
    "loss = error ** 2\n",
    "print(f\"The loss for w={w}, b={b}, x={x} and y={y} is {loss}.\")\n",
    "\n",
    "And that is all for the __forward pass__ on our computational graph.\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "Having calculated the value of the loss function for the current example, our next task is to compute the gradient of the parameters:\n",
    "\n",
    "$$\\frac{\\partial L_d(\\theta)}{\\partial \\theta}= \\left\\langle \\frac{\\partial L_d(w)}{\\partial w}, \\frac{\\partial L_d(b)}{\\partial b}\\right\\rangle\n",
    "$$\n",
    "\n",
    "for which we have to calculate the partial derivative of the loss with respect to $w$ and $b$. Somewhat surprisingly, in this case we can work backwards, from right to left by computing partial derivatives with respect to the operation outputs until we reach the partial derivatives of $L$ we are interested in, with respect to $w$ and $b$. (This is the so called \"backpropagation of error\" [although \"backpropagation of loss\" would be more precise on our case]).\n",
    "\n",
    "The mathematical ground for doing so is the **chain rule** for derivatives, according to which\n",
    "\n",
    "$$\n",
    "\\frac{\\partial F}{\\partial \\alpha} = \\frac{\\partial F}{\\partial \\beta} \\cdot \\frac{\\partial \\beta}{\\partial \\alpha}\n",
    "$$\n",
    "which, for our purposes, means that we can calculate the derivative of the loss with respect to any value $\\alpha$ in the computational graph which is the input of an $f$ operation with the $\\beta$ output simply as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\alpha} = \\frac{\\partial L}{\\partial \\beta} \\cdot \\frac{\\partial \\beta}{\\partial \\alpha} = \n",
    "\\frac{\\partial L}{\\partial \\beta} \\cdot \\frac{\\partial f(\\alpha)}{\\partial \\alpha}\n",
    "$$\n",
    "\n",
    "To do that, we need to know the derivative of the operations in the graph, which are, fortunately, very simple:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial x^2}{\\partial x} = 2x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (x - y)}{\\partial x} = 1, \\frac{\\partial (x - y)}{\\partial y} = -1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (x + y)}{\\partial x} = 1, \\frac{\\partial (x + y)}{\\partial y} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (x \\cdot y)}{\\partial x} = y, \\frac{\\partial (x \\cdot y)}{\\partial y} = x\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Using these derivatives and applying the chain rule step by step the loss derivatives can be calculated as\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1johrny_RNeV14iatNruZ0h_jXhb6kCyj\"><img src=\"https://drive.google.com/uc?export=view&id=1DQA9Y9rVkJEh2EdqKzaBwTazf4fNtg_n\" width=\"500px\"></a>\n",
    "\n",
    "d_error = 2 * error # for the first operation node we can directly calculate the derivative\n",
    "d_y_hat = d_error * 1\n",
    "d_b = d_y_hat * 1\n",
    "print(f\"d_b is {d_b}\")\n",
    "d_prod = d_y_hat * 1\n",
    "d_w = d_prod * x\n",
    "print(f\"d_w is {d_w}\")\n",
    "\n",
    "### Update on the basis of this single data point\n",
    "\n",
    "As our  current $\\langle w, b\\rangle$ parameter vector is $\\langle 3, 2 \\rangle$ and, according to our calculation, the gradient for this data point is $\\langle \\frac{\\delta L}{\\delta w}, \\frac{\\delta L}{\\delta b} \\rangle = \\langle 72, 18\\rangle$, with a learning rate of $\\frac{1}{18}$ (for simplicity) our updated parameter vector for this single data point would be\n",
    "$$\\langle w, b\\rangle - \\eta \\left\\langle \\frac{\\delta L}{\\delta w},\\frac{\\delta L}{\\delta b}\\right\\rangle = \\langle 3, 2\\rangle - \\langle 4, 1\\rangle = \\langle -1, 1\\rangle,$$\n",
    "\n",
    "for which the loss on this example is 64, which is indeed less then the previous 81 loss value. __Of course, in reality we typically make updates on the basis of more the one data point!__ (More about this later.)\n",
    "\n",
    "### Generalization\n",
    "- Method of computing loss and its gradient with recursive forward pass and backpropagation on a computational graph with simpler differentiable operations as nodes can be used to efficiently implement Gradient Descent for feed-forward neural networks in general. \n",
    "- All modern neural network frameworks use variants of this approach to implement gradient decent. \n",
    "- Important difference to our toy example is that \"real life\" computational graphs for neural networks mostly contain operations with higher dimensional (vector/matrix/tensor) arguments\n",
    "- Frameworks have to provide efficient implementations of the derivatives of these operations, e.g., that of matrix multiplication. \n",
    "\n",
    "Simple example of a __vectorized__ computational graph, consider the following network with a hidden layer:\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1F4TOpCCuRKh8Bvh7FJRKEXq7Ex-OS2Nr\"><img src=\"https://drive.google.com/uc?export=view&id=1K-Urkrl53Mznto7kiB8ojzU2hR-jt8l5\" width=\"350px\"></a>\n",
    "\n",
    "\n",
    "Mathematically, if the hidden layer's weights are $\\mathbf W = \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23}\\end{bmatrix}$, its biases are  $\\mathbf {b}^h = \\begin{bmatrix}b^h_1 \\\\ b^h_2 \\end{bmatrix}$, the output layer's weights are $\\mathbf v =\\begin{bmatrix}v_1 & v_2\\end{bmatrix}$ and its bias is $b$ then the network's output for an $\\mathbf x = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{bmatrix}$ input is \n",
    "\n",
    "$$ \\hat y = \\begin{bmatrix}v_1 & v_2\\end{bmatrix}\\cdot \\sigma \\left ( \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23}\\end{bmatrix} \\cdot \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{bmatrix} + \\begin{bmatrix}b^h_1 \\\\ b^h_2 \\end{bmatrix}\\right ) + b = \\mathbf v \\cdot \\sigma(\\mathbf W\\cdot \\mathbf x  + \\mathbf {b}^h) + b $$\n",
    "\n",
    "Accordingly, the corresponding computational graph in terms of matrices and vectors is along the lines of \n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1HO9C0srDTZTT6ZYAQmCRhLj89yFwd03d\"><img src=\"https://drive.google.com/uc?export=view&id=1aXG2XhMFOtolJVjxBRmUpW_SIiGuDH_N\" width=\"500px\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GRegsIRVgdJ"
   },
   "source": [
    "## A \"workhorse\" learning method -- Gradient descent\n",
    "<a href=\"https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_animation.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1IVQBJxq8tf0vsMWw9vVI_PutXJ0J5aL3\"></a>\n",
    "\n",
    "The Gradient Descent algorithm takes a small step in right direction taking into consideration all examples of the training data, so it moves toward the minimum in the error space.\n",
    "\n",
    "## Gradient Descent algorithm\n",
    "If the function to be minimized is the differentiable $F:\\mathbb R^n\\rightarrow \\mathbb R$,  $\\eta _n$ is a series of learning rates and  $K$ is the number of steps then the algorithm is\n",
    "\n",
    "1. $\\mathbf p_0 :=  \\mathbf p_{\\mathrm init}$ (initial parameters  [for neural nets these are the weights and biases]):\n",
    "2. for k $\\in [1..K]$:\n",
    "    - $\\mathbf g_k :=\\Delta F(\\mathbf p_{k-1})$ (compute the value of the derivative for the actual parameters)            \n",
    "    - $\\mathbf p_k := \\mathbf p_{k-1} - \\eta_k \\mathbf g_k$ (take a step in the direction of the gradient)\n",
    "3. The result is $\\mathbf p_K$.\n",
    "\n",
    "<a href=\"https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_gradient_descent_1.png\"><img src=\"https://drive.google.com/uc?export=view&id=16Ejy98onOnUqHZ6PbuK8Ewp_6_b7PwP6\"></a>\n",
    "\n",
    "### Convergence\n",
    "\n",
    "Under certain conditions (among others, $F$ has to be convex)  the series generated by the algorithm is guaranteed to converge to the minimum: the $\\eta_n$ series can be chosen to be a constant series such that the convergence rate is $\\mathcal O(1/k)$, that is,  if $F$ reaches its minimum at $\\mathbf p^*$ then there is an $\\alpha$ constant for which for any $k$, $F(\\mathbf{p}_k)-F(\\mathbf{p}^*)\\leq \\frac{\\alpha}{k}$.\n",
    "\n",
    "### Too small and too large learning rates\n",
    "\n",
    "<a href=\"https://cdn-images-1.medium.com/max/1600/1*EP8stDFdu_OxZFGimCZRtQ.jpeg\"><img src=\"https://drive.google.com/uc?export=view&id=1e0NZxneJuJyT6CRVDW7gmjZ7sLzpDW28\" width=\"600\"></a>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAy-KLGKVgdO"
   },
   "source": [
    "## Universal approximation theorem (Cybenko, 1989)\n",
    "\n",
    "Let $F$ be a continuous function on a closed and bounded subset of $\\mathbb R^n$ and $\\sigma$ any sigmoid-like function, that is, $\\sigma:\\mathbb R\\rightarrow\\mathbb R$, continuous and $\\lim_{x \\to -\\infty} \\sigma(x) = 0$ and $\\lim_{x \\to \\infty} \\sigma(x) = 1$. Then for any $\\epsilon>0$ there exists a $\\hat{f}$ finite neural network with a single hidden layer whose activation function is $\\sigma$  and which is closer to $f$ than $\\epsilon$, that is,\n",
    "\n",
    "$$\\forall \\mathbf x \\in \\mathrm{Dom}(f): \\left|~f(\\mathbf x) - \\hat{f}(\\mathbf x)\\right|< \\epsilon$$\n",
    "\n",
    "Original paper: [here](https://www.dartmouth.edu/~gvc/Cybenko_MCSS.pdf). Somewhat clearer version of the original proof: [here](http://mcneela.github.io/machine_learning/2017/03/21/Universal-Approximation-Theorem.html).\n",
    "\n",
    "Illustration:\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1xIKYRXMchV6B6C9WmhwK0qCENbkIYGiv\"><img src=\"https://drive.google.com/uc?export=view&id=1OeKexw1HCSLxrMqubc3ruOtwnHmtXo5K\" style=\"width: 45%;\"></a>\n",
    "\n",
    "[Source](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2647&rep=rep1&type=pdf)\n",
    "\n",
    "\n",
    "### Some generalizations\n",
    "\n",
    "- Hornik, 1990: The theorem also holds for continuous, bounded and not constant activation functions [here](http://zmjones.com/static/statistical-learning/hornik-nn-1991.pdf)\n",
    "\n",
    "- Leshno et al, 1993: It is enough to require piecewise continuity and so called local boundedness if the function is not polynomial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2B0tCZqR1I8"
   },
   "source": [
    "### Intuitive explanation\n",
    "\n",
    "Intuitive explanation of the theorem can be found in [Chapter 4 of Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap4.html): it demonstrates how function approximations can be put together from basic blocks of linear functions and sigmoid-like nonlinearities.\n",
    "\n",
    "A very nice visual introduction can be found [here](https://towardsdatascience.com/representation-power-of-neural-networks-8e99a383586).\n",
    "\n",
    "<a href=\"https://miro.medium.com/max/536/1*WpLFxIZ9qllHlJu-_1qRuA.png\"><img src=\"https://drive.google.com/uc?export=view&id=1p5d0NROelGS47awGli5__mfs0esAM2bq\"></a>\n",
    "\n",
    "If we generalize this visualization to more dimensions, we can see the compositional structure of the decision boundaries in case of deep networks, thus we can understand how they can create arbitrarily complex decision boundaries.\n",
    "<a href=\"https://miro.medium.com/max/531/1*Lf9gGY5sTEps6jvSVQR_Nw.png\"><img src=\"https://drive.google.com/uc?export=view&id=1hXYl_M3Wub5MLNDx0W04QzLHSU88HkVa\"></a>\n",
    "\n",
    "<a href=\"https://miro.medium.com/max/1017/1*xUGfnzOlmOLyIILnTSBorQ.png\"><img src=\"https://drive.google.com/uc?export=view&id=1hUyUZB8gN1LC3pRkPU4RwPNvonJ0UDex\"></a>\n",
    "\n",
    "This image might be familiar from the ensemble methods, but the self learning and hierarchical nature is quite new!\n",
    "\n",
    "\n",
    "In essence this is why neural networks represent a more expressive model class then say ensamble of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short: __The motivation for using neural networks is, that they are extremely flexible, capable of modely complex functions by end-to-end learning.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can neural networks be used for time series modeling?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But why?\n",
    "\n",
    "There can be several reasons for using neural models for time series prediction:\n",
    "- We assume, that beside the trend and periodic signals there are other patterns that we could try to extract and use (think about the \"residuals\" in case of decomposition)\n",
    "- We don't want to do manual feature engineering, looking for wavelets, etc. we are more into end-to-end learning\n",
    "- There is a Hungarian proverb: \"Whoever has a hammer, sees nails everywhere.\" :-P\n",
    "\n",
    "## First step: Feedforward networks for time series\n",
    "\n",
    "Let us get back to the Airline Passengers dataset from the Time Series class for illustration.\n",
    "\n",
    "**Source: [Monthly Airline Passenger Numbers (in thousands) 1949-1960](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/AirPassengers.html)**\n",
    "\n",
    "(Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control. \n",
    "Third Edition. Holden-Day. Series G.)\n",
    "\n",
    "\n",
    "Direct  link [here](https://www.analyticsvidhya.com/wp-content/uploads/2016/02/AirPassengers.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.215163Z",
     "start_time": "2020-05-27T17:04:59.270016Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import blaze as bz\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.749438Z",
     "start_time": "2020-05-27T17:05:01.216160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-27 19:05:01--  https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/AirPassengers.csv?inline=false\n",
      "Resolving gitlab.com (gitlab.com)... 172.65.251.78\n",
      "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1746 (1.7K) [text/plain]\n",
      "Saving to: ‘AirPassengers.csv’\n",
      "\n",
      "AirPassengers.csv   100%[===================>]   1.71K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-05-27 19:05:01 (52.4 MB/s) - ‘AirPassengers.csv’ saved [1746/1746]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/AirPassengers.csv?inline=false -O AirPassengers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.755631Z",
     "start_time": "2020-05-27T17:05:01.750777Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AirPassengers.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.876904Z",
     "start_time": "2020-05-27T17:05:01.756866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"#Passengers\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "If we would like to work with a feedforward network, we have to make the data acceptable for a model with a fixed input width (in this case \"length\", in time).\n",
    "\n",
    "The most widespread solution for this is to use a *\"sliding window\"*, where we transform the data so as to create for each time point (considered as $y$) a fixed $x$ - with `window_size`, so we get a dataframe with row number: timesteps minus window size and columns and window size columns as $x$, and a vector with timsteps minus window size length as $y$ value.\n",
    "\n",
    "|   Step     | Variable | Dimension  |  Variable | Dimension |\n",
    "|:------------- |:------------| :----- |:-------------|:-----|\n",
    "|**in**| df|**[data_length, 1]**|window_size| **[scalar]**|\n",
    "|**out**| x|**[data_length-window_size, window_size]** |y| **[data_length-window_size, 1]** |\n",
    "\n",
    "In this case we use a sliding window of 10, though 13-14 could also be interesting (if we think back to the PACF analysis of this data). The majority of \"signal\" is persumed to lie inside the ~10 months range.\n",
    "\n",
    "We will fit a tiny two layered NN on the data with L1 regularization and Adamm optimizer.\n",
    "\n",
    "\n",
    "|   Paremeter     | Value | \n",
    "|:------------- |:------------| \n",
    "|n_hidden_1 | 17 |\n",
    "| n_hidden_2 | 9 |\n",
    "| n_input | 10 (window_size) | \n",
    "|training_epochs | 100000|\n",
    "|Optimizer| Adamm|\n",
    "|learning_rate | 0.01|\n",
    "|Regularizer| L1|\n",
    "| l1_lambda |0.00015|\n",
    "\n",
    "\n",
    "### Let's see the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.882364Z",
     "start_time": "2020-05-27T17:05:01.877850Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Shameless copy of https://stackoverflow.com/questions/27852343/split-python-sequence-time-series-array-into-subsequences-with-overlap \n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "\n",
    "rolled_data = rolling_window(df[\"#Passengers\"].values, window_size+1)\n",
    "\n",
    "rolled_train_data, rolled_test_data = train_test_split(rolled_data, test_size=0.1, shuffle=False)\n",
    "\n",
    "rolled_train_y = rolled_train_data[:,window_size]\n",
    "rolled_train_x = rolled_train_data[:,:window_size]\n",
    "\n",
    "rolled_test_y = rolled_test_data[:,window_size]\n",
    "rolled_test_x = rolled_test_data[:,:window_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us ensure that the dimensions are ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.885858Z",
     "start_time": "2020-05-27T17:05:01.883343Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 10)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "print(rolled_test_x.shape)\n",
    "print(rolled_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:01.889530Z",
     "start_time": "2020-05-27T17:05:01.886819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolled_train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:41.751973Z",
     "start_time": "2020-05-27T17:05:01.891005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/1000\n",
      "120/120 [==============================] - 1s 6ms/sample - loss: 25784.4331 - val_loss: 26385.9785\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 10199.4309 - val_loss: 16384.2656\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 3130.4589 - val_loss: 8991.1777\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 3693.1771 - val_loss: 7528.3525\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 2447.6011 - val_loss: 8710.8730\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 2453.5271 - val_loss: 10319.1572\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 2343.5764 - val_loss: 5730.9277\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 1744.3307 - val_loss: 5015.1504\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 1565.1799 - val_loss: 5080.2949\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 1450.0882 - val_loss: 3995.7085\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1509.9735 - val_loss: 3818.0293\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 1255.3925 - val_loss: 3427.4622\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 1256.5451 - val_loss: 3288.1609\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 1056.9182 - val_loss: 2913.7417\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 1092.5041 - val_loss: 3016.1301\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 1037.3021 - val_loss: 2534.8564\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 908.5866 - val_loss: 2466.7549\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 883.1169 - val_loss: 2219.2268\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 796.0678 - val_loss: 2008.4379\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 729.6139 - val_loss: 1872.4122\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 745.6546 - val_loss: 1898.9575\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 739.8094 - val_loss: 1590.9572\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 696.7218 - val_loss: 1723.6635\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 738.2404 - val_loss: 2512.7310\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 878.1489 - val_loss: 1569.1692\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 575.8291 - val_loss: 1478.4587\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 600.9160 - val_loss: 1564.7147\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 582.4885 - val_loss: 1414.7506\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 562.5160 - val_loss: 1433.8577\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 544.6472 - val_loss: 1534.2306\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 569.1562 - val_loss: 1602.8395\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 587.2889 - val_loss: 1391.9146\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 603.9431 - val_loss: 1463.5653\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 627.0407 - val_loss: 1316.6808\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 326us/sample - loss: 633.6238 - val_loss: 1400.5490\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 541.8558 - val_loss: 1672.3414\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 571.0465 - val_loss: 1593.3107\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 715.6935 - val_loss: 1358.9182\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 634.1581 - val_loss: 1736.5828\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 728.7748 - val_loss: 1844.3243\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 654.0240 - val_loss: 1602.7169\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 602.6611 - val_loss: 1323.8729\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 582.7853 - val_loss: 1351.2424\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 575.6995 - val_loss: 1672.3669\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 635.3976 - val_loss: 1675.6974\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 561.1643 - val_loss: 1535.8702\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 610.8415 - val_loss: 1610.0770\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 583.8277 - val_loss: 1389.2140\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 616.5687 - val_loss: 1438.9252\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 578.9086 - val_loss: 1731.6145\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 660.2891 - val_loss: 1888.0850\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 630.5852 - val_loss: 1403.7051\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 477us/sample - loss: 551.7740 - val_loss: 1320.3542\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 714us/sample - loss: 559.3099 - val_loss: 1298.9924\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 630us/sample - loss: 584.5039 - val_loss: 1307.5594\n",
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 572.3870 - val_loss: 1390.4108\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 619us/sample - loss: 557.1158 - val_loss: 1347.2975\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 562.2831 - val_loss: 1312.0309\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 590.0877 - val_loss: 1432.0453\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 666.7817 - val_loss: 1933.4738\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 366us/sample - loss: 714.8300 - val_loss: 1700.2682\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 627.8828 - val_loss: 1346.3292\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 871.3811 - val_loss: 1981.3378\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 749.3773 - val_loss: 1620.9564\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 643.4409 - val_loss: 1478.8928\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 689.4052 - val_loss: 1353.8898\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 653.4704 - val_loss: 1498.1443\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 565.7825 - val_loss: 1370.9180\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 538.5715 - val_loss: 1515.2732\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 560.2032 - val_loss: 1601.0206\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 715.5412 - val_loss: 1918.8219\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 579.5686 - val_loss: 1693.2971\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 599.3125 - val_loss: 1418.4963\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 573.0974 - val_loss: 1297.3224\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 609.7577 - val_loss: 1621.0990\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 668.1922 - val_loss: 1933.7225\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 663.5920 - val_loss: 2082.7588\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 675.2712 - val_loss: 1653.1553\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 361us/sample - loss: 722.3341 - val_loss: 1309.9738\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 471us/sample - loss: 582.3028 - val_loss: 1319.2618\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 546.9330 - val_loss: 1401.1089\n",
      "Epoch 82/1000\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 624.1496 - val_loss: 1496.6921\n",
      "Epoch 83/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 616.1744 - val_loss: 1351.9437\n",
      "Epoch 84/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 525.4558 - val_loss: 1291.4541\n",
      "Epoch 85/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 535.4658 - val_loss: 1275.7966\n",
      "Epoch 86/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 517.2478 - val_loss: 1361.1270\n",
      "Epoch 87/1000\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 542.3038 - val_loss: 1346.1006\n",
      "Epoch 88/1000\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 524.4874 - val_loss: 1246.3816\n",
      "Epoch 89/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 590.8072 - val_loss: 1531.0178\n",
      "Epoch 90/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 592.3239 - val_loss: 1277.3113\n",
      "Epoch 91/1000\n",
      "120/120 [==============================] - 0s 335us/sample - loss: 580.6034 - val_loss: 1428.4132\n",
      "Epoch 92/1000\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 678.3772 - val_loss: 1848.6936\n",
      "Epoch 93/1000\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 638.1030 - val_loss: 2338.0244\n",
      "Epoch 94/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 586.5586 - val_loss: 2428.3516\n",
      "Epoch 95/1000\n",
      "120/120 [==============================] - 0s 421us/sample - loss: 849.4103 - val_loss: 1548.1074\n",
      "Epoch 96/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 541.6481 - val_loss: 1245.8625\n",
      "Epoch 97/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 582.8906 - val_loss: 1170.4039\n",
      "Epoch 98/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 498.8750 - val_loss: 1167.8788\n",
      "Epoch 99/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 471.4904 - val_loss: 1161.1976\n",
      "Epoch 100/1000\n",
      "120/120 [==============================] - 0s 460us/sample - loss: 488.4147 - val_loss: 1206.4994\n",
      "Epoch 101/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 502.4933 - val_loss: 1692.0387\n",
      "Epoch 102/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 597.0926 - val_loss: 2673.8652\n",
      "Epoch 103/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 856.6774 - val_loss: 3048.4932\n",
      "Epoch 104/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 830.6180 - val_loss: 1773.0012\n",
      "Epoch 105/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 557.9802 - val_loss: 1644.4750\n",
      "Epoch 106/1000\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 544.7425 - val_loss: 1192.6156\n",
      "Epoch 107/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 495.9217 - val_loss: 1180.6752\n",
      "Epoch 108/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 473.8982 - val_loss: 1053.8126\n",
      "Epoch 109/1000\n",
      "120/120 [==============================] - 0s 401us/sample - loss: 421.2110 - val_loss: 1154.9260\n",
      "Epoch 110/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 436.2967 - val_loss: 1110.4806\n",
      "Epoch 111/1000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 459.5598 - val_loss: 1203.4760\n",
      "Epoch 112/1000\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 435.6551 - val_loss: 1193.8718\n",
      "Epoch 113/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 436.3889 - val_loss: 1192.6134\n",
      "Epoch 114/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 499.6883 - val_loss: 1201.4156\n",
      "Epoch 115/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 460.1134 - val_loss: 1103.5911\n",
      "Epoch 116/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 469.1134 - val_loss: 1205.7000\n",
      "Epoch 117/1000\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 452.8425 - val_loss: 1154.5509\n",
      "Epoch 118/1000\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 458.7933 - val_loss: 1021.6754\n",
      "Epoch 119/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 476.7748 - val_loss: 1033.2346\n",
      "Epoch 120/1000\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 415.5349 - val_loss: 1196.7834\n",
      "Epoch 121/1000\n",
      "120/120 [==============================] - 0s 509us/sample - loss: 396.0844 - val_loss: 1008.6136\n",
      "Epoch 122/1000\n",
      "120/120 [==============================] - 0s 493us/sample - loss: 392.2270 - val_loss: 1034.0216\n",
      "Epoch 123/1000\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 428.1512 - val_loss: 1582.1147\n",
      "Epoch 124/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 481.2229 - val_loss: 1004.5228\n",
      "Epoch 125/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 379.4856 - val_loss: 1007.4662\n",
      "Epoch 126/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 362.9797 - val_loss: 1023.3697\n",
      "Epoch 127/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 409.9762 - val_loss: 1415.8827\n",
      "Epoch 128/1000\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 450.6137 - val_loss: 1671.0458\n",
      "Epoch 129/1000\n",
      "120/120 [==============================] - 0s 445us/sample - loss: 468.1280 - val_loss: 1005.8452\n",
      "Epoch 130/1000\n",
      "120/120 [==============================] - 0s 420us/sample - loss: 416.8579 - val_loss: 957.7543\n",
      "Epoch 131/1000\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 409.2370 - val_loss: 1013.4399\n",
      "Epoch 132/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 441.6422 - val_loss: 1796.2905\n",
      "Epoch 133/1000\n",
      "120/120 [==============================] - 0s 355us/sample - loss: 534.5466 - val_loss: 1336.7887\n",
      "Epoch 134/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 435.3194 - val_loss: 900.1502\n",
      "Epoch 135/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 452.8195 - val_loss: 922.9485\n",
      "Epoch 136/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 406.0580 - val_loss: 1324.6008\n",
      "Epoch 137/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 440.1140 - val_loss: 902.2523\n",
      "Epoch 138/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 460.7830 - val_loss: 929.2007\n",
      "Epoch 139/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 463.0993 - val_loss: 1006.5573\n",
      "Epoch 140/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 311.6301 - val_loss: 963.1212\n",
      "Epoch 141/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 408.3075 - val_loss: 893.3632\n",
      "Epoch 142/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 349.3179 - val_loss: 1252.3020\n",
      "Epoch 143/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 389.4765 - val_loss: 1766.6292\n",
      "Epoch 144/1000\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 597.4616 - val_loss: 1583.0110\n",
      "Epoch 145/1000\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 599.0405 - val_loss: 1173.7166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "120/120 [==============================] - 0s 429us/sample - loss: 446.9977 - val_loss: 1306.1223\n",
      "Epoch 147/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 468.7247 - val_loss: 1519.5399\n",
      "Epoch 148/1000\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 544.3190 - val_loss: 1161.0884\n",
      "Epoch 149/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 397.9895 - val_loss: 864.2380\n",
      "Epoch 150/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 387.2520 - val_loss: 1200.2792\n",
      "Epoch 151/1000\n",
      "120/120 [==============================] - 0s 404us/sample - loss: 437.2257 - val_loss: 1149.0376\n",
      "Epoch 152/1000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 389.8137 - val_loss: 1113.4187\n",
      "Epoch 153/1000\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 351.5315 - val_loss: 821.1898\n",
      "Epoch 154/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 370.6740 - val_loss: 790.0792\n",
      "Epoch 155/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 319.8082 - val_loss: 1090.6826\n",
      "Epoch 156/1000\n",
      "120/120 [==============================] - 0s 315us/sample - loss: 358.2348 - val_loss: 1403.9391\n",
      "Epoch 157/1000\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 345.7273 - val_loss: 1069.9468\n",
      "Epoch 158/1000\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 303.6477 - val_loss: 1054.7545\n",
      "Epoch 159/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 303.9879 - val_loss: 869.3099\n",
      "Epoch 160/1000\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 269.4771 - val_loss: 839.0430\n",
      "Epoch 161/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 271.1825 - val_loss: 900.4025\n",
      "Epoch 162/1000\n",
      "120/120 [==============================] - 0s 339us/sample - loss: 261.5063 - val_loss: 898.5906\n",
      "Epoch 163/1000\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 296.1825 - val_loss: 995.4840\n",
      "Epoch 164/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 341.8338 - val_loss: 839.4574\n",
      "Epoch 165/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 295.0413 - val_loss: 1017.7826\n",
      "Epoch 166/1000\n",
      "120/120 [==============================] - 0s 326us/sample - loss: 294.1824 - val_loss: 943.9753\n",
      "Epoch 167/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 319.9841 - val_loss: 818.3596\n",
      "Epoch 168/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 264.8675 - val_loss: 1103.8374\n",
      "Epoch 169/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 334.0480 - val_loss: 930.3405\n",
      "Epoch 170/1000\n",
      "120/120 [==============================] - 0s 367us/sample - loss: 299.5525 - val_loss: 904.5779\n",
      "Epoch 171/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 346.4992 - val_loss: 1356.6726\n",
      "Epoch 172/1000\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 318.1840 - val_loss: 1111.1813\n",
      "Epoch 173/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 322.4499 - val_loss: 798.8279\n",
      "Epoch 174/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 295.3821 - val_loss: 877.2284\n",
      "Epoch 175/1000\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 269.0974 - val_loss: 940.4271\n",
      "Epoch 176/1000\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 265.1218 - val_loss: 801.9546\n",
      "Epoch 177/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 261.8726 - val_loss: 814.3381\n",
      "Epoch 178/1000\n",
      "120/120 [==============================] - 0s 385us/sample - loss: 234.3967 - val_loss: 991.1042\n",
      "Epoch 179/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 256.5850 - val_loss: 876.2557\n",
      "Epoch 180/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 254.2694 - val_loss: 933.3238\n",
      "Epoch 181/1000\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 282.0190 - val_loss: 884.2616\n",
      "Epoch 182/1000\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 242.6878 - val_loss: 858.3206\n",
      "Epoch 183/1000\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 253.6164 - val_loss: 846.1091\n",
      "Epoch 184/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 241.8418 - val_loss: 902.5228\n",
      "Epoch 185/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 251.9768 - val_loss: 828.6340\n",
      "Epoch 186/1000\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 243.6078 - val_loss: 914.9182\n",
      "Epoch 187/1000\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 283.7611 - val_loss: 1169.9565\n",
      "Epoch 188/1000\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 322.2990 - val_loss: 750.7338\n",
      "Epoch 189/1000\n",
      "120/120 [==============================] - 0s 436us/sample - loss: 289.2905 - val_loss: 1002.7557\n",
      "Epoch 190/1000\n",
      "120/120 [==============================] - 0s 406us/sample - loss: 343.8378 - val_loss: 1319.0906\n",
      "Epoch 191/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 384.1258 - val_loss: 828.1794\n",
      "Epoch 192/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 422.9542 - val_loss: 1173.7955\n",
      "Epoch 193/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 401.6733 - val_loss: 1137.5278\n",
      "Epoch 194/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 349.7926 - val_loss: 1086.8418\n",
      "Epoch 195/1000\n",
      "120/120 [==============================] - 0s 340us/sample - loss: 449.0974 - val_loss: 1105.7828\n",
      "Epoch 196/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 348.1769 - val_loss: 830.1915\n",
      "Epoch 197/1000\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 371.4549 - val_loss: 1558.4529\n",
      "Epoch 198/1000\n",
      "120/120 [==============================] - 0s 329us/sample - loss: 361.3664 - val_loss: 1319.8516\n",
      "Epoch 199/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 486.7104 - val_loss: 871.6326\n",
      "Epoch 200/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 327.5643 - val_loss: 1045.3934\n",
      "Epoch 201/1000\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 296.7595 - val_loss: 993.9404\n",
      "Epoch 202/1000\n",
      "120/120 [==============================] - 0s 381us/sample - loss: 346.9599 - val_loss: 748.7592\n",
      "Epoch 203/1000\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 268.8476 - val_loss: 1030.8169\n",
      "Epoch 204/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 289.6442 - val_loss: 940.6201\n",
      "Epoch 205/1000\n",
      "120/120 [==============================] - 0s 666us/sample - loss: 252.3570 - val_loss: 1193.0040\n",
      "Epoch 206/1000\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 329.6187 - val_loss: 877.7921\n",
      "Epoch 207/1000\n",
      "120/120 [==============================] - 0s 450us/sample - loss: 305.7871 - val_loss: 909.2086\n",
      "Epoch 208/1000\n",
      "120/120 [==============================] - 0s 339us/sample - loss: 259.8461 - val_loss: 782.6404\n",
      "Epoch 209/1000\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 229.9035 - val_loss: 804.5176\n",
      "Epoch 210/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 234.6524 - val_loss: 865.8090\n",
      "Epoch 211/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 256.9066 - val_loss: 903.7612\n",
      "Epoch 212/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 288.4368 - val_loss: 820.4298\n",
      "Epoch 213/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 224.6227 - val_loss: 831.8178\n",
      "Epoch 214/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 248.8835 - val_loss: 735.6141\n",
      "Epoch 215/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 224.9092 - val_loss: 883.4551\n",
      "Epoch 216/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 233.0174 - val_loss: 748.7300\n",
      "Epoch 217/1000\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 227.0086 - val_loss: 748.2015\n",
      "Epoch 218/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 224.4477 - val_loss: 858.2863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 221.1657 - val_loss: 717.7272\n",
      "Epoch 220/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 226.0356 - val_loss: 799.3351\n",
      "Epoch 221/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 213.4909 - val_loss: 1130.2333\n",
      "Epoch 222/1000\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 263.7400 - val_loss: 692.4517\n",
      "Epoch 223/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 239.8597 - val_loss: 692.5461\n",
      "Epoch 224/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 212.7929 - val_loss: 902.8666\n",
      "Epoch 225/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 237.4021 - val_loss: 809.3901\n",
      "Epoch 226/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 226.2783 - val_loss: 701.0192\n",
      "Epoch 227/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 208.3114 - val_loss: 805.8009\n",
      "Epoch 228/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 236.6070 - val_loss: 883.0678\n",
      "Epoch 229/1000\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 229.9345 - val_loss: 680.1521\n",
      "Epoch 230/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 260.7887 - val_loss: 835.0384\n",
      "Epoch 231/1000\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 235.7012 - val_loss: 752.1417\n",
      "Epoch 232/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 194.7447 - val_loss: 707.7930\n",
      "Epoch 233/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 191.9390 - val_loss: 768.2809\n",
      "Epoch 234/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 213.2433 - val_loss: 691.8026\n",
      "Epoch 235/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 201.0248 - val_loss: 729.5953\n",
      "Epoch 236/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 203.0558 - val_loss: 746.4537\n",
      "Epoch 237/1000\n",
      "120/120 [==============================] - 0s 451us/sample - loss: 210.6798 - val_loss: 793.0588\n",
      "Epoch 238/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 217.9721 - val_loss: 699.7548\n",
      "Epoch 239/1000\n",
      "120/120 [==============================] - 0s 578us/sample - loss: 193.7346 - val_loss: 683.7731\n",
      "Epoch 240/1000\n",
      "120/120 [==============================] - 0s 833us/sample - loss: 191.7034 - val_loss: 795.4749\n",
      "Epoch 241/1000\n",
      "120/120 [==============================] - 0s 710us/sample - loss: 195.1415 - val_loss: 769.6339\n",
      "Epoch 242/1000\n",
      "120/120 [==============================] - 0s 916us/sample - loss: 218.3660 - val_loss: 740.6634\n",
      "Epoch 243/1000\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 208.1226 - val_loss: 722.2220\n",
      "Epoch 244/1000\n",
      "120/120 [==============================] - 0s 454us/sample - loss: 192.0204 - val_loss: 706.2040\n",
      "Epoch 245/1000\n",
      "120/120 [==============================] - 0s 534us/sample - loss: 188.8987 - val_loss: 841.3377\n",
      "Epoch 246/1000\n",
      "120/120 [==============================] - 0s 535us/sample - loss: 248.9701 - val_loss: 706.9036\n",
      "Epoch 247/1000\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 229.0087 - val_loss: 1229.0771\n",
      "Epoch 248/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 270.5785 - val_loss: 787.2571\n",
      "Epoch 249/1000\n",
      "120/120 [==============================] - 0s 446us/sample - loss: 225.8836 - val_loss: 819.6593\n",
      "Epoch 250/1000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 221.9622 - val_loss: 1290.5477\n",
      "Epoch 251/1000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 356.0315 - val_loss: 887.5573\n",
      "Epoch 252/1000\n",
      "120/120 [==============================] - 0s 355us/sample - loss: 386.5915 - val_loss: 1366.1393\n",
      "Epoch 253/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 524.7906 - val_loss: 1109.6321\n",
      "Epoch 254/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 522.1846 - val_loss: 1246.1251\n",
      "Epoch 255/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 615.6498 - val_loss: 1746.5852\n",
      "Epoch 256/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 460.7110 - val_loss: 1207.0569\n",
      "Epoch 257/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 547.4311 - val_loss: 1011.7684\n",
      "Epoch 258/1000\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 384.1155 - val_loss: 1607.4507\n",
      "Epoch 259/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 349.6992 - val_loss: 1973.2141\n",
      "Epoch 260/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 509.8352 - val_loss: 1226.0537\n",
      "Epoch 261/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 342.4922 - val_loss: 696.8936\n",
      "Epoch 262/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 205.6128 - val_loss: 708.5584\n",
      "Epoch 263/1000\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 209.5874 - val_loss: 700.8551\n",
      "Epoch 264/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 190.9532 - val_loss: 570.6456\n",
      "Epoch 265/1000\n",
      "120/120 [==============================] - 0s 514us/sample - loss: 202.6659 - val_loss: 909.9431\n",
      "Epoch 266/1000\n",
      "120/120 [==============================] - 0s 597us/sample - loss: 239.6914 - val_loss: 864.3368\n",
      "Epoch 267/1000\n",
      "120/120 [==============================] - 0s 670us/sample - loss: 227.7234 - val_loss: 886.3423\n",
      "Epoch 268/1000\n",
      "120/120 [==============================] - 0s 451us/sample - loss: 249.8165 - val_loss: 724.5977\n",
      "Epoch 269/1000\n",
      "120/120 [==============================] - 0s 412us/sample - loss: 212.7551 - val_loss: 694.3609\n",
      "Epoch 270/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 187.3091 - val_loss: 653.4905\n",
      "Epoch 271/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 188.3226 - val_loss: 644.7092\n",
      "Epoch 272/1000\n",
      "120/120 [==============================] - 0s 464us/sample - loss: 201.8026 - val_loss: 678.3045\n",
      "Epoch 273/1000\n",
      "120/120 [==============================] - 0s 414us/sample - loss: 187.3246 - val_loss: 711.0287\n",
      "Epoch 274/1000\n",
      "120/120 [==============================] - 0s 436us/sample - loss: 184.7752 - val_loss: 690.7328\n",
      "Epoch 275/1000\n",
      "120/120 [==============================] - 0s 416us/sample - loss: 183.9706 - val_loss: 726.0001\n",
      "Epoch 276/1000\n",
      "120/120 [==============================] - 0s 401us/sample - loss: 189.4073 - val_loss: 690.0136\n",
      "Epoch 277/1000\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 177.3891 - val_loss: 693.0273\n",
      "Epoch 278/1000\n",
      "120/120 [==============================] - 0s 457us/sample - loss: 188.8995 - val_loss: 674.3983\n",
      "Epoch 279/1000\n",
      "120/120 [==============================] - 0s 506us/sample - loss: 192.3932 - val_loss: 917.4046\n",
      "Epoch 280/1000\n",
      "120/120 [==============================] - 0s 429us/sample - loss: 252.8506 - val_loss: 670.3263\n",
      "Epoch 281/1000\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 199.7171 - val_loss: 776.4195\n",
      "Epoch 282/1000\n",
      "120/120 [==============================] - 0s 393us/sample - loss: 215.9726 - val_loss: 773.6893\n",
      "Epoch 283/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 198.7708 - val_loss: 598.0727\n",
      "Epoch 284/1000\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 183.8375 - val_loss: 671.3376\n",
      "Epoch 285/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 181.5947 - val_loss: 692.6780\n",
      "Epoch 286/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 173.5055 - val_loss: 605.4321\n",
      "Epoch 287/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 177.4902 - val_loss: 685.5718\n",
      "Epoch 288/1000\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 189.4917 - val_loss: 670.2388\n",
      "Epoch 289/1000\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 186.7050 - val_loss: 756.9167\n",
      "Epoch 290/1000\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 216.4016 - val_loss: 838.6815\n",
      "Epoch 291/1000\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 212.5016 - val_loss: 707.5386\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 301us/sample - loss: 245.4980 - val_loss: 1018.6685\n",
      "Epoch 293/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 264.8233 - val_loss: 705.1254\n",
      "Epoch 294/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 297.6687 - val_loss: 1025.4247\n",
      "Epoch 295/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 298.9660 - val_loss: 794.2599\n",
      "Epoch 296/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 244.2945 - val_loss: 624.9298\n",
      "Epoch 297/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 224.4495 - val_loss: 737.9171\n",
      "Epoch 298/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 215.7439 - val_loss: 684.6924\n",
      "Epoch 299/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 192.0222 - val_loss: 664.9868\n",
      "Epoch 300/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 206.6911 - val_loss: 665.3938\n",
      "Epoch 301/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 248.8930 - val_loss: 867.6163\n",
      "Epoch 302/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 211.8366 - val_loss: 689.4655\n",
      "Epoch 303/1000\n",
      "120/120 [==============================] - 0s 439us/sample - loss: 190.3202 - val_loss: 675.2192\n",
      "Epoch 304/1000\n",
      "120/120 [==============================] - 0s 518us/sample - loss: 179.3575 - val_loss: 727.6395\n",
      "Epoch 305/1000\n",
      "120/120 [==============================] - 0s 450us/sample - loss: 202.1275 - val_loss: 692.4809\n",
      "Epoch 306/1000\n",
      "120/120 [==============================] - 0s 483us/sample - loss: 198.1741 - val_loss: 656.2906\n",
      "Epoch 307/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 200.6291 - val_loss: 716.2228\n",
      "Epoch 308/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 189.8652 - val_loss: 655.8295\n",
      "Epoch 309/1000\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 177.1533 - val_loss: 580.0300\n",
      "Epoch 310/1000\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 192.3753 - val_loss: 779.8768\n",
      "Epoch 311/1000\n",
      "120/120 [==============================] - 0s 492us/sample - loss: 191.5361 - val_loss: 613.6877\n",
      "Epoch 312/1000\n",
      "120/120 [==============================] - 0s 419us/sample - loss: 168.5758 - val_loss: 572.7415\n",
      "Epoch 313/1000\n",
      "120/120 [==============================] - 0s 428us/sample - loss: 178.7912 - val_loss: 752.3371\n",
      "Epoch 314/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 186.9079 - val_loss: 1043.9535\n",
      "Epoch 315/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 256.3281 - val_loss: 855.7827\n",
      "Epoch 316/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 268.5557 - val_loss: 704.1675\n",
      "Epoch 317/1000\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 208.8340 - val_loss: 645.6457\n",
      "Epoch 318/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 177.1857 - val_loss: 577.1525\n",
      "Epoch 319/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 184.5460 - val_loss: 635.5108\n",
      "Epoch 320/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 179.3666 - val_loss: 652.9089\n",
      "Epoch 321/1000\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 156.6362 - val_loss: 642.5574\n",
      "Epoch 322/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 167.6921 - val_loss: 581.5128\n",
      "Epoch 323/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 157.7919 - val_loss: 623.5510\n",
      "Epoch 324/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 163.5051 - val_loss: 638.2275\n",
      "Epoch 325/1000\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 173.8346 - val_loss: 646.3863\n",
      "Epoch 326/1000\n",
      "120/120 [==============================] - 0s 519us/sample - loss: 183.1526 - val_loss: 652.0163\n",
      "Epoch 327/1000\n",
      "120/120 [==============================] - 0s 416us/sample - loss: 176.6133 - val_loss: 649.4144\n",
      "Epoch 328/1000\n",
      "120/120 [==============================] - 0s 441us/sample - loss: 159.7330 - val_loss: 617.7469\n",
      "Epoch 329/1000\n",
      "120/120 [==============================] - 0s 310us/sample - loss: 168.2800 - val_loss: 658.5700\n",
      "Epoch 330/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 211.0436 - val_loss: 758.2465\n",
      "Epoch 331/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 225.4772 - val_loss: 569.9916\n",
      "Epoch 332/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 185.1675 - val_loss: 850.6971\n",
      "Epoch 333/1000\n",
      "120/120 [==============================] - 0s 485us/sample - loss: 221.2983 - val_loss: 590.0777\n",
      "Epoch 334/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 159.8086 - val_loss: 581.2575\n",
      "Epoch 335/1000\n",
      "120/120 [==============================] - 0s 593us/sample - loss: 165.0817 - val_loss: 624.0398\n",
      "Epoch 336/1000\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 173.3717 - val_loss: 936.9512\n",
      "Epoch 337/1000\n",
      "120/120 [==============================] - 0s 424us/sample - loss: 245.1797 - val_loss: 728.0817\n",
      "Epoch 338/1000\n",
      "120/120 [==============================] - 0s 382us/sample - loss: 206.7952 - val_loss: 654.0285\n",
      "Epoch 339/1000\n",
      "120/120 [==============================] - 0s 462us/sample - loss: 230.9357 - val_loss: 783.0623\n",
      "Epoch 340/1000\n",
      "120/120 [==============================] - 0s 427us/sample - loss: 179.4460 - val_loss: 584.1585\n",
      "Epoch 341/1000\n",
      "120/120 [==============================] - 0s 484us/sample - loss: 170.6916 - val_loss: 600.8044\n",
      "Epoch 342/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 168.7671 - val_loss: 746.2046\n",
      "Epoch 343/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 183.6731 - val_loss: 913.5228\n",
      "Epoch 344/1000\n",
      "120/120 [==============================] - 0s 489us/sample - loss: 213.8990 - val_loss: 609.8347\n",
      "Epoch 345/1000\n",
      "120/120 [==============================] - 0s 477us/sample - loss: 232.4754 - val_loss: 622.9492\n",
      "Epoch 346/1000\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 166.0496 - val_loss: 739.6981\n",
      "Epoch 347/1000\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 218.3340 - val_loss: 762.9472\n",
      "Epoch 348/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 182.7282 - val_loss: 1041.1439\n",
      "Epoch 349/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 264.2213 - val_loss: 535.0845\n",
      "Epoch 350/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 213.3694 - val_loss: 709.3549\n",
      "Epoch 351/1000\n",
      "120/120 [==============================] - 0s 493us/sample - loss: 156.8730 - val_loss: 714.5699\n",
      "Epoch 352/1000\n",
      "120/120 [==============================] - 0s 503us/sample - loss: 201.5954 - val_loss: 523.8375\n",
      "Epoch 353/1000\n",
      "120/120 [==============================] - 0s 426us/sample - loss: 167.0372 - val_loss: 625.3760\n",
      "Epoch 354/1000\n",
      "120/120 [==============================] - 0s 402us/sample - loss: 155.1230 - val_loss: 508.2547\n",
      "Epoch 355/1000\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 149.9834 - val_loss: 588.9280\n",
      "Epoch 356/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 168.9755 - val_loss: 666.2322\n",
      "Epoch 357/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 168.5047 - val_loss: 553.9822\n",
      "Epoch 358/1000\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 163.8578 - val_loss: 543.6144\n",
      "Epoch 359/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 153.8379 - val_loss: 631.1172\n",
      "Epoch 360/1000\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 216.1097 - val_loss: 753.9301\n",
      "Epoch 361/1000\n",
      "120/120 [==============================] - 0s 408us/sample - loss: 244.8085 - val_loss: 811.6145\n",
      "Epoch 362/1000\n",
      "120/120 [==============================] - 0s 406us/sample - loss: 284.7910 - val_loss: 598.5436\n",
      "Epoch 363/1000\n",
      "120/120 [==============================] - 0s 518us/sample - loss: 204.7447 - val_loss: 610.4329\n",
      "Epoch 364/1000\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 249.9063 - val_loss: 713.2057\n",
      "Epoch 365/1000\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 211.2907 - val_loss: 606.4676\n",
      "Epoch 366/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 313.4864 - val_loss: 693.8677\n",
      "Epoch 367/1000\n",
      "120/120 [==============================] - 0s 447us/sample - loss: 199.9998 - val_loss: 753.5616\n",
      "Epoch 368/1000\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 222.6070 - val_loss: 624.4146\n",
      "Epoch 369/1000\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 222.5834 - val_loss: 620.5648\n",
      "Epoch 370/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 230.9579 - val_loss: 897.8657\n",
      "Epoch 371/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 358.2182 - val_loss: 806.8419\n",
      "Epoch 372/1000\n",
      "120/120 [==============================] - 0s 410us/sample - loss: 306.3643 - val_loss: 584.2822\n",
      "Epoch 373/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 185.8981 - val_loss: 689.6611\n",
      "Epoch 374/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 200.7535 - val_loss: 670.8634\n",
      "Epoch 375/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 166.8663 - val_loss: 500.5505\n",
      "Epoch 376/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 175.3900 - val_loss: 643.1866\n",
      "Epoch 377/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 159.2719 - val_loss: 616.0148\n",
      "Epoch 378/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 178.6828 - val_loss: 593.2549\n",
      "Epoch 379/1000\n",
      "120/120 [==============================] - 0s 417us/sample - loss: 149.1410 - val_loss: 613.5475\n",
      "Epoch 380/1000\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 164.9020 - val_loss: 564.1169\n",
      "Epoch 381/1000\n",
      "120/120 [==============================] - 0s 393us/sample - loss: 170.2331 - val_loss: 581.1449\n",
      "Epoch 382/1000\n",
      "120/120 [==============================] - 0s 424us/sample - loss: 167.4548 - val_loss: 659.5214\n",
      "Epoch 383/1000\n",
      "120/120 [==============================] - 0s 596us/sample - loss: 180.5888 - val_loss: 555.1863\n",
      "Epoch 384/1000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 177.6449 - val_loss: 616.1508\n",
      "Epoch 385/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 184.0487 - val_loss: 803.6205\n",
      "Epoch 386/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 170.1879 - val_loss: 511.5768\n",
      "Epoch 387/1000\n",
      "120/120 [==============================] - 0s 390us/sample - loss: 188.4156 - val_loss: 645.2614\n",
      "Epoch 388/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 176.0484 - val_loss: 721.5240\n",
      "Epoch 389/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 173.8146 - val_loss: 524.8845\n",
      "Epoch 390/1000\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 169.5271 - val_loss: 545.7230\n",
      "Epoch 391/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 185.1520 - val_loss: 774.1025\n",
      "Epoch 392/1000\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 190.3955 - val_loss: 678.0939\n",
      "Epoch 393/1000\n",
      "120/120 [==============================] - 0s 725us/sample - loss: 256.6679 - val_loss: 803.4428\n",
      "Epoch 394/1000\n",
      "120/120 [==============================] - 0s 679us/sample - loss: 318.2347 - val_loss: 1490.7169\n",
      "Epoch 395/1000\n",
      "120/120 [==============================] - 0s 577us/sample - loss: 382.7358 - val_loss: 527.1153\n",
      "Epoch 396/1000\n",
      "120/120 [==============================] - 0s 812us/sample - loss: 233.2934 - val_loss: 900.2073\n",
      "Epoch 397/1000\n",
      "120/120 [==============================] - 0s 428us/sample - loss: 253.7813 - val_loss: 631.0915\n",
      "Epoch 398/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 179.9793 - val_loss: 621.6301\n",
      "Epoch 399/1000\n",
      "120/120 [==============================] - 0s 340us/sample - loss: 212.2715 - val_loss: 655.8699\n",
      "Epoch 400/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 139.1343 - val_loss: 746.2066\n",
      "Epoch 401/1000\n",
      "120/120 [==============================] - 0s 394us/sample - loss: 215.6052 - val_loss: 525.3348\n",
      "Epoch 402/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 192.8881 - val_loss: 748.5518\n",
      "Epoch 403/1000\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 236.9688 - val_loss: 840.6641\n",
      "Epoch 404/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 262.0435 - val_loss: 705.4426\n",
      "Epoch 405/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 193.6457 - val_loss: 856.9415\n",
      "Epoch 406/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 207.6187 - val_loss: 642.7526\n",
      "Epoch 407/1000\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 194.6489 - val_loss: 512.0469\n",
      "Epoch 408/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 159.7424 - val_loss: 532.9796\n",
      "Epoch 409/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 140.0967 - val_loss: 615.5240\n",
      "Epoch 410/1000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 167.3757 - val_loss: 522.6526\n",
      "Epoch 411/1000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 160.2834 - val_loss: 468.9308\n",
      "Epoch 412/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 141.1179 - val_loss: 610.7900\n",
      "Epoch 413/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 156.6404 - val_loss: 549.3566\n",
      "Epoch 414/1000\n",
      "120/120 [==============================] - ETA: 0s - loss: 100.797 - 0s 360us/sample - loss: 153.2693 - val_loss: 476.6187\n",
      "Epoch 415/1000\n",
      "120/120 [==============================] - 0s 480us/sample - loss: 145.7822 - val_loss: 540.4792\n",
      "Epoch 416/1000\n",
      "120/120 [==============================] - 0s 803us/sample - loss: 150.3239 - val_loss: 529.7228\n",
      "Epoch 417/1000\n",
      "120/120 [==============================] - 0s 665us/sample - loss: 190.9178 - val_loss: 632.1811\n",
      "Epoch 418/1000\n",
      "120/120 [==============================] - 0s 592us/sample - loss: 219.7088 - val_loss: 683.4508\n",
      "Epoch 419/1000\n",
      "120/120 [==============================] - 0s 459us/sample - loss: 188.9233 - val_loss: 488.3457\n",
      "Epoch 420/1000\n",
      "120/120 [==============================] - 0s 501us/sample - loss: 172.5334 - val_loss: 500.9017\n",
      "Epoch 421/1000\n",
      "120/120 [==============================] - 0s 476us/sample - loss: 141.7895 - val_loss: 597.3854\n",
      "Epoch 422/1000\n",
      "120/120 [==============================] - 0s 522us/sample - loss: 147.0140 - val_loss: 490.0267\n",
      "Epoch 423/1000\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 152.3456 - val_loss: 616.2563\n",
      "Epoch 424/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 151.1593 - val_loss: 737.8038\n",
      "Epoch 425/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 213.5411 - val_loss: 591.1307\n",
      "Epoch 426/1000\n",
      "120/120 [==============================] - 0s 368us/sample - loss: 156.3369 - val_loss: 619.6679\n",
      "Epoch 427/1000\n",
      "120/120 [==============================] - 0s 726us/sample - loss: 167.5245 - val_loss: 522.8052\n",
      "Epoch 428/1000\n",
      "120/120 [==============================] - 0s 650us/sample - loss: 135.2254 - val_loss: 553.5850\n",
      "Epoch 429/1000\n",
      "120/120 [==============================] - 0s 458us/sample - loss: 148.1235 - val_loss: 515.2862\n",
      "Epoch 430/1000\n",
      "120/120 [==============================] - 0s 743us/sample - loss: 156.2423 - val_loss: 674.7844\n",
      "Epoch 431/1000\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 179.5697 - val_loss: 495.2402\n",
      "Epoch 432/1000\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 209.3890 - val_loss: 790.9993\n",
      "Epoch 433/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 236.6402 - val_loss: 534.7421\n",
      "Epoch 434/1000\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 195.8625 - val_loss: 750.8438\n",
      "Epoch 435/1000\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 242.9159 - val_loss: 541.3621\n",
      "Epoch 436/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 235.0958 - val_loss: 754.7195\n",
      "Epoch 437/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 255.1299 - val_loss: 787.7924\n",
      "Epoch 438/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 263us/sample - loss: 196.7209 - val_loss: 547.4647\n",
      "Epoch 439/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 215.8372 - val_loss: 546.8480\n",
      "Epoch 440/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 135.3065 - val_loss: 615.6300\n",
      "Epoch 441/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 174.6528 - val_loss: 529.0778\n",
      "Epoch 442/1000\n",
      "120/120 [==============================] - 0s 468us/sample - loss: 157.6396 - val_loss: 551.0286\n",
      "Epoch 443/1000\n",
      "120/120 [==============================] - 0s 631us/sample - loss: 171.7812 - val_loss: 595.3790\n",
      "Epoch 444/1000\n",
      "120/120 [==============================] - 0s 766us/sample - loss: 223.9768 - val_loss: 895.2320\n",
      "Epoch 445/1000\n",
      "120/120 [==============================] - 0s 620us/sample - loss: 310.6581 - val_loss: 567.4209\n",
      "Epoch 446/1000\n",
      "120/120 [==============================] - 0s 443us/sample - loss: 239.9350 - val_loss: 1221.4341\n",
      "Epoch 447/1000\n",
      "120/120 [==============================] - 0s 543us/sample - loss: 282.6535 - val_loss: 724.4066\n",
      "Epoch 448/1000\n",
      "120/120 [==============================] - 0s 611us/sample - loss: 285.6301 - val_loss: 703.6459\n",
      "Epoch 449/1000\n",
      "120/120 [==============================] - 0s 632us/sample - loss: 216.6150 - val_loss: 1226.4427\n",
      "Epoch 450/1000\n",
      "120/120 [==============================] - 0s 715us/sample - loss: 302.4414 - val_loss: 457.1101\n",
      "Epoch 451/1000\n",
      "120/120 [==============================] - 0s 848us/sample - loss: 240.9577 - val_loss: 1066.5428\n",
      "Epoch 452/1000\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 242.4565 - val_loss: 922.0529\n",
      "Epoch 453/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 266.8487 - val_loss: 496.5091\n",
      "Epoch 454/1000\n",
      "120/120 [==============================] - 0s 351us/sample - loss: 186.8766 - val_loss: 1004.5311\n",
      "Epoch 455/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 261.9734 - val_loss: 696.1792\n",
      "Epoch 456/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 198.5371 - val_loss: 507.1031\n",
      "Epoch 457/1000\n",
      "120/120 [==============================] - 0s 285us/sample - loss: 179.5259 - val_loss: 826.4672\n",
      "Epoch 458/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 161.8925 - val_loss: 756.7097\n",
      "Epoch 459/1000\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 183.3617 - val_loss: 525.2505\n",
      "Epoch 460/1000\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 166.4113 - val_loss: 492.9354\n",
      "Epoch 461/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 159.4744 - val_loss: 864.2418\n",
      "Epoch 462/1000\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 249.4073 - val_loss: 548.3644\n",
      "Epoch 463/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 173.8201 - val_loss: 987.9755\n",
      "Epoch 464/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 228.3017 - val_loss: 1038.1053\n",
      "Epoch 465/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 242.4683 - val_loss: 497.0882\n",
      "Epoch 466/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 254.4817 - val_loss: 1058.9178\n",
      "Epoch 467/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 311.4608 - val_loss: 568.4031\n",
      "Epoch 468/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 225.7005 - val_loss: 689.4271\n",
      "Epoch 469/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 184.5854 - val_loss: 666.9893\n",
      "Epoch 470/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 155.2981 - val_loss: 537.1714\n",
      "Epoch 471/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 141.7270 - val_loss: 478.8635\n",
      "Epoch 472/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 134.2532 - val_loss: 484.1332\n",
      "Epoch 473/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 140.5903 - val_loss: 479.4865\n",
      "Epoch 474/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 124.3788 - val_loss: 495.2632\n",
      "Epoch 475/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 143.5977 - val_loss: 455.6100\n",
      "Epoch 476/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 145.1145 - val_loss: 506.4785\n",
      "Epoch 477/1000\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 128.3424 - val_loss: 487.4710\n",
      "Epoch 478/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 134.9513 - val_loss: 515.7003\n",
      "Epoch 479/1000\n",
      "120/120 [==============================] - 0s 333us/sample - loss: 138.8190 - val_loss: 483.5951\n",
      "Epoch 480/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 122.0445 - val_loss: 483.8609\n",
      "Epoch 481/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 120.4631 - val_loss: 460.0209\n",
      "Epoch 482/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 123.1916 - val_loss: 542.2758\n",
      "Epoch 483/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 140.4561 - val_loss: 459.1371\n",
      "Epoch 484/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 134.0401 - val_loss: 489.0650\n",
      "Epoch 485/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 133.8855 - val_loss: 712.7032\n",
      "Epoch 486/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 165.0597 - val_loss: 473.9922\n",
      "Epoch 487/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 128.5706 - val_loss: 538.1096\n",
      "Epoch 488/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 149.7233 - val_loss: 722.5935\n",
      "Epoch 489/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 136.5232 - val_loss: 652.7436\n",
      "Epoch 490/1000\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 149.7410 - val_loss: 495.7731\n",
      "Epoch 491/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 149.4530 - val_loss: 587.3430\n",
      "Epoch 492/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 154.8464 - val_loss: 461.6528\n",
      "Epoch 493/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 116.0717 - val_loss: 518.0121\n",
      "Epoch 494/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 125.0487 - val_loss: 466.1039\n",
      "Epoch 495/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 126.5994 - val_loss: 471.3001\n",
      "Epoch 496/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 139.6901 - val_loss: 485.3025\n",
      "Epoch 497/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 128.4068 - val_loss: 452.4273\n",
      "Epoch 498/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 121.5918 - val_loss: 522.6888\n",
      "Epoch 499/1000\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 126.7316 - val_loss: 513.3369\n",
      "Epoch 500/1000\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 123.0512 - val_loss: 606.7893\n",
      "Epoch 501/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 175.1587 - val_loss: 510.5088\n",
      "Epoch 502/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 133.8947 - val_loss: 610.7425\n",
      "Epoch 503/1000\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 152.6424 - val_loss: 456.9003\n",
      "Epoch 504/1000\n",
      "120/120 [==============================] - 0s 382us/sample - loss: 137.9962 - val_loss: 475.1786\n",
      "Epoch 505/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 139.7196 - val_loss: 475.9110\n",
      "Epoch 506/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 138.6176 - val_loss: 507.0369\n",
      "Epoch 507/1000\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 162.5139 - val_loss: 566.5778\n",
      "Epoch 508/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 164.6653 - val_loss: 542.8857\n",
      "Epoch 509/1000\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 145.6589 - val_loss: 513.3284\n",
      "Epoch 510/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 139.3188 - val_loss: 462.4374\n",
      "Epoch 511/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 145.2184 - val_loss: 719.7520\n",
      "Epoch 512/1000\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 168.0540 - val_loss: 466.8676\n",
      "Epoch 513/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 120.0744 - val_loss: 485.0874\n",
      "Epoch 514/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 121.5544 - val_loss: 544.5895\n",
      "Epoch 515/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 121.2218 - val_loss: 489.0348\n",
      "Epoch 516/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 122.7704 - val_loss: 554.2993\n",
      "Epoch 517/1000\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 132.8915 - val_loss: 453.4747\n",
      "Epoch 518/1000\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 123.5239 - val_loss: 483.1442\n",
      "Epoch 519/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 112.5274 - val_loss: 453.3129\n",
      "Epoch 520/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 110.8668 - val_loss: 439.3196\n",
      "Epoch 521/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 120.7757 - val_loss: 516.2825\n",
      "Epoch 522/1000\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 140.4073 - val_loss: 598.8066\n",
      "Epoch 523/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 147.6749 - val_loss: 499.7781\n",
      "Epoch 524/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 126.0942 - val_loss: 482.0244\n",
      "Epoch 525/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 142.0614 - val_loss: 443.2365\n",
      "Epoch 526/1000\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 130.9493 - val_loss: 520.9822\n",
      "Epoch 527/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 155.6875 - val_loss: 555.6790\n",
      "Epoch 528/1000\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 121.6307 - val_loss: 570.8135\n",
      "Epoch 529/1000\n",
      "120/120 [==============================] - 0s 674us/sample - loss: 140.7047 - val_loss: 452.0033\n",
      "Epoch 530/1000\n",
      "120/120 [==============================] - 0s 466us/sample - loss: 125.4150 - val_loss: 608.0688\n",
      "Epoch 531/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 146.7728 - val_loss: 518.2892\n",
      "Epoch 532/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 133.6888 - val_loss: 444.8303\n",
      "Epoch 533/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 118.9842 - val_loss: 630.5325\n",
      "Epoch 534/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 129.7836 - val_loss: 514.2452\n",
      "Epoch 535/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 111.5170 - val_loss: 434.6568\n",
      "Epoch 536/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 118.9913 - val_loss: 459.1915\n",
      "Epoch 537/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 126.2808 - val_loss: 512.9845\n",
      "Epoch 538/1000\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 135.8676 - val_loss: 606.5093\n",
      "Epoch 539/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 146.4633 - val_loss: 480.6818\n",
      "Epoch 540/1000\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 211.7179 - val_loss: 920.3221\n",
      "Epoch 541/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 204.1791 - val_loss: 539.2853\n",
      "Epoch 542/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 131.4136 - val_loss: 446.3110\n",
      "Epoch 543/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 111.7241 - val_loss: 646.1183\n",
      "Epoch 544/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 135.9401 - val_loss: 959.8398\n",
      "Epoch 545/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 205.9814 - val_loss: 467.9726\n",
      "Epoch 546/1000\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 113.0781 - val_loss: 436.9531\n",
      "Epoch 547/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 138.3097 - val_loss: 475.3853\n",
      "Epoch 548/1000\n",
      "120/120 [==============================] - 0s 188us/sample - loss: 128.3163 - val_loss: 469.2209\n",
      "Epoch 549/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 114.4732 - val_loss: 490.2274\n",
      "Epoch 550/1000\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 136.5993 - val_loss: 466.3117\n",
      "Epoch 551/1000\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 126.2603 - val_loss: 549.6078\n",
      "Epoch 552/1000\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 134.2991 - val_loss: 430.1934\n",
      "Epoch 553/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 109.8121 - val_loss: 478.0985\n",
      "Epoch 554/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 106.3508 - val_loss: 510.0078\n",
      "Epoch 555/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 131.3849 - val_loss: 445.9019\n",
      "Epoch 556/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 123.4376 - val_loss: 443.9284\n",
      "Epoch 557/1000\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 123.8480 - val_loss: 496.9106\n",
      "Epoch 558/1000\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 114.1030 - val_loss: 475.6110\n",
      "Epoch 559/1000\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 101.8122 - val_loss: 466.8746\n",
      "Epoch 560/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 119.4472 - val_loss: 419.3580\n",
      "Epoch 561/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 112.9338 - val_loss: 441.0243\n",
      "Epoch 562/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 109.6041 - val_loss: 457.1227\n",
      "Epoch 563/1000\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 107.1183 - val_loss: 474.9297\n",
      "Epoch 564/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 127.8897 - val_loss: 482.7170\n",
      "Epoch 565/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 111.0216 - val_loss: 460.2342\n",
      "Epoch 566/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 108.5363 - val_loss: 447.0203\n",
      "Epoch 567/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 107.1238 - val_loss: 451.8353\n",
      "Epoch 568/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 103.1237 - val_loss: 456.4363\n",
      "Epoch 569/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 105.4856 - val_loss: 484.3636\n",
      "Epoch 570/1000\n",
      "120/120 [==============================] - 0s 187us/sample - loss: 125.2905 - val_loss: 442.1229\n",
      "Epoch 571/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 150.6233 - val_loss: 460.7535\n",
      "Epoch 572/1000\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 116.2855 - val_loss: 480.5761\n",
      "Epoch 573/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 127.9240 - val_loss: 450.8541\n",
      "Epoch 574/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 111.4176 - val_loss: 458.5186\n",
      "Epoch 575/1000\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 108.0465 - val_loss: 485.5647\n",
      "Epoch 576/1000\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 114.2374 - val_loss: 454.8030\n",
      "Epoch 577/1000\n",
      "120/120 [==============================] - 0s 624us/sample - loss: 112.4686 - val_loss: 437.5310\n",
      "Epoch 578/1000\n",
      "120/120 [==============================] - 0s 511us/sample - loss: 105.9065 - val_loss: 425.2232\n",
      "Epoch 579/1000\n",
      "120/120 [==============================] - 0s 568us/sample - loss: 103.3594 - val_loss: 449.8503\n",
      "Epoch 580/1000\n",
      "120/120 [==============================] - 0s 525us/sample - loss: 105.2198 - val_loss: 442.1783\n",
      "Epoch 581/1000\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 110.3187 - val_loss: 496.6537\n",
      "Epoch 582/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 130.4230 - val_loss: 606.6703\n",
      "Epoch 583/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 163.8235 - val_loss: 516.1683\n",
      "Epoch 584/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 257us/sample - loss: 153.5851 - val_loss: 481.6837\n",
      "Epoch 585/1000\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 115.4945 - val_loss: 462.1435\n",
      "Epoch 586/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 120.3363 - val_loss: 425.5033\n",
      "Epoch 587/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 113.0549 - val_loss: 433.7737\n",
      "Epoch 588/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 105.9718 - val_loss: 452.0735\n",
      "Epoch 589/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 119.4237 - val_loss: 444.1472\n",
      "Epoch 590/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 107.7515 - val_loss: 420.6546\n",
      "Epoch 591/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 109.8108 - val_loss: 474.5105\n",
      "Epoch 592/1000\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 105.9289 - val_loss: 477.5947\n",
      "Epoch 593/1000\n",
      "120/120 [==============================] - 0s 739us/sample - loss: 130.2094 - val_loss: 460.7875\n",
      "Epoch 594/1000\n",
      "120/120 [==============================] - 0s 682us/sample - loss: 92.5308 - val_loss: 440.3419\n",
      "Epoch 595/1000\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 118.0266 - val_loss: 456.0986\n",
      "Epoch 596/1000\n",
      "120/120 [==============================] - 0s 549us/sample - loss: 134.2003 - val_loss: 458.7840\n",
      "Epoch 597/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 148.6664 - val_loss: 422.9832\n",
      "Epoch 598/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 111.8816 - val_loss: 505.8600\n",
      "Epoch 599/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 127.7503 - val_loss: 616.4653\n",
      "Epoch 600/1000\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 128.1186 - val_loss: 434.7133\n",
      "Epoch 601/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 113.8721 - val_loss: 601.1174\n",
      "Epoch 602/1000\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 116.5270 - val_loss: 882.3839\n",
      "Epoch 603/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 181.2832 - val_loss: 446.9448\n",
      "Epoch 604/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 145.6644 - val_loss: 863.9376\n",
      "Epoch 605/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 246.0833 - val_loss: 634.1658\n",
      "Epoch 606/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 165.9309 - val_loss: 467.3931\n",
      "Epoch 607/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 150.6854 - val_loss: 624.7345\n",
      "Epoch 608/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 168.6423 - val_loss: 498.5507\n",
      "Epoch 609/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 127.3673 - val_loss: 539.3163\n",
      "Epoch 610/1000\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 142.3175 - val_loss: 443.6959\n",
      "Epoch 611/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 128.5981 - val_loss: 462.6595\n",
      "Epoch 612/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 126.8057 - val_loss: 597.4660\n",
      "Epoch 613/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 121.2556 - val_loss: 429.1298\n",
      "Epoch 614/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 129.1344 - val_loss: 507.6300\n",
      "Epoch 615/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 122.8947 - val_loss: 552.8198\n",
      "Epoch 616/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 121.6431 - val_loss: 433.9134\n",
      "Epoch 617/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 153.8780 - val_loss: 531.6804\n",
      "Epoch 618/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 175.7227 - val_loss: 535.5908\n",
      "Epoch 619/1000\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 183.1166 - val_loss: 742.9442\n",
      "Epoch 620/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 257.2431 - val_loss: 940.4021\n",
      "Epoch 621/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 311.0422 - val_loss: 604.0036\n",
      "Epoch 622/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 182.2953 - val_loss: 738.5000\n",
      "Epoch 623/1000\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 156.4817 - val_loss: 591.1975\n",
      "Epoch 624/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 150.4488 - val_loss: 487.4692\n",
      "Epoch 625/1000\n",
      "120/120 [==============================] - 0s 188us/sample - loss: 164.7942 - val_loss: 419.8071\n",
      "Epoch 626/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 116.1529 - val_loss: 447.4919\n",
      "Epoch 627/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 107.3877 - val_loss: 546.5908\n",
      "Epoch 628/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 112.7212 - val_loss: 465.7427\n",
      "Epoch 629/1000\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 112.8349 - val_loss: 540.8741\n",
      "Epoch 630/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 132.3271 - val_loss: 517.8564\n",
      "Epoch 631/1000\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 109.8111 - val_loss: 594.9836\n",
      "Epoch 632/1000\n",
      "120/120 [==============================] - 0s 429us/sample - loss: 128.8922 - val_loss: 468.3495\n",
      "Epoch 633/1000\n",
      "120/120 [==============================] - 0s 543us/sample - loss: 120.9778 - val_loss: 457.8830\n",
      "Epoch 634/1000\n",
      "120/120 [==============================] - 0s 632us/sample - loss: 118.0037 - val_loss: 466.2890\n",
      "Epoch 635/1000\n",
      "120/120 [==============================] - 0s 575us/sample - loss: 111.9653 - val_loss: 473.9943\n",
      "Epoch 636/1000\n",
      "120/120 [==============================] - 0s 503us/sample - loss: 110.9273 - val_loss: 567.9042\n",
      "Epoch 637/1000\n",
      "120/120 [==============================] - 0s 417us/sample - loss: 129.4239 - val_loss: 463.7962\n",
      "Epoch 638/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 147.4836 - val_loss: 664.8130\n",
      "Epoch 639/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 156.2729 - val_loss: 987.0045\n",
      "Epoch 640/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 242.9208 - val_loss: 524.9514\n",
      "Epoch 641/1000\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 146.8793 - val_loss: 640.6271\n",
      "Epoch 642/1000\n",
      "120/120 [==============================] - 0s 648us/sample - loss: 146.2372 - val_loss: 460.7998\n",
      "Epoch 643/1000\n",
      "120/120 [==============================] - 0s 672us/sample - loss: 117.1969 - val_loss: 707.0594\n",
      "Epoch 644/1000\n",
      "120/120 [==============================] - 0s 509us/sample - loss: 160.5582 - val_loss: 469.2213\n",
      "Epoch 645/1000\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 140.4622 - val_loss: 523.2397\n",
      "Epoch 646/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 133.0414 - val_loss: 688.8187\n",
      "Epoch 647/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 170.6255 - val_loss: 460.7979\n",
      "Epoch 648/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 124.4534 - val_loss: 669.8641\n",
      "Epoch 649/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 135.4059 - val_loss: 647.5311\n",
      "Epoch 650/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 136.8577 - val_loss: 448.4173\n",
      "Epoch 651/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 113.4852 - val_loss: 445.1879\n",
      "Epoch 652/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 115.0676 - val_loss: 467.1194\n",
      "Epoch 653/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 99.6052 - val_loss: 642.4537\n",
      "Epoch 654/1000\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 144.9499 - val_loss: 418.1375\n",
      "Epoch 655/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 115.3650 - val_loss: 650.0197\n",
      "Epoch 656/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 159.5288 - val_loss: 647.9941\n",
      "Epoch 657/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 125.5041 - val_loss: 411.6583\n",
      "Epoch 658/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 181.3591 - val_loss: 575.0676\n",
      "Epoch 659/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 157.7599 - val_loss: 424.0513\n",
      "Epoch 660/1000\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 120.6433 - val_loss: 660.5981\n",
      "Epoch 661/1000\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 141.8679 - val_loss: 445.8947\n",
      "Epoch 662/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 115.1790 - val_loss: 475.0339\n",
      "Epoch 663/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 145.4093 - val_loss: 414.3506\n",
      "Epoch 664/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 113.3530 - val_loss: 424.1716\n",
      "Epoch 665/1000\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 98.8769 - val_loss: 436.3405\n",
      "Epoch 666/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 91.0658 - val_loss: 420.9622\n",
      "Epoch 667/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 107.8787 - val_loss: 425.6126\n",
      "Epoch 668/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 95.1543 - val_loss: 427.7984\n",
      "Epoch 669/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 91.4191 - val_loss: 505.3325\n",
      "Epoch 670/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 125.3253 - val_loss: 435.2447\n",
      "Epoch 671/1000\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 107.0757 - val_loss: 532.9003\n",
      "Epoch 672/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 116.0730 - val_loss: 506.3281\n",
      "Epoch 673/1000\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 104.9756 - val_loss: 436.0271\n",
      "Epoch 674/1000\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 102.4229 - val_loss: 493.2668\n",
      "Epoch 675/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 125.0301 - val_loss: 550.3810\n",
      "Epoch 676/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 123.8549 - val_loss: 439.1155\n",
      "Epoch 677/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 123.7497 - val_loss: 680.5510\n",
      "Epoch 678/1000\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 147.5695 - val_loss: 460.2742\n",
      "Epoch 679/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 144.9248 - val_loss: 895.5097\n",
      "Epoch 680/1000\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 175.8680 - val_loss: 398.0040\n",
      "Epoch 681/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 159.0729 - val_loss: 524.2642\n",
      "Epoch 682/1000\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 166.5325 - val_loss: 416.3877\n",
      "Epoch 683/1000\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 126.0234 - val_loss: 442.7228\n",
      "Epoch 684/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 108.3131 - val_loss: 484.1534\n",
      "Epoch 685/1000\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 103.7486 - val_loss: 458.2990\n",
      "Epoch 686/1000\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 114.5081 - val_loss: 435.8202\n",
      "Epoch 687/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 117.2263 - val_loss: 635.9460\n",
      "Epoch 688/1000\n",
      "120/120 [==============================] - 0s 338us/sample - loss: 139.4008 - val_loss: 415.4723\n",
      "Epoch 689/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 107.1910 - val_loss: 464.9932\n",
      "Epoch 690/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 98.1006 - val_loss: 476.6473\n",
      "Epoch 691/1000\n",
      "120/120 [==============================] - 0s 188us/sample - loss: 100.7890 - val_loss: 504.5949\n",
      "Epoch 692/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 105.2796 - val_loss: 445.6273\n",
      "Epoch 693/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 98.6334 - val_loss: 429.9853\n",
      "Epoch 694/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 96.3196 - val_loss: 423.2184\n",
      "Epoch 695/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 112.1866 - val_loss: 455.3712\n",
      "Epoch 696/1000\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 113.0343 - val_loss: 509.1094\n",
      "Epoch 697/1000\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 162.6102 - val_loss: 747.6028\n",
      "Epoch 698/1000\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 164.1268 - val_loss: 535.5445\n",
      "Epoch 699/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 139.7798 - val_loss: 714.0783\n",
      "Epoch 700/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 156.5256 - val_loss: 529.5724\n",
      "Epoch 701/1000\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 143.9420 - val_loss: 446.5198\n",
      "Epoch 702/1000\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 111.9731 - val_loss: 559.8875\n",
      "Epoch 703/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 107.1261 - val_loss: 435.0393\n",
      "Epoch 704/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 109.2645 - val_loss: 441.4035\n",
      "Epoch 705/1000\n",
      "120/120 [==============================] - 0s 187us/sample - loss: 86.4685 - val_loss: 467.3641\n",
      "Epoch 706/1000\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 110.2004 - val_loss: 465.4508\n",
      "Epoch 707/1000\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 101.1617 - val_loss: 509.1765\n",
      "Epoch 708/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 124.3545 - val_loss: 541.5672\n",
      "Epoch 709/1000\n",
      "120/120 [==============================] - 0s 187us/sample - loss: 171.2469 - val_loss: 503.0128\n",
      "Epoch 710/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 183.6493 - val_loss: 1122.5151\n",
      "Epoch 711/1000\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 264.4147 - val_loss: 478.3073\n",
      "Epoch 712/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 222.8037 - val_loss: 641.2825\n",
      "Epoch 713/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 173.5502 - val_loss: 444.4839\n",
      "Epoch 714/1000\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 131.1729 - val_loss: 500.9374\n",
      "Epoch 715/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 171.6797 - val_loss: 513.0079\n",
      "Epoch 716/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 190.2751 - val_loss: 471.8215\n",
      "Epoch 717/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 113.6093 - val_loss: 569.8920\n",
      "Epoch 718/1000\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 150.6741 - val_loss: 497.6964\n",
      "Epoch 719/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 140.3672 - val_loss: 477.9381\n",
      "Epoch 720/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 155.8340 - val_loss: 763.2701\n",
      "Epoch 721/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 156.8084 - val_loss: 438.9960\n",
      "Epoch 722/1000\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 150.1298 - val_loss: 508.3680\n",
      "Epoch 723/1000\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 100.2493 - val_loss: 582.7745\n",
      "Epoch 724/1000\n",
      "120/120 [==============================] - 0s 424us/sample - loss: 116.7616 - val_loss: 443.5313\n",
      "Epoch 725/1000\n",
      "120/120 [==============================] - 0s 558us/sample - loss: 97.4318 - val_loss: 445.6248\n",
      "Epoch 726/1000\n",
      "120/120 [==============================] - 0s 600us/sample - loss: 104.8803 - val_loss: 467.1402\n",
      "Epoch 727/1000\n",
      "120/120 [==============================] - 0s 665us/sample - loss: 109.7895 - val_loss: 434.7772\n",
      "Epoch 728/1000\n",
      "120/120 [==============================] - 0s 563us/sample - loss: 125.5283 - val_loss: 514.4706\n",
      "Epoch 729/1000\n",
      "120/120 [==============================] - 0s 494us/sample - loss: 110.5602 - val_loss: 541.6474\n",
      "Epoch 730/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 285us/sample - loss: 126.1621 - val_loss: 459.5131\n",
      "Epoch 731/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 139.8381 - val_loss: 432.1567\n",
      "Epoch 732/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 108.0450 - val_loss: 455.3328\n",
      "Epoch 733/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 117.4675 - val_loss: 445.0155\n",
      "Epoch 734/1000\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 114.6528 - val_loss: 456.2325\n",
      "Epoch 735/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 119.0473 - val_loss: 416.9220\n",
      "Epoch 736/1000\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 100.6568 - val_loss: 607.9109\n",
      "Epoch 737/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 133.6128 - val_loss: 447.5065\n",
      "Epoch 738/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 117.4210 - val_loss: 490.7518\n",
      "Epoch 739/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 118.5597 - val_loss: 394.9828\n",
      "Epoch 740/1000\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 93.5827 - val_loss: 477.7169\n",
      "Epoch 741/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 89.2275 - val_loss: 421.3389\n",
      "Epoch 742/1000\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 79.8524 - val_loss: 461.8953\n",
      "Epoch 743/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 104.2787 - val_loss: 416.4553\n",
      "Epoch 744/1000\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 93.9750 - val_loss: 421.2955\n",
      "Epoch 745/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 89.7177 - val_loss: 542.5430\n",
      "Epoch 746/1000\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 133.9004 - val_loss: 492.1209\n",
      "Epoch 747/1000\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 129.0493 - val_loss: 607.3547\n",
      "Epoch 748/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 111.4071 - val_loss: 484.4167\n",
      "Epoch 749/1000\n",
      "120/120 [==============================] - 0s 488us/sample - loss: 138.4800 - val_loss: 560.7885\n",
      "Epoch 750/1000\n",
      "120/120 [==============================] - 0s 559us/sample - loss: 102.8745 - val_loss: 464.4168\n",
      "Epoch 751/1000\n",
      "120/120 [==============================] - 0s 650us/sample - loss: 112.2675 - val_loss: 408.8149\n",
      "Epoch 752/1000\n",
      "120/120 [==============================] - 0s 395us/sample - loss: 98.2719 - val_loss: 391.8658\n",
      "Epoch 753/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 91.8718 - val_loss: 489.5683\n",
      "Epoch 754/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 88.4274 - val_loss: 478.3149\n",
      "Epoch 755/1000\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 116.6304 - val_loss: 454.7231\n",
      "Epoch 756/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 87.7794 - val_loss: 451.7422\n",
      "Epoch 757/1000\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 100.3687 - val_loss: 509.2950\n",
      "Epoch 758/1000\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 111.2298 - val_loss: 446.5627\n",
      "Epoch 759/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 138.8752 - val_loss: 798.0355\n",
      "Epoch 760/1000\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 176.1616 - val_loss: 590.5347\n",
      "Epoch 761/1000\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 156.8267 - val_loss: 544.8427\n",
      "Epoch 762/1000\n",
      "120/120 [==============================] - 0s 445us/sample - loss: 118.2503 - val_loss: 468.4908\n",
      "Epoch 763/1000\n",
      "120/120 [==============================] - 0s 553us/sample - loss: 104.7623 - val_loss: 487.0548\n",
      "Epoch 764/1000\n",
      "120/120 [==============================] - 0s 533us/sample - loss: 116.1544 - val_loss: 424.4368\n",
      "Epoch 765/1000\n",
      "120/120 [==============================] - 0s 488us/sample - loss: 107.8932 - val_loss: 812.7704\n",
      "Epoch 766/1000\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 159.1155 - val_loss: 448.8403\n",
      "Epoch 767/1000\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 109.9529 - val_loss: 560.1260\n",
      "Epoch 768/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 132.3911 - val_loss: 400.1316\n",
      "Epoch 769/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 97.3335 - val_loss: 571.0369\n",
      "Epoch 770/1000\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 116.1386 - val_loss: 460.9224\n",
      "Epoch 771/1000\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 147.3662 - val_loss: 581.9679\n",
      "Epoch 772/1000\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 128.4926 - val_loss: 661.5377\n",
      "Epoch 773/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 150.9761 - val_loss: 567.9457\n",
      "Epoch 774/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 137.8234 - val_loss: 461.0537\n",
      "Epoch 775/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 100.0181 - val_loss: 461.2274\n",
      "Epoch 776/1000\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 101.0695 - val_loss: 603.7586\n",
      "Epoch 777/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 141.7485 - val_loss: 431.8173\n",
      "Epoch 778/1000\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 145.2525 - val_loss: 631.6084\n",
      "Epoch 779/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 129.4754 - val_loss: 411.4749\n",
      "Epoch 780/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 101.5637 - val_loss: 465.9847\n",
      "Epoch 781/1000\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 93.3547 - val_loss: 462.6817\n",
      "Epoch 782/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 98.1286 - val_loss: 464.7181\n",
      "Epoch 783/1000\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 96.3016 - val_loss: 436.2848\n",
      "Epoch 784/1000\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 102.6172 - val_loss: 450.0053\n",
      "Epoch 785/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 123.0009 - val_loss: 523.6473\n",
      "Epoch 786/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 140.9717 - val_loss: 817.3319\n",
      "Epoch 787/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 148.1142 - val_loss: 431.2352\n",
      "Epoch 788/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 117.0925 - val_loss: 517.8524\n",
      "Epoch 789/1000\n",
      "120/120 [==============================] - 0s 467us/sample - loss: 143.3708 - val_loss: 573.6118\n",
      "Epoch 790/1000\n",
      "120/120 [==============================] - 0s 559us/sample - loss: 117.3982 - val_loss: 590.4193\n",
      "Epoch 791/1000\n",
      "120/120 [==============================] - 0s 514us/sample - loss: 110.1104 - val_loss: 463.9631\n",
      "Epoch 792/1000\n",
      "120/120 [==============================] - 0s 596us/sample - loss: 132.4827 - val_loss: 454.7886\n",
      "Epoch 793/1000\n",
      "120/120 [==============================] - 0s 369us/sample - loss: 123.9589 - val_loss: 584.3893\n",
      "Epoch 794/1000\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 132.0336 - val_loss: 569.7647\n",
      "Epoch 795/1000\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 136.7736 - val_loss: 441.5145\n",
      "Epoch 796/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 81.5939 - val_loss: 502.4097\n",
      "Epoch 797/1000\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 96.2368 - val_loss: 453.0418\n",
      "Epoch 798/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 92.3839 - val_loss: 395.2290\n",
      "Epoch 799/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 82.7735 - val_loss: 445.9174\n",
      "Epoch 800/1000\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 93.0859 - val_loss: 417.5486\n",
      "Epoch 801/1000\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 88.1418 - val_loss: 424.4055\n",
      "Epoch 802/1000\n",
      "120/120 [==============================] - 0s 431us/sample - loss: 83.4511 - val_loss: 455.0260\n",
      "Epoch 803/1000\n",
      "120/120 [==============================] - 0s 483us/sample - loss: 104.8193 - val_loss: 424.9985\n",
      "Epoch 804/1000\n",
      "120/120 [==============================] - 0s 523us/sample - loss: 96.2974 - val_loss: 502.6516\n",
      "Epoch 805/1000\n",
      "120/120 [==============================] - 0s 509us/sample - loss: 82.4843 - val_loss: 410.9380\n",
      "Epoch 806/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 115.8867 - val_loss: 533.9265\n",
      "Epoch 807/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 143.1690 - val_loss: 490.0358\n",
      "Epoch 808/1000\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 88.5679 - val_loss: 410.5184\n",
      "Epoch 809/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 106.3815 - val_loss: 420.1792\n",
      "Epoch 810/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 91.0653 - val_loss: 536.2083\n",
      "Epoch 811/1000\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 92.6417 - val_loss: 437.3538\n",
      "Epoch 812/1000\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 91.6613 - val_loss: 430.3403\n",
      "Epoch 813/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 89.4743 - val_loss: 439.9542\n",
      "Epoch 814/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 108.0212 - val_loss: 500.5771\n",
      "Epoch 815/1000\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 78.6534 - val_loss: 386.7558\n",
      "Epoch 816/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 99.0544 - val_loss: 496.7022\n",
      "Epoch 817/1000\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 130.6494 - val_loss: 475.3625\n",
      "Epoch 818/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 115.5990 - val_loss: 748.1010\n",
      "Epoch 819/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 129.2587 - val_loss: 448.3618\n",
      "Epoch 820/1000\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 97.6999 - val_loss: 428.8643\n",
      "Epoch 821/1000\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 84.1636 - val_loss: 617.2590\n",
      "Epoch 822/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 102.5800 - val_loss: 386.9067\n",
      "Epoch 823/1000\n",
      "120/120 [==============================] - 0s 458us/sample - loss: 83.1949 - val_loss: 411.6047\n",
      "Epoch 824/1000\n",
      "120/120 [==============================] - 0s 455us/sample - loss: 83.6669 - val_loss: 570.2483\n",
      "Epoch 825/1000\n",
      "120/120 [==============================] - 0s 437us/sample - loss: 112.2121 - val_loss: 485.6544\n",
      "Epoch 826/1000\n",
      "120/120 [==============================] - 0s 450us/sample - loss: 108.4681 - val_loss: 452.6578\n",
      "Epoch 827/1000\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 97.6339 - val_loss: 421.6982\n",
      "Epoch 828/1000\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 91.1823 - val_loss: 478.7620\n",
      "Epoch 829/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 118.5008 - val_loss: 601.9301\n",
      "Epoch 830/1000\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 118.4455 - val_loss: 508.8055\n",
      "Epoch 831/1000\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 92.6187 - val_loss: 426.9851\n",
      "Epoch 832/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 90.4533 - val_loss: 437.6632\n",
      "Epoch 833/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 91.6210 - val_loss: 442.0366\n",
      "Epoch 834/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 82.4694 - val_loss: 431.4712\n",
      "Epoch 835/1000\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 92.4947 - val_loss: 428.0653\n",
      "Epoch 836/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 99.5097 - val_loss: 600.1702\n",
      "Epoch 837/1000\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 140.6500 - val_loss: 429.9532\n",
      "Epoch 838/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 147.9696 - val_loss: 746.8290\n",
      "Epoch 839/1000\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 124.0944 - val_loss: 452.3826\n",
      "Epoch 840/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 135.6887 - val_loss: 526.2247\n",
      "Epoch 841/1000\n",
      "120/120 [==============================] - 0s 473us/sample - loss: 105.5120 - val_loss: 746.9997\n",
      "Epoch 842/1000\n",
      "120/120 [==============================] - 0s 495us/sample - loss: 137.2527 - val_loss: 415.7920\n",
      "Epoch 843/1000\n",
      "120/120 [==============================] - 0s 557us/sample - loss: 92.3414 - val_loss: 470.8232\n",
      "Epoch 844/1000\n",
      "120/120 [==============================] - 0s 510us/sample - loss: 99.7797 - val_loss: 491.4673\n",
      "Epoch 845/1000\n",
      "120/120 [==============================] - 0s 441us/sample - loss: 84.0275 - val_loss: 429.3139\n",
      "Epoch 846/1000\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 80.1011 - val_loss: 433.5572\n",
      "Epoch 847/1000\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 88.5508 - val_loss: 469.6486\n",
      "Epoch 848/1000\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 97.7829 - val_loss: 474.6604\n",
      "Epoch 849/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 88.8560 - val_loss: 442.6780\n",
      "Epoch 850/1000\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 85.1443 - val_loss: 399.4945\n",
      "Epoch 851/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 98.3047 - val_loss: 424.3470\n",
      "Epoch 852/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 83.9555 - val_loss: 629.1603\n",
      "Epoch 853/1000\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 103.4079 - val_loss: 429.7847\n",
      "Epoch 854/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 68.9557 - val_loss: 455.3940\n",
      "Epoch 855/1000\n",
      "120/120 [==============================] - 0s 537us/sample - loss: 86.2530 - val_loss: 425.5782\n",
      "Epoch 856/1000\n",
      "120/120 [==============================] - 0s 497us/sample - loss: 78.5313 - val_loss: 400.9293\n",
      "Epoch 857/1000\n",
      "120/120 [==============================] - 0s 584us/sample - loss: 92.6682 - val_loss: 496.6221\n",
      "Epoch 858/1000\n",
      "120/120 [==============================] - 0s 465us/sample - loss: 96.6411 - val_loss: 396.0073\n",
      "Epoch 859/1000\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 92.1126 - val_loss: 489.6293\n",
      "Epoch 860/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 102.7150 - val_loss: 510.7616\n",
      "Epoch 861/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 117.9920 - val_loss: 624.2027\n",
      "Epoch 862/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 113.3816 - val_loss: 433.4342\n",
      "Epoch 863/1000\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 94.3302 - val_loss: 459.2333\n",
      "Epoch 864/1000\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 120.8423 - val_loss: 451.5259\n",
      "Epoch 865/1000\n",
      "120/120 [==============================] - 0s 419us/sample - loss: 113.2515 - val_loss: 491.2593\n",
      "Epoch 866/1000\n",
      "120/120 [==============================] - 0s 794us/sample - loss: 87.5379 - val_loss: 456.3874\n",
      "Epoch 867/1000\n",
      "120/120 [==============================] - 0s 428us/sample - loss: 98.7574 - val_loss: 418.8690\n",
      "Epoch 868/1000\n",
      "120/120 [==============================] - 0s 719us/sample - loss: 83.6796 - val_loss: 395.7359\n",
      "Epoch 869/1000\n",
      "120/120 [==============================] - 0s 617us/sample - loss: 81.5314 - val_loss: 624.7176\n",
      "Epoch 870/1000\n",
      "120/120 [==============================] - 0s 579us/sample - loss: 101.3784 - val_loss: 413.4159\n",
      "Epoch 871/1000\n",
      "120/120 [==============================] - 0s 459us/sample - loss: 104.9605 - val_loss: 537.6875\n",
      "Epoch 872/1000\n",
      "120/120 [==============================] - 0s 414us/sample - loss: 131.4308 - val_loss: 397.8548\n",
      "Epoch 873/1000\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 108.3301 - val_loss: 655.1292\n",
      "Epoch 874/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 131.2235 - val_loss: 531.8354\n",
      "Epoch 875/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 159.7507 - val_loss: 461.5370\n",
      "Epoch 876/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 226us/sample - loss: 145.8370 - val_loss: 435.8310\n",
      "Epoch 877/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 110.2143 - val_loss: 671.4852\n",
      "Epoch 878/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 131.1452 - val_loss: 553.5711\n",
      "Epoch 879/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 104.7895 - val_loss: 476.6648\n",
      "Epoch 880/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 85.6981 - val_loss: 453.2322\n",
      "Epoch 881/1000\n",
      "120/120 [==============================] - 0s 477us/sample - loss: 82.4330 - val_loss: 427.3854\n",
      "Epoch 882/1000\n",
      "120/120 [==============================] - 0s 527us/sample - loss: 97.6828 - val_loss: 411.9811\n",
      "Epoch 883/1000\n",
      "120/120 [==============================] - 0s 518us/sample - loss: 103.1490 - val_loss: 442.5779\n",
      "Epoch 884/1000\n",
      "120/120 [==============================] - 0s 455us/sample - loss: 105.1189 - val_loss: 448.4962\n",
      "Epoch 885/1000\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 97.4754 - val_loss: 394.1315\n",
      "Epoch 886/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 82.2820 - val_loss: 711.4365\n",
      "Epoch 887/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 152.4437 - val_loss: 448.8887\n",
      "Epoch 888/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 110.0325 - val_loss: 452.7369\n",
      "Epoch 889/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 97.2485 - val_loss: 462.0252\n",
      "Epoch 890/1000\n",
      "120/120 [==============================] - 0s 721us/sample - loss: 83.1263 - val_loss: 447.2322\n",
      "Epoch 891/1000\n",
      "120/120 [==============================] - 0s 678us/sample - loss: 86.0890 - val_loss: 399.8325\n",
      "Epoch 892/1000\n",
      "120/120 [==============================] - 0s 774us/sample - loss: 77.8607 - val_loss: 427.6545\n",
      "Epoch 893/1000\n",
      "120/120 [==============================] - 0s 672us/sample - loss: 85.9299 - val_loss: 469.5618\n",
      "Epoch 894/1000\n",
      "120/120 [==============================] - 0s 555us/sample - loss: 103.6627 - val_loss: 423.0865\n",
      "Epoch 895/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 72.0521 - val_loss: 396.0936\n",
      "Epoch 896/1000\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 91.9057 - val_loss: 409.8073\n",
      "Epoch 897/1000\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 87.0177 - val_loss: 432.3734\n",
      "Epoch 898/1000\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 82.8885 - val_loss: 546.7327\n",
      "Epoch 899/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 154.5014 - val_loss: 560.6061\n",
      "Epoch 900/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 140.0787 - val_loss: 558.1742\n",
      "Epoch 901/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 189.0869 - val_loss: 538.7986\n",
      "Epoch 902/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 141.5784 - val_loss: 452.8561\n",
      "Epoch 903/1000\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 144.8633 - val_loss: 580.5250\n",
      "Epoch 904/1000\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 174.6284 - val_loss: 741.1575\n",
      "Epoch 905/1000\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 161.7564 - val_loss: 652.6917\n",
      "Epoch 906/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 141.3426 - val_loss: 397.7599\n",
      "Epoch 907/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 109.8119 - val_loss: 401.9977\n",
      "Epoch 908/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 122.0844 - val_loss: 637.6502\n",
      "Epoch 909/1000\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 103.9176 - val_loss: 396.4441\n",
      "Epoch 910/1000\n",
      "120/120 [==============================] - 0s 582us/sample - loss: 82.3080 - val_loss: 432.9963\n",
      "Epoch 911/1000\n",
      "120/120 [==============================] - 0s 686us/sample - loss: 92.0289 - val_loss: 427.3340\n",
      "Epoch 912/1000\n",
      "120/120 [==============================] - 0s 529us/sample - loss: 92.2549 - val_loss: 535.6248\n",
      "Epoch 913/1000\n",
      "120/120 [==============================] - 0s 363us/sample - loss: 95.9043 - val_loss: 409.0615\n",
      "Epoch 914/1000\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 89.4769 - val_loss: 483.9200\n",
      "Epoch 915/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 100.5259 - val_loss: 416.1471\n",
      "Epoch 916/1000\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 81.6665 - val_loss: 470.6022\n",
      "Epoch 917/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 113.7420 - val_loss: 416.4670\n",
      "Epoch 918/1000\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 95.9317 - val_loss: 414.8822\n",
      "Epoch 919/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 76.6512 - val_loss: 566.8123\n",
      "Epoch 920/1000\n",
      "120/120 [==============================] - 0s 496us/sample - loss: 128.3069 - val_loss: 471.5615\n",
      "Epoch 921/1000\n",
      "120/120 [==============================] - 0s 522us/sample - loss: 167.9325 - val_loss: 501.9834\n",
      "Epoch 922/1000\n",
      "120/120 [==============================] - 0s 567us/sample - loss: 141.6697 - val_loss: 515.3759\n",
      "Epoch 923/1000\n",
      "120/120 [==============================] - 0s 483us/sample - loss: 128.8396 - val_loss: 561.8900\n",
      "Epoch 924/1000\n",
      "120/120 [==============================] - 0s 434us/sample - loss: 127.3940 - val_loss: 527.6193\n",
      "Epoch 925/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 111.3063 - val_loss: 404.7639\n",
      "Epoch 926/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 126.5919 - val_loss: 1026.7728\n",
      "Epoch 927/1000\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 163.1283 - val_loss: 434.5180\n",
      "Epoch 928/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 131.4921 - val_loss: 620.9921\n",
      "Epoch 929/1000\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 142.3382 - val_loss: 461.0318\n",
      "Epoch 930/1000\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 91.4603 - val_loss: 459.8358\n",
      "Epoch 931/1000\n",
      "120/120 [==============================] - 0s 416us/sample - loss: 82.0835 - val_loss: 431.9648\n",
      "Epoch 932/1000\n",
      "120/120 [==============================] - 0s 463us/sample - loss: 88.3349 - val_loss: 445.8668\n",
      "Epoch 933/1000\n",
      "120/120 [==============================] - 0s 736us/sample - loss: 97.9174 - val_loss: 506.3660\n",
      "Epoch 934/1000\n",
      "120/120 [==============================] - 0s 591us/sample - loss: 104.4055 - val_loss: 475.1476\n",
      "Epoch 935/1000\n",
      "120/120 [==============================] - 0s 595us/sample - loss: 104.2054 - val_loss: 421.7138\n",
      "Epoch 936/1000\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 112.0221 - val_loss: 381.3561\n",
      "Epoch 937/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 103.5406 - val_loss: 437.9807\n",
      "Epoch 938/1000\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 103.2335 - val_loss: 463.1162\n",
      "Epoch 939/1000\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 100.6959 - val_loss: 413.1380\n",
      "Epoch 940/1000\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 114.8116 - val_loss: 423.5860\n",
      "Epoch 941/1000\n",
      "120/120 [==============================] - 0s 301us/sample - loss: 112.4325 - val_loss: 487.8865\n",
      "Epoch 942/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 120.5877 - val_loss: 376.3519\n",
      "Epoch 943/1000\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 110.9521 - val_loss: 449.4231\n",
      "Epoch 944/1000\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 94.2640 - val_loss: 487.9647\n",
      "Epoch 945/1000\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 108.2711 - val_loss: 447.6613\n",
      "Epoch 946/1000\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 141.8775 - val_loss: 469.0663\n",
      "Epoch 947/1000\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 119.8470 - val_loss: 469.6266\n",
      "Epoch 948/1000\n",
      "120/120 [==============================] - 0s 496us/sample - loss: 101.5555 - val_loss: 429.2063\n",
      "Epoch 949/1000\n",
      "120/120 [==============================] - 0s 633us/sample - loss: 90.2017 - val_loss: 469.5859\n",
      "Epoch 950/1000\n",
      "120/120 [==============================] - 0s 605us/sample - loss: 94.8391 - val_loss: 449.4083\n",
      "Epoch 951/1000\n",
      "120/120 [==============================] - 0s 428us/sample - loss: 79.9087 - val_loss: 409.9935\n",
      "Epoch 952/1000\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 106.7850 - val_loss: 469.8053\n",
      "Epoch 953/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 157.0377 - val_loss: 437.9843\n",
      "Epoch 954/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 103.7238 - val_loss: 447.6534\n",
      "Epoch 955/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 127.3420 - val_loss: 485.6964\n",
      "Epoch 956/1000\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 119.6565 - val_loss: 545.0847\n",
      "Epoch 957/1000\n",
      "120/120 [==============================] - 0s 289us/sample - loss: 119.8603 - val_loss: 465.8836\n",
      "Epoch 958/1000\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 104.8154 - val_loss: 451.3065\n",
      "Epoch 959/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 92.0048 - val_loss: 429.2126\n",
      "Epoch 960/1000\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 86.1349 - val_loss: 425.8471\n",
      "Epoch 961/1000\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 81.1708 - val_loss: 431.6915\n",
      "Epoch 962/1000\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 97.6506 - val_loss: 392.2526\n",
      "Epoch 963/1000\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 86.7921 - val_loss: 637.2968\n",
      "Epoch 964/1000\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 139.9203 - val_loss: 633.2825\n",
      "Epoch 965/1000\n",
      "120/120 [==============================] - 0s 601us/sample - loss: 144.9384 - val_loss: 612.0513\n",
      "Epoch 966/1000\n",
      "120/120 [==============================] - 0s 585us/sample - loss: 165.1105 - val_loss: 442.3473\n",
      "Epoch 967/1000\n",
      "120/120 [==============================] - 0s 488us/sample - loss: 125.2125 - val_loss: 531.0648\n",
      "Epoch 968/1000\n",
      "120/120 [==============================] - 0s 545us/sample - loss: 148.9290 - val_loss: 686.2410\n",
      "Epoch 969/1000\n",
      "120/120 [==============================] - 0s 559us/sample - loss: 144.0068 - val_loss: 486.9859\n",
      "Epoch 970/1000\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 142.5561 - val_loss: 637.6124\n",
      "Epoch 971/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 112.3621 - val_loss: 435.7863\n",
      "Epoch 972/1000\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 99.7834 - val_loss: 408.8097\n",
      "Epoch 973/1000\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 89.1470 - val_loss: 428.8822\n",
      "Epoch 974/1000\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 95.5885 - val_loss: 377.6633\n",
      "Epoch 975/1000\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 75.3205 - val_loss: 450.2080\n",
      "Epoch 976/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 81.4722 - val_loss: 432.7631\n",
      "Epoch 977/1000\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 84.3238 - val_loss: 418.9102\n",
      "Epoch 978/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 77.3334 - val_loss: 365.3130\n",
      "Epoch 979/1000\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 90.7442 - val_loss: 494.2769\n",
      "Epoch 980/1000\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 110.6254 - val_loss: 477.6820\n",
      "Epoch 981/1000\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 123.0734 - val_loss: 540.1039\n",
      "Epoch 982/1000\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 103.2282 - val_loss: 580.1248\n",
      "Epoch 983/1000\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 132.1579 - val_loss: 424.8516\n",
      "Epoch 984/1000\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 129.0669 - val_loss: 630.1111\n",
      "Epoch 985/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 155.9024 - val_loss: 418.9371\n",
      "Epoch 986/1000\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 113.2252 - val_loss: 648.6909\n",
      "Epoch 987/1000\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 136.5302 - val_loss: 439.6381\n",
      "Epoch 988/1000\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 126.1365 - val_loss: 462.6832\n",
      "Epoch 989/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 145.2089 - val_loss: 450.2378\n",
      "Epoch 990/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 138.8593 - val_loss: 497.1863\n",
      "Epoch 991/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 149.9809 - val_loss: 843.3474\n",
      "Epoch 992/1000\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 173.7133 - val_loss: 597.3572\n",
      "Epoch 993/1000\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 182.4951 - val_loss: 655.0319\n",
      "Epoch 994/1000\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 205.8677 - val_loss: 527.2390\n",
      "Epoch 995/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 85.5811 - val_loss: 441.0728\n",
      "Epoch 996/1000\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 83.1096 - val_loss: 441.2167\n",
      "Epoch 997/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 82.7996 - val_loss: 385.9200\n",
      "Epoch 998/1000\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 86.6357 - val_loss: 395.4101\n",
      "Epoch 999/1000\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 80.4345 - val_loss: 413.1212\n",
      "Epoch 1000/1000\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 72.8460 - val_loss: 440.9646\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "# Parameters\n",
    "############\n",
    "\n",
    "hidden_1_size = 17\n",
    "hidden_2_size = 9\n",
    "\n",
    "training_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "l1_lambda = 0.00015\n",
    "\n",
    "# Model\n",
    "#######\n",
    "\n",
    "inputs = Input(shape=(window_size,))\n",
    "\n",
    "# Hidden layers\n",
    "\n",
    "hidden_output_1 = Dense(hidden_1_size, activation='relu', kernel_regularizer=l1(l1_lambda), bias_regularizer=l1(l1_lambda))(inputs)\n",
    "hidden_output_2 = Dense(hidden_2_size, activation='relu', kernel_regularizer=l1(l1_lambda), bias_regularizer=l1(l1_lambda))(hidden_output_1)\n",
    "\n",
    "# Prediction layer\n",
    "predictions = Dense(1, activation='linear')(hidden_output_2)\n",
    "\n",
    "\n",
    "# Full model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Optimizer\n",
    "####################\n",
    "\n",
    "optimizer = Adam(lr=learning_rate)\n",
    " \n",
    "\n",
    "# Compilation and fitting \n",
    "#########################\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(x=rolled_train_x, \n",
    "                    y=rolled_train_y,\n",
    "                    validation_data=(rolled_test_x,rolled_test_y),\n",
    "                    epochs=training_epochs,\n",
    "                    batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:41.892490Z",
     "start_time": "2020-05-27T17:05:41.753780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:42.040859Z",
     "start_time": "2020-05-27T17:05:41.893885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd5gT1drAf2c7vfe2NEEEBaWJitgolovtXsHu9RPrtaOoV8WCYi9X7GIvoKCgoEgVUXrvsPRd2i4LW1i2Jef7Y2aSSTJJJtlkS/b8nidPkpMzM2c22fOet5z3FVJKFAqFQlE9iavoASgUCoWi4lBCQKFQKKoxSggoFApFNUYJAYVCoajGKCGgUCgU1ZiEih5AIBo3bixTU1MrehgKhUJRpVi5cmWWlLKJnb6VWgikpqayYsWKih6GQqFQVCmEEHvs9lXmIIVCoajGKCGgUCgU1RglBBQKhaIaU6l9AgqFonpSUlJCeno6hYWFFT2USk1KSgqtW7cmMTEx7HMoIaBQKCod6enp1KlTh9TUVIQQFT2cSomUkiNHjpCenk779u3DPo8yBykUikpHYWEhjRo1UgIgAEIIGjVqVGZtSQkBhUJRKVECIDiR+BspIVAWsnfCjnkVPQqFQqEIm6BCQAiRIoRYJoRYK4TYKIR4Rm9vL4RYKoTYLoSYJIRI0tuT9fdp+ueppnM9prdvFUIMidZNlRtv94Ivr6joUSgUiihQu3btih5CuWBHEygCzpdSngb0BIYKIfoDLwFvSCk7A0eBW/X+twJHpZSdgDf0fgghugEjgFOAocC7Qoj4SN6MQqFQKEIjqBCQGvn620T9IYHzgR/09s+By/XXw/X36J9fIDTD1XDgOyllkZRyF5AG9I3IXSgUCkWUkFIyevRounfvTo8ePZg0aRIABw4cYODAgfTs2ZPu3bvz559/4nA4uPnmm11933jjjQoefXBshYjqK/aVQCdgArADOCalLNW7pAOt9NetgH0AUspSIUQO0EhvX2I6rfkY87VGAaMA2rZtG+LtKBSKWOOZnzeyaX9uRM/ZrWVdnr7sFFt9p06dypo1a1i7di1ZWVn06dOHgQMH8s033zBkyBCeeOIJHA4HBQUFrFmzhoyMDDZs2ADAsWPHIjruaGDLMSyldEgpewKt0VbvJ1t105+t3NUyQLv3tT6UUvaWUvZu0sRWEjyFQqGIGosWLWLkyJHEx8fTrFkzzj33XJYvX06fPn349NNPGTt2LOvXr6dOnTp06NCBnTt38p///IfffvuNunXrVvTwgxLSZjEp5TEhxAKgP1BfCJGgawOtgf16t3SgDZAuhEgA6gHZpnYD8zEKhUJhid0Ve7SQ0metCsDAgQNZuHAhM2bM4IYbbmD06NHceOONrF27llmzZjFhwgQmT57MxIkTy3nEoWEnOqiJEKK+/roGcCGwGZgPXK13uwmYpr+err9H/3ye1P6K04ERevRQe6AzsCxSN6JQKBTRYODAgUyaNAmHw0FmZiYLFy6kb9++7Nmzh6ZNm3Lbbbdx6623smrVKrKysnA6nVx11VU899xzrFq1qqKHHxQ7mkAL4HPdLxAHTJZS/iKE2AR8J4R4HlgNfKL3/wT4UgiRhqYBjACQUm4UQkwGNgGlwN1SSkdkb0ehUCgiyxVXXMHixYs57bTTEELw8ssv07x5cz7//HNeeeUVEhMTqV27Nl988QUZGRnccsstOJ1OAF588cUKHn1whD9VpzLQu3dvWamLyoytpz/nVOw4FIoYY/PmzZx8spXrUeGN1d9KCLFSStnbzvFqx7BCoVBUY5QQUCgUimqMEgIKhUJRjVFCQKFQKKoxSggoFApFNUYJAYVCoajGKCGgUCgU1RglBBQKhaKMBKo9sHv3brp3716OowkNJQQUCoWiGhNSAjmFQqEod34dAwfXR/aczXvAsPF+P3700Udp164dd911FwBjx45FCMHChQs5evQoJSUlPP/88wwfPjykyxYWFnLnnXeyYsUKEhISeP311znvvPPYuHEjt9xyC8XFxTidTqZMmULLli3517/+RXp6Og6HgyeffJJrrrmmTLdthRICCoVC4cWIESO4//77XUJg8uTJ/PbbbzzwwAPUrVuXrKws+vfvzz/+8Y+Qir1PmDABgPXr17NlyxYGDx7Mtm3beP/997nvvvu47rrrKC4uxuFwMHPmTFq2bMmMGTMAyMmJTnoaJQQUCkXlJsCKPVr06tWLw4cPs3//fjIzM2nQoAEtWrTggQceYOHChcTFxZGRkcGhQ4do3ry57fMuWrSI//znPwB07dqVdu3asW3bNs4880zGjRtHeno6V155JZ07d6ZHjx48/PDDPProo1x66aWcc845UblX5RNQKBQKC66++mp++OEHJk2axIgRI/j666/JzMxk5cqVrFmzhmbNmlFYWBjSOf0l7Lz22muZPn06NWrUYMiQIcybN4+TTjqJlStX0qNHDx577DGeffbZSNyWD0oTUCgUCgtGjBjBbbfdRlZWFn/88QeTJ0+madOmJCYmMn/+fPbs2RPyOQcOHMjXX3/N+eefz7Zt29i7dy9dunRh586ddOjQgXvvvZedO3eybt06unbtSsOGDbn++uupXbs2n332WeRvEiUEFAqFwpJTTjmFvLw8WrVqRYsWLbjuuuu47LLL6N27Nz179qRr164hn/Ouu+7ijjvuoEePHiQkJPDZZ5+RnJzMpEmT+Oqrr0hMTKR58+Y89dRTLF++nNGjRxMXF0diYiLvvfdeFO5S1RMoG6qegEIRFVQ9AfuoegKVgUosSBUKhSIQyhwUCaSEEMLEFApF7LF+/XpuuOEGj7bk5GSWLl1aQSOyhxICEUFpAgpFpJFShhSDX9H06NGDNWvWlOs1I2HOV+agSKDMQQpFRElJSeHIkSMRmeRiFSklR44cISUlpUznUZpARFA/VIUikrRu3Zr09HQyMzMreiiVmpSUFFq3bl2mcyghEAnUakWhiCiJiYm0b9++oodRLVDmoIighIBCoaiaKCGgUCgU1ZigQkAI0UYIMV8IsVkIsVEIcZ/ePlYIkSGEWKM/LjYd85gQIk0IsVUIMcTUPlRvSxNCjInOLVUAyhykUCiqKHZ8AqXAQ1LKVUKIOsBKIcRs/bM3pJSvmjsLIboBI4BTgJbAHCHESfrHE4CLgHRguRBiupRyUyRupGJRQkChUFRNgmoCUsoDUspV+us8YDPQKsAhw4HvpJRFUspdQBrQV3+kSSl3SimLge/0vtEhP1NL67Dzj6hdwoXSBBQKRRUlJJ+AECIV6AUYW+DuEUKsE0JMFEI00NtaAftMh6Xrbf7ao0OGnnNoybtRu4QbJQQUCkXVxLYQEELUBqYA90spc4H3gI5AT+AA8JrR1eJwGaDd+zqjhBArhBAryhQjXJ6rc6UJKBSKKootISCESEQTAF9LKacCSCkPSSkdUkon8BGauQe0FX4b0+Gtgf0B2j2QUn4opewtpezdpEmTUO+nglBCQKFQVE3sRAcJ4BNgs5TydVN7C1O3K4AN+uvpwAghRLIQoj3QGVgGLAc6CyHaCyGS0JzH0yNzGxWM0gQUCkUVxU500FnADcB6IYSRHelxYKQQoifaMng3cDuAlHKjEGIysAktsuhuKaUDQAhxDzALiAcmSik3RvBe/BDhBFSlxXBgLbTpY2pUQkChUFRNggoBKeUirGfSmQGOGQeMs2ifGei4yBKlifnX0bDyM/jPKtOllBBQKBRVk9jfMRzpVLR7l2jPpUWmRiUEFApF1ST2hUCkKT6uPSfWcLcpTUChUFRRYlcIRGtiLs7XnqtQsQuFQqHwR+wKARcRnqwNTcAsZJQmoFAoqijVQAhEGEex9iydpkYlBBQKRdVECYFwMQsBpQkoFIoqSgwLgShPzE5H+V1LoVAookQMCwGdaDlwlSagUChigNgXAtFCOoL3USgUikqOEgLhosxBCoUiBohdIRBtE40yBykUihggdoVAtFEhogqFIgZQQiBclCagUChiACUEwkX5BBQKRQwQw0Ig2j4BkxBQmoBCoaiixLAQiDLKJ6BQKGIAJQTCxak0AYVCUfWJXSFgTMzlsWNYaQIKhaKKErtCINqo6CCFQhEDVAMhECVNQEUHKRSKGKAaCIEooTQBhUIRA8SwEIjAxJy9Ew6s83N6p3W7QqFQVCESKnoAUacsjuG3e2nPY3N8P1P7BBQKRQwQw5pAlFE+AYVCEQPErhBQWUQVCoUiKEGFgBCijRBivhBisxBioxDiPr29oRBithBiu/7cQG8XQoi3hRBpQoh1QojTTee6Se+/XQhxU/RuC6KfNkLtE1AoFFUfO5pAKfCQlPJkoD9wtxCiGzAGmCul7AzM1d8DDAM6649RwHugCQ3gaaAf0Bd42hAcUcG1OlflJRUKhcIfQYWAlPKAlHKV/joP2Ay0AoYDn+vdPgcu118PB76QGkuA+kKIFsAQYLaUMltKeRSYDQyN6N14Djxqpwa8fAIKhUJRNQnJJyCESAV6AUuBZlLKA6AJCqCp3q0VsM90WLre5q/d+xqjhBArhBArMjMzQxmeJ6GGcEoJ81+AQ5ts9o8Rx3BhrtJkFIpqjG0hIISoDUwB7pdS5gbqatEmA7R7Nkj5oZSyt5Syd5MmTewOz86pA1N8HP54CT61qZzEgjkoPxPGt4GFr1b0SBQKRQVhSwgIIRLRBMDXUsqpevMh3cyD/nxYb08H2pgObw3sD9AeHYxJ2u4+AaNfabG9/rEQIpqn//k3TavYcSgUigrDTnSQAD4BNkspXzd9NB0wInxuAqaZ2m/Uo4T6Azm6uWgWMFgI0UB3CA/W26JDqKvzLTONA22ePwY0AVem1YodhkKhqDjs7Bg+C7gBWC+EWKO3PQ6MByYLIW4F9gL/1D+bCVwMpAEFwC0AUspsIcRzwHK937NSyuyI3IUVofoEpv6ffpyEIzvgwNrA/WNBEzDGLWJ3u4hCoQhMUCEgpVyE/7XiBRb9JXC3n3NNBCaGMsCwKC2GPX+Fd6x0wvtnQ0lB8H6u11VUCLjuQakCCkV1JTaXgIU5sPbb4P3SV0D6Sq9G6V8AmCf7WNgs5tpKoYSAQlFdic0EcnHx9vp9rCsy5gRxgVb1Hqv/WEggF+UNdQqFotITm5pAnFm22Zjg/K7wvT43+wFiwSfgiqCKzZ+BQqEITmz+95uFgNnU4XTAH69o5iIzHit5iwndmCw9NIEY8gkoIaBQVFti878/zo+Va9M0mP88zHnGs10GSQFhrPo9TECx4BMwooOUOUihqK5ULyFQlKc9O4o824OFkxqTv9OPEKiiMkD5BBQKRYwKAT+35dB3A8cne7YHSwbn0gScvm3aB/6PzT2gRSFVRqTaJ6BQVHdiMzrIA9Mq1yUEkjy72NUEwokOmtAPinKsS1RWNKGm1lAoFDFH9VoClupmoIQQhYAziDkokCZQ5DX5b5oGJYWBr1deqM1iCkW1p3oJAbMm4PSzqrcimDnIYTPp3J7FMPlG+P2/9vpHm5IT2rPSBBSKakv1FQJm57C3OcfbRi6DRAfZXdkX6Rm4j+621z+arPsevr1Ge62EgEJRbYl9IeCxT6BUe45LgFLTxO3jGPaaFIOZg0pP2BuLsZPZGEdFsuVn92vlGFYoqi2x/9/vMcHpk7t0BrDvex+DtWPYfHyJXSGQqB9bCYSAB0oTUCiqK7EvBIyJF9yTu9PhORF7CwHv3EPBNovZFgJ6MFZlEAJmE5gyBykU1ZbYFwKY8v4c12sWH94EGabsod6OYR9NwEgbYc4xZDqm1I9PwOkVRlqZhIAZZQ5SKKotsb9PwJi4F7wIq7/UXm/6SXu4+niHiNrwCZgncn+awLMNPa9RmXwCHihNQKGorlSDJaAuBLYFqGTp7Ri2Ex0Uqk/A6XALm8omBJQ5SKGotsS+EDAm3qRawfsYeKedsNwnYJrI/ZmDvK/hEgJB9iWUO0oIKBTVlWogBHRNILFmgD5BooOMCd+fOSjYZjOjj3EdR0nw/lHH7BiO/Z+BQqGwphr890tY/TXkHQjQxW6IqB9zkDNI2gmjv8u3UNnMQdXgZ6BQKCyJfcew0wHT7grcx1sIeO8gNiZ5f+Ygq+PzD/leozKZg1SIqEKhIJY1gasnas/F+cH7ek/Kpd71BowVvJ/NYt7moEVvwGtdvM7hrLyOYYVCUW2JXSHQ/Srtefvvwft6r+S9Hb1Wm8XME7m3EEmb63sNp8Oe7yAY+Zkw/wV7JqhAqNW/QqEgloVAKHhPzv7e2zUHWU2w0mkywZShFNkv98MfL8HuheGfA6puXWSFQhFRggoBIcREIcRhIcQGU9tYIUSGEGKN/rjY9NljQog0IcRWIcQQU/tQvS1NCDEm8rdSBuzWE5hym6mtDNFBZZmADS2l1Gb6aoVCoQiAHU3gM2CoRfsbUsqe+mMmgBCiGzACOEU/5l0hRLwQIh6YAAwDugEj9b6Vg2CTsjHJ56a728w1BEKNDso/CFNHhTZGAyP1RCRMSwqFotoTVAhIKRcC2TbPNxz4TkpZJKXcBaQBffVHmpRyp5SyGPhO71s5CBats+xjOHHUs83sPA6mSRh9zP3WTbI/PjOisqaeiDJF+cqEpVBEgbL4BO4RQqzTzUUN9LZWwD5Tn3S9zV+7D0KIUUKIFUKIFZmZmWUYXggEm8S3/Qo/3+/ZZt7w5eNDsJiszOagshBnyoRaXcjJgBdbwZL3KnokCkXMEa4QeA/oCPQEDgCv6e1WIScyQLtvo5QfSil7Syl7N2nSJMzh6XS73F4/O6vqgiOe782VyexMyE5nZEw41dEcZFRi2zy9QoehUMQiYQkBKeUhKaVDSukEPkIz94C2wm9j6toa2B+gPbpc9bG9fk4baRy8I34Mn4CIt2kOipAm4DIHVSMh4FovqLBWhSLShCUEhBAtTG+vAIzIoenACCFEshCiPdAZWAYsBzoLIdoLIZLQnMfRX9bFJwbvA+CwY1/3moCM6Jz4RJvRQc7I2LTjIiQElH1doVBgI22EEOJbYBDQWAiRDjwNDBJC9ERbou0GbgeQUm4UQkwGNgGlwN1SajOkEOIeYBYQD0yUUm6M+N2Ei8Mi3DI+2dPk451fxzgmLtGmOcgRmdV7dTQHKRSKqBFUCEgpR1o0fxKg/zhgnEX7TGBmSKMrL4qP+7Yl14ECsxDwYw6KT7S3qvZnDtr1J7TuA4kp9sbqKpFZxuigqrRj2Pj7VqUxKxRVhNjfMXzHouB9lkzwbUuuE/gYRzjmIC8hkLkNPr8Ufn0k+PEG0TAHVXrTkPIJKBTRIvaFQPMecPI/Avc5sNa3Lbm253vvidJlDkoIPzrI2HuQuSX48QYuc1AEnMwGkTyXQqGoUsS+EAA4/7++bddPgX9+7v+Y5Lqe73fOd782F6iJT4xsdFBpMRzb6//zSGwWy94JW2eYxqaEgEJRXakeQiDBwt4el+Df5NO6j68QMGMWAnFlMAdZmTlmPABv9oDCHOvzRMIctNJb+FVyc5DyCSgUUaN6CYHEmpCkT/x1WkJKPc9+SXW0OgQ3ToP4AD7zJC9NwM6EXHzcXr/tc9z9rTCEQFmig4xzGFR6TaCSCymFogoT+5XFwL1fID4R6reFg+uhYQfI3uHZ73FTgrj4JC0Sx2qCjDPtP4hLsHCsWkxaX10Jff7PenzmFa4R/eN93V0LIW1OZMxBPuUzK7sQ0FGagEIRcaqHEEiuCy16wqDHoNXpcGyfttKv18b/MfFJkFQbinJ9P4sz/dnsRgeBJnzMGMLDo9RjnG8bwOeXac9nP6h/XoaJu6oKAYVCEXGqhxCIT4Db/3C/r91Ue06qCe3P1VaY3k7iuq2gQSr8421Y9CZs+sn9mVkI2N0sBvYmW3+agOtzfTVcFgvJHy95vq/sQqDSh7AqFFWX6iEEAnHjNO3Z29QwaAyc8yAk1dK0Bw8hYLKpxydCSYG9a/kUpHf6Xtt46Ve7cHWwd01b46rsk6zaJ6BQRIvq4RgOhBDWtub4RE0AAPS7091+0jAvTSDB/kraW2OwmuhFkFTRLk0gkkKgkmsCBsonoFBEHCUE7JCQBBc9p73udIGvTyBcc5DVcUHTQkRDE6giQkChUEQcZQ6yS/87NWfxGTfDFtNGKytNwN8q3dwvPskkBMwrXP21PyHgqlMc5sS94CXftspuDorE+I7ugY1TodtwLTJMoVAASgjYJz4R+t+hvU7RN5KJOHcYaWmxZt7xt8kLPFf+cYnWE30wTcAwIYW7WWzBCxbnrOyaQAR8Am+dqj0v/RAe2lzmESkUsYISAuFgbDKLS9ScxCeOwfM2qqCZfQAlx2HNV9prq30C/mocGMJBOrWQ05qNoG7L0MbvM65KLgRcMiACPoFAQlqhqIYoIRAOhhCo3Uzbg5Bns0ia9+p988++fUQQc5BRzEY64P2zNaHx9FF71/dHZRcCkUQ5lxUKD5RjOBxS6mvPxzOh/UD7x9nZ5WtlDjL7IJZ9oH+uC5RITODVSQgoFAoPlBAIh9NGaM8nDQ5ed8CMMdm27uu/j0sImOoeT7nN4lzVKTookvsElCagUJhR5qBwqNcaHt2tlaBMX2b/OKdDMx817x7gOOHua2A1SfvbTHY8S0+UV9P6cyuqSnRQJEw5yhykUHigNIFwqdFAm2gTatg/Rjr0lX6AicjKJ2AlBPxFB73SET4ZbH9M/s6vUFix5D3YMa+iR6GIIEoTKCuJIQgBp0NPOeG98tYn/qJ8OLhOe+0wmYMsNYEAE/eh9f4/s6SSawJlxUPTUZpAmfhtjPY8VkVZxQpKEygrIQmBEs/dxt7MeNDUN4gmUJZ6Aj7nquSagGt8YU7g5vtTMkCh8EAJgbLiKlhTC0bvDNzXUaLXA/CaiQwTUI6pnkEwn4BZUygrVUUIhGvP97g/JQUUCjNKCJQVQxOIi4dEizKWZhzFvlW9wF2zwJzn3yOc1MJcU1oU0jADUlWEQCSOLzwGJ0z7KvavhvSVZTu/QlGFUUKgrBhCoMO5wZ3EzlJrIXBgrclfYPQNstLf8ENo4wxEWSfZzb9ATkbwfqVFcHBDGBcoo8/C+/6y0tyvPxwEH59ftvMrFFWYoEJACDFRCHFYCLHB1NZQCDFbCLFdf26gtwshxNtCiDQhxDohxOmmY27S+28XQtwUndupAJJqwV1L4MqPIM6GTBUWQgA0LcH8WVnKR4aKXSFweItvOKmUMOk6exFJvzwI758FeQfDHF8kzEGAQ9eiVn7u21ehsMuxvZC9q6JHUWbsaAKfAUO92sYAc6WUnYG5+nuAYUBn/TEKeA80oQE8DfQD+gJPG4IjJmh6sn0HsZUmANoPasdc9/twEsQ5w1zR2xEC7w6Ad/vBqi+8rqmPMzfd9xhv9i7WnouPhze+sH0CXoLLoafeWPlpeOdTKADe7AFv96zoUZSZoEJASrkQyPZqHg4Yy6jPgctN7V9IjSVAfSFEC2AIMFtKmS2lPArMxlewxAY3Tg/8eaFFzWKA72/2fB+O4zfUiCEjpbKdzWKHN2rP+1d7toeisYQ7mUfSJwDw5RWa8DqeVbbzKhQxQLg+gWZSygMA+rNetJdWwD5Tv3S9zV+7D0KIUUKIFUKIFZmZmWEOrwLpcC7ctVQrQtPjX76f5/sxhRze5Pk+fTmMraeZYOwSqgnpnpVw2rWh7Rj2KYwTjhAI8WdX1h3NVkKkMEfL/RSr/PEy7F1S0aNQVAEi7Ri2WuLJAO2+jVJ+KKXsLaXs3aSJjfTMlZGmXeGse6FNgBxBwdg4VXve9qv9Y0I1IcXFaeapUFbaZRICRvqHcIVAhHwCxjlLC8M7X1Vg/jiYOKSiR6GoAoQrBA7pZh7058N6ezrQxtSvNbA/QHtskxAkZNQOoUzs4TiTjaI4dvFelYcyPldVtBBX9pH2CWiN4Z0rVFZ/Da90Ct9fo1BEmXCFwHTAiPC5CZhmar9RjxLqD+To5qJZwGAhRAPdITxYb4ttelwNfSwygIYymYVSBCUc23nIQsBr0g8meLbPMdVACLM0Zlmjg6wm/HArs4XKz/dpZqdgIb/hsm4y7Pk7OudWVAvshIh+CywGuggh0oUQtwLjgYuEENuBi/T3ADOBnUAa8BFwF4CUMht4DliuP57V22KbxBpwyau+7aGshP9+237fYBOy1XX9CQGnw3r1Goo5aO9S+PoqmPuM57EhC6so+AQimXbDH3mH3JN/tDK1Tr0NPh3m2VbZs8IqKhVBE8hJKUf6+egCi74SuNvPeSYCE0MancIeORlQu6nnhOy9+Qz8C4HSIpg3Ds6+X9v3APBsQ0g9B27+xescIQiBE7qcP5IGXwx3O8XD1gTCJJQsrJHktZMCjyFalJeWo4gJ1I7hiiDSOe3f6AYzH/b85//xDt9+VhORiIPiPFj4Msz3KkK/+8/g5wgkBFwFchywc0HgcWz8EabdY30eo//WGeGtcjMs0kKU52Y8KB/NwyCcezu0ERZPiPxYFJWemBYCi3ccYctBP3H55cmIb+CqT6BNP+jxz+hcY+VnMOdp9/v1k7XVvRmricgskBa/E/w63qtMO0LAOwrHaqX6/c2w+kvr85iFRjir3O+u9W0r79VyWTWBfcvhh3/bczCHIwTePxtmPR76cYoqT0wLgZEfLWHomxarWQtKHU5Sx8zgrTnbQ7qG02ljZdr1Es1JfOvvcNXHIZ0/JDZM8Xy/8GXP9+aJaNBj2nOo4ZrOUph0Pez+y/3eH4aAKTnhfxw+5/cTzmm+vtNZ9mibonJeHJRV6Hw7Qvt+02bbuFYYQsCOkFK+hpgkpoVAKBQ7tH+CCQvSAvaTUvLxnzs5lFvImCnr6PD4zNAv1ndUOEMsO+Z/9KYna8+hCoHCHNj8M3yru4r8TTjH9sGcsdprb00g0IRTYpFSwkMTKIH3BsALLW0P2ZIFL5bt+FCJ1Ia3byw2IPrrGw6BhGtlzzZb1XGUQEH5x8soIaBT4pD6c+Af+t7sAp6fsZnbv1zJd8u1TdDZx4tDu1iTLvBIOSWeyjVtx/jLFGlkTP52/BNbZrhfuyZ96fXeiyn/Bwf1Cmc+mkCAVXFRnm+befLZPhsyN0PpCd9+oWBOJ10elHkCDSHMtSz+jkeHj9AAACAASURBVEDjVEIguky5FV5uX+6XVUJAp1Sf/IMt2AxhkXuihAY1EwHYfSTEhGjgWWHsmq/g8vet+923LvRzm/nhVvfrv//nfm1kLPXWBKwmFrOT2Y59H9yZOiGwOch75VmU73su85eyIkIBZunLI3Meu5TVMRxKYaGoCYEImYNKTkCJxW5tpwPWTqq+0U2b9O1W5Wx2U0JAp9SObR9wrcgExOupo0tKw1ghGaGYACdfBj1Hwhk3Q6eLPPs1aAeDdQdvg1T4byY8ccj+dcwrXvM/eHJt7dlbCJQW+U7MJQWen4P7h2pnwjEfD+7zr/gUnm0A+YchPklrKzZpApum6bmTTN9NVU31UOYwV4s2hx8NtExCIMAEXNZ7KCnUEiiOaw6vnuT7+YqJ8OMold21nCPXYrbQfDCzTrj9pVsGuHDYFiAmrFJKX/aW9jy2nvZ86jXac4N22nPTUyAhKbTrOIrhu+tgi1e8f8OO2rO3EHAU+Y7N/KN0TcLBhIDpL1R4zPMjYzJZrjvJ8w5ompGj2HOFOPlG7XmwKcrJagXpzfEsbYNaj38GL/RTXpR1dRuSJlCGa0XTHPT+2XBED7wostgJn68vbqp7dldHCcQnltvlYlYIFIW4Oi912JvIXanMTLZ0+1qEFxc9a114/pFd2o8gSV+tuyRPGPsLsndoD2/qtNDP6a0JFEOc6Qd4yCu7qVkTOLwFPr8s9DEZk4mRVjs+GZfQsEqvsOgN0/Vt+ALmPqPVPfCufVCRRMMn4FcTKIMQCHRsWe/hSJDIu3ATDMYa0Uox4oeYFQKFJaH9I5TaDDl06j9U83Rs91gfzrrPur1mQ6+GAELgnpWQtz+0yfi0kaYqaF7nLC301DZ+9hqj2b6/dYbnZ+ZdyvtX+b++YXIwVoPF+e6oIKvVbYFpZWintnJldGBGY9dzVMxBIWgC0++FxJowbLx1/9Avrj9HeDNlVcNRvuagmBS5h/MKGf7OXyEdU2JTE7DSGOxqEWFTQxcKRhEYM407QY0Qi7SZJw8fc1Cx14/Q696MVBBIa38CQLGXD8AbYzIxnMDmzVyGEPAnWHP2WbeDFllUfJxKOYmUWQhYRQf5mSwiKQQm3wSrv7L+bNXnsPS98K/lc20LW6sVh7fAaydrviQzjlKtYNBLqZAV2n4fv+QdhH3LInMuu5SzJhCTQiA5IZ6MY75mA4dT8s687eQW+v6R/U3kOSdKPGz+hunHvCgP2xxkl/bnwMhJcN5/3W03/Aj/N097nVIvtPOZV9M+E3mhZw0DK3MVaM5e7wynRkSQtyPYG8PkYGgE+SZHtyGgwvlHeLE1vN4t9OP8UZhjT/OwQ7Q1gY0/mfpG0Cew6SeYdrf/MUQUm5rA4nc07Xer1x6dI9thxzwtGOL3JyMzpA/OhU8uCt4vkoRTVbAMxKQQqFcjkfo1fR0rt32xgld/38aLMzf7fLZgq3tVsXLPUd6aowmL0575nddnb3V95tBXqIII+ARCoctQTzNNx/Oh9Rna6/pt4fqp9s9l/pF5C4GVn8H0/7jf+xMC4GmrB3fK6GKLME8zgTZqGatYW2Yfi7974bHI5GbauQDGt/XN0Gnw2aXw6cX2zxcVx7BJCJjLfpo1ATuO9GDXAe03E+3QxbL4vrwJx6+wabrv785Ielie9SCUJhAZjHQOyQnuW5y3RZvoj+T72lJfm73N9fqq9/7mjTnbOHBM+wf6bYO7JKSn2Uh77agMBUM6XaCVtbRDs1Pcr72Tqy33SmtxwiuyJxBG5FCwQvL7lroFhjeGgLKzGvI7sUZgEvliuPZslXwOtOR6e0IwOUbFMVxi/bn57zKuWWiX8fc3XTe5EvpavL9n0/tQBcmuP2HyDTDnGevPrXayRxwjOKJ890nErBB4dFhXABrXTvb5rNhmOGhWvrYqqFfDrVXsPaKZOsy/Mbv+hKjTtCuccoX/zy95Ha6eCOc94W7r6S9TuM4hfddvi57Br2/k4wkmBMC/U/OnOwJ/bnWOfctgsykENpyVpNmcEg3KvFkslOggL5/AlP8L4Tr+NIGiymMOslNfItTfgLGf5tge68+tNjGGw7rJ8Ofr1p8Z2osyB0WG6/q144perYiP8/0x2N0T8NS0DQDUr6mZYUodTh6Z4ruDN6x9AtHi0jfhll9h8PPa+9vmwY3ToHVf6H4ldL8K4k0mnm7D3a/rtvZ/3kQb8fZG3pNg5iCAnfMDn8dhwxxkTIKfXASTrnO3r/ws+LHezHgw9GNCIdo+AelHEwBY/71n+hBvzKYks7DyPk+khYCj1NNcFao5KFA/u+agXx6Abb8H72eVziQcpt7mLrLkjQgQJh1FYlYIAMTHCcsJuqRUaxs+4S+GvfUn0o+tc0emtqJtUU+rFXy82P1P4bFPIMSNaVGlRn1oNwDOvAeePAKtzoAOg+D/ZgePIjJ2Ef/rCy2M1MyQcb79vZn7DGTv8r/SMTPpev+f5e6Ht04Lfo5I7qwsOBK5c1kRdXOQCatJ5PtbNNPWb49pmxHNTn3zvZvH6XF+EXkh8PXVXuYqm5qAvzWXeXzBhEDJCfj5fm2X8jf/dE/A/vwekRIC/shKc/+e0+ZG91pexLQQSIgTrhj+w3nuFcfe7AI2ZOSwdt8xNh/IDbqxzNAcCoqtJ51ycQyHihCeK347tOylPddtBVd45TJqdYb79Zi9cIeFPTxjJbzd07oYTSiYV/WBiFTkTnkQSb+RcS4Pc5DpN2gVZ75vCXx0Pix5V3ufZ049Ypp0nQ7YMV/TxryFiXmSPR4BoWlog6VF2iNkx7BXP7MWE0wIrP/eKz2FcS4//8uLXi/bd1ha7Fm0J/eA+/XxLHjH9P/lT1OIEjEtBAxNoNThpO84t3Q9mFvIpf9b5Hp/KDdwBMXkFensOXKc40UmTcD0eaUyB4WATy2EYS9pPgPzhG9FSj1o3j16Azu6214/OyajimBsPS2+3kxZVtHeq1Nj8vTnE7DjT/E32RXnw5eXa/ULvDUN8z2s+MTGNWzyamctEsuFTZ/Aca99Ah7mK/0cX13tjuJa9pG2UMna7ltwKZgmsOUX35BUAzv+ggNrPIv2fDvC/fq9s4IfH0ViWggkxAnyi0rZdijwl7QvW9tT0KNVPS7p0cKyz2X/W8TxIvcKSwj376XSOIZDYMa6A3R4fCa7s0xO3KQ6ms/A30rsuilwzsPlM0A7vN1L27VaHkgJU2+HmY8E7mek3d7k5Wi26xg+tAn2/O3Z5l328asrtWfzJG1e/dsSAn4wtKvDWwILAX+/kbQ5sGex9vrEMVj+SfDQ0sIcLbIsVE1g7rOQvVNLP1Ja5CkEDE0gbbY7imvmw5o29NVV7tBP9wHBr+dv/8vPNn6DPqGnJgHmM5byJaaFwOaDeRSWOHndFP5pRcYx7ct9cPBJ1EmxNqHkFpby4+oM13vz6j+UENG7v1nF8Amh7WaOBj+t0e5ly0GTrTPOz8+hdnPtufOFcIGNTTjGJjZvApXWHPFN8PNaserz8I4LheIC2DEX1n0Hyz7w/Xz3X9rqPyfDupQl2NcE3jvTd2/C+sm+/V7v5jmRlBRA5lb47fHQ91h47Hw0HRvIHORv0vzqKvh0qPb65/s0h7u/MFvfQWlPu/+yb246tg/Gt4GJQ+Dj803D8/otm+83oJAMY0F3JHAhKsD3b1mJ8iNVnpFEgZV7tLCvOZvd9s/e7Xydo49O0cIgG9ZMonayfzv6Z3/vdr3ecjCPE3p+olA0gRnrDrB23zG/zujywnBmJ1hET7m4Y5G2U/nhrf77WNGki3W7lRbR4Tx4eLtWgrOy4C3Uv/mXO9md1eeGYNi7OMA5yxAiauUAzs2AXX+435ec0BytSyb4D3P0GI+X09fAEALC67rOUv+CY+6z1tcwhFSo6b+3/QqvdNDMN1ZYjcMc4QTWO+HdH/qeM5g5KBB2BLy3n8a4Xp5FWvhGnUMfQxmIaSHw0GDfnOVDuzf3279j09rU9tIEAmmmBXq0UDg+gYo2IRnXT0yIg8YWud0BmvfQdir742ZTArlTR2j9L3rOHWUE8M/P4Yaf4N7V1tE8/e+E2k2110NfCvEuooT3qs3b0f39jV799Ql+9tP+z1kWn4Bf278+ztrNtOyqxv4MO6UzPcJLTQLKnKXV/H2lzfG8B/PE/+drfi6i/8YP++7Qt+7u9T8x04bp0V/iRG8h4F3YyP8g3GMxirx488OtMOMh93s7lgAfrUq/zq+j/Y+hnIhpIXDXoE5c3tOzFm3HprWZfPuZAEy8ubervUmdZGonJ9C8rhYOelqb+qx+8iLq1/BMPzHuCl+HaGZe6A7K9RkW+dTLESPi6c9tmfDvWXD7wtBPkno2PL4fHk6DKz/QNIezdPvof1bBnYvhlMuh43la8jur0EVzcZ2TBodxJzZpGiSnkLnugFW4qHkC3Pyz+/XYetpuU4DcdP/nP56phSTaTePg9BeqacJwEKfUg33LQwtzNa9Ml5l2ibvMQcLzutt+C2zWOXHUd5y5uvnUmMzjg9XCCLGwUyC8V2/mDYxWKztXPiv93PuWuutZeLPhB8+d9YH8PcUFWj4jH/+KfoyVJhAsAWOEKZMQEELsFkKsF0KsEUKs0NsaCiFmCyG2688N9HYhhHhbCJEmhFgnhDg9EjcQjKvO0DZAndO5MQCdm9amb/uG7B5/Ceee1JR7zuvElDsH8MfoQQC0aVgTgB6t6tKgVhIvXNHD43xW5qKlu/z/8+UWlvDY1HXkF3mugq96728/R5QPRljrx4t2aamrW9iIy7ciqRbUbuLb3qgjNPOaeK1WTHVNQjpe392dUANGW9RAKAvDJwT+vPSEewJ4/WTfzwOtJK0KpHjz+5NaSKK3w9gf5jQFwXaQJtcN3bloaALLPvJMGGg2m3gL7Z/uwC8vpXqmHXc64dhezz41GwUekz9tSUpY8JIWceXtJPeHjyYQLKmhl5ZqJfCm3uaum+1xbAAhMONBLbNplpdf0rje8UzfY8olRYWbSGgC50kpe0opjWX1GGCulLIzMFd/DzAM6Kw/RgERzEHrn3M6N2Hb88P45KY+zH3oXFo3qOn6LD5O8PCQLpzRrgE1k7TJfUDHRrx0VQ8ev1ibCIb1aMGlp7ojhhLj43hrhDuFQoOaiRzKLfJr4//gjx18u2wfXy2xYactRwx/SbnSsqdWItPgoa2e6bETdCEgBNRq7Hu8v7rI/rj0DRigaybNbIS0Fub43z06/R571/SH6x/bZuSLOewwkCNTxIeeRRa0Cb602NfkYmQMFSL0vPYbf3S/tvIDBPveAm3UWvCCJkDNYZaBCFUIuAStPgZ/qU9++LdvWyBN4MBa7dk7464hBKx211clTcAPwwEjZONz4HJT+xdSYwlQXwhhHY8ZYZIS4khKiKNjk9pB+wohuKZPW5dQABh3eQ9a1Euhb/uGDD2lucd5UhvX4kSJg/yiUhZsPeyTksJYcVfmvQRD3wzDFBQOcfFw7xr3+zpe/hkjY6nxD1xfjx2/4y9NM3hkp2a2umeF/2uccqX7de9/w4XPwBMH7ZXlnDNW2z0aDYyEeT+Ock8MgTAX0gmURqBRR3spPbxxlMC6Sf4/P3EU1n4b2jkN3w74ak7pK9zmIX9YaVsnjvr6ZOzkefI2PWWZI3gsBLGhzbnivv1MxFbaSvZOzU9ghSFcvEusGtqDlbAxBHQ5UVYhIIHfhRArhRCj9LZmUsoDAPqz8ctoBZgrgqTrbR4IIUYJIVYIIVZkZlqoShVAvZqJLH7sAibffiZxccIjoVzPNvUBmLZmPzd/upw352hqX05BibYZyxT67K0thBshtHJPNst3Zwfv6AdvQeURJhpthNAEwUiLCcjwDwzSlcc7FsH9G7SNabUaaykxWpymTXx3L7c+/7mPeE4AcXHBJ0kjBDaaBc7NDtcPBkJ+pmZayN4FBzdofoVMk8nAvGEukDlIxGnVvULFURxcu1nuJzrHH+a041leEWUfXxD8eCuz2szRvmG3dkqMLvtACx81mGpKomflu3Gt1A1NwI8Q8BcOuuEHLYJs0ZuaNmVERhlaXIHX/6ujRNuL4S/PVjmahMpaXvIsKeV+IURTYLYQYkuAvlZ6sM8sKKX8EPgQoHfv3pVy+dyqvntS+VfvNnz6127+3qGt3CbM38GurOPMXH+QW89uz85M7UsWCJ/0EkWlTlISLQrOB+Gq97RQxN3jwwurDLX0ZsRp2F57eBOfCGNNE0FKPf+mjiZeEU0N2kObvtC4iyY4AjlJH07TKqQd3Q1N9QpVdiappDpQHCGB+d1ISPcjyECzIc8ZqwmIgOagOE/nul2MamHRwl8dhkB4T5TgWz0sFN4MYVe7kTJdSti7NLjWYsWOeTBHjxBb/RVc8aE7XNf799jiNDi0wfcc8Una911cEHrFwDApkxCQUu7Xnw8LIX4E+gKHhBAtpJQHdHOP8S2mA21Mh7cGAqQ2rLzExQmG92xJs7opnNSsDgAz17sdc8brTxbtcrW99NsWvl7q6RcoKglPCJSVwpJKlPAuEtw2H1qZ4gzqNNMe/qjdRHsY+xnqtoaBo2HhK5792p0Ne9zpRSImACCwAABt57GdTVYiLrzJYttvoR8D1n8nA6tVcpt+WqSNHazqM5RXWmVjQt45P3CG20B875Uq5MdR7tfHvMqi+hPctZtDzt7gPowIErY5SAhRSwhRx3gNDAY2ANMB469xE2AE204HbtSjhPoDOYbZqCry1ohePH7xyZapqv2RftRTjU0/FtoXLaUkdcyM4B2DUFRawZpApHgyC57K9hQAgeh7u5YWw5u4ODj/v5BSX9vQ1u5saDsAbpoOt852Z1TtcxvUa6P5KC59A/4dJAVx01MCf+6PlHr+BUCb/p7vhXBrS616Q99RcMbN2h6OC8fCNWVc8SfV8Xw/0BTXXq8NQQnW59QRgT/fW05RdDv87HL3x1n3h9Y/z2u9u2MuTLHwI9TT07n/9lh4KdHDoCw+gWbAIiHEWmAZMENK+RswHrhICLEduEh/DzAT2AmkAR8Bd5Xh2pWWUQMtisH74ZK3FwXvZCJYDiS7GJpAh8ZhmBEqE/GJmrPZLhe/rCXI88eYPVpajFtmwL9/1c7dpq+WUfXBzVqCvQd0H0Xvf0PbfvCYbl/uPBhOGgqj/sBl+RxwD1zwlPa6YUff653zsCZYGnWGIS+4241srlZcOwl6/Mv9vvFJbrtyh0Fw8Stw2VvaHo6zH4CTL4P7fGtg2KY4D677QXtdr60WwXXuo3DTL9DrhuDHG8590GpkX+pVknTwc9bHBfqeyos2/fyHKqfUtX8e83dfqyk06uS/7yWvas9ps2H9D/avUQbCNgdJKXcCPsHlUsojgI+BVWpe0LvDvV5lpn7NRI4VlPDLf85mV1Zwh86Ajo34e0foqXiHRCiKx/AJ1PHaCKcIQN2W1u3JdbS6Dea03U8d0VaWnS7UVuq9btCc04vf1XZg//6klvJhwD1uU46U8Pc7cMZNmr145wKtfdjL8Osj2m7sf8/SzAhXfqit/ms1gTPvhjV63qWWfqq/NWinTcDzn/f9rN8d2vgOrIVpFuuyntdD54s0zcLYS3KeHqaZejac85Bm787aqm2g8t5la96Nfu5oze7/ywPuNnNE0fB3tdDJVqdr92sVjumPGg20SKKmp8Dhjf77XT/VnYAPNE3vh39Dzj7fvg3aW4cqg7Y3w+CCp33TPw+4F/5+W3t9+XswUd8I+dBWeMOPhnjn31rp1wapmr+qSVf/9xFByuoYVgBzHjwXp1PStG6K5WbE5IQ4j5oF5g1nuYUl1E0JPhnnFkbONmqYg+r6SZanCBHvug1x8drEaWBMdIMe1Z6v/lSbNM22fCHgIVN6hbE5Wlhly9PhtBGQVNut9QjhXjEC9LkVGnfWNAF/nH2/Zmte/4OWymPTT5qm0FjPU5Ohh93GJWgmpOLjmmZjRFqlnu17TqNmheGDST0Hln2oCS2Ai1/1HVPNhtq9jTU5/Ed+Bz/dqZVGTbKIdBr0uLZPAKD3rVoa657XwZqvtbb713tqHOu+18az6gutboCZTl7r09Z94IoP4LOLfa/bvIdvG0DnIe7vt/NgOOdBXyEw+DlNCJzzkKYxGsTFad+F8TcCTdtIX+Gu/W04yMPdwBkiahaIAOY6xl2be6qJn97Sh3M7N+Gzv3fz7C+b9D51+H2Ttl38YE6hLSGQcdRu7pPgGOagQMnyKhu/rNtPvRqJnNPZYndyVaNWI6g1IHi/1vr+y2CbweLitdQcgYhPhH/8T3uAb4qOk/8Bq7+Gqz7y3NAXCkJAv9thoT75973N/VkTr13Y//ifVrwIoMsweHS37/kueErLUXTuI24BuvRD7dnYfdygvacAADhV3+vRIFXTwPrcBh+cA/11Q0THC7Rkfx0GaWNOPcvt8L5+iiY89q+GHlfr57tG21Pxj/9pWpOx0rt1jlbX2x/mSLdOF2kmHtD8NmYhUKOhZ44uwxke7DuNEFVnFqgixMcJtjw3lK5PatEXrevXIC5OcJq+nwCgf8dGZB0v5pule3nypw1M0nMZBeJgkMI3oZBxTBMo7U0+ASmlR8nMysY932hZIsMNi1UEoWZDrQRpJBi93ev9Tk0ImTndT14eM+c8pD3M9L5Fi5zpf6c2yXexWMEb1G/rFnrmCfmGqb59z3tCewihmfHMXPmh9vCmTR/P43ct9F9Vb8Q37hKV3v9n3incr5usmYMMJ3GUiekEchVFSmI8dw7SnEEt9T0FyQnuP3XLejW481zt86W7svnJVKegxOF0TdJmDlsIgaPHw9tVuCvrOInxgj6pDU3XrdgtGevTc0gdM4PNB3KDd1ZULWo1Cs2RGoj4RM2ckpCsmcHqRijpgBAhlLW04NxH4OZfNIE3eqfv5wlJ2t/B4PH9Wh1wq/De9gPtCckIoTSBKPHIkC7cOagjtXSTS0qiWwg0r5fikcd/9A9r2ZtdwPLd2RzOLWLroTzWPHUR9Wu6d74ezvXNVNp73Bw2PTuE5ITQ9hocKyimfs0kerV1aydFpQ6SEipuTTB7k7a34tcNBzm5heeEUdG1FxQK29QKkiTPIKkWDBmnPSoYpQlECSGEl61fm/Q7NK5FSmI8CfFxdGqq5SAqcUhen72NP7dnsfWQpjJ+sdi9sazU4eQ1vTpa2rhhPDJU2+TkcEq6/Pe3kCfJwhInKYlx1K+ZxLPDNWeU2XFdERh1HPILfZOW5Vq0KRSKyKCEQDlhbCprptcrALj7PIvYcZ2P/3SrlH9sc+dQSoiP80hbAbA/JzR/QWGJgxRdezDMVHaEQHGpMyqr8j7j5vDCTC3jyPEi3wk/p6BskVEZx04w5I2FbMjIYb+XqW3elkOcNX5exafSCJPJy/cx8sMlFT0MRRVGCYFyon3jWrxwRQ/euda9EeiKXq15dKj/6AJjwj1e7DlBtajnKQTmbTlM2mH7G8kKSxyudBWGKakoyCS4L7uAk/77a9B6zaFyvKjUoyhPocVu5qMFZcuo+NWSPWw9lMel/1vEgPGeO0Of/GkjGcdOcCiCjvfy5JEp61i8M/Q9JwqFgRIC5ci1/drSyBROCnDLWak+/Xq3a0BuYSk/rztAt6d+Y4NehezCk7V8OH1SPZ1JT/60gQtf/8PnPFaUOJwcyCl0+SjsagJGJbSf11qne3KGkSr7WEExpzw9K2i/sgqB+AAOv2I9o2pxBZvDykqpo2qPX1FxKCFQwVglkDPqIN/77WoKih38vHY/dVIS+PgmLW5cCEHf9g19jgNYsPUwb8zehpSSLxbvJtsrguiRH9ax5WCeywmcrAuDYJOgsRO6RpJvLMG3y/bS4fGZQaOVShxOHpi0xqW17Mv2jYKysjYdM5mDpJR8uHAHaYeDJ3MrKC7lRLGDOK/8TqljZrjGatx3noUZqipRWE5CbP7Wwzyv73dRxAZKCFQC3r/+DNo1qsmPdw3grkEdueWs9gw8yb0p6kBOIXleztEPbzjD5zybD+Ry86fLeWvudtbsO8ZT0zYy+nt3AZOiUgc/6uGohgPWMAetz8jhuo+XcExfdb84czMdH5/pOnbtPi3V7oniUp74cb3rPcBT07QMjPuO+ibE+ystyxX2uXF/Lj+uzuCBSVphmcN5viaYUosSlMdMmsCPqzN4YeYW7vxqlU8/M4UlDro9NYvzX1tgqQmM/XkjT/y4npwTmoCxckhXNnZlHWfKSus6xt4+jcO5hbYEZajc8ulyPl60q1IXSVKEhgoRrQQM7d7ctfrv1VYz9Zzetj4LTQ5h75V//ZpJfPN//bj2Y3ea3mFvuTeqXPGuln1xR6bbV7DVVDzmmD75Geag//6kTeS/bTjIiL5t+WCh5pgucThJjI9zmaR2Hylg95G9zFh/gDVPabtOjfnAvGLPLyrF4ZRcp49vwcODeGGGlhbBSFux54iv0DhRbOUTcJ/3cz1qKlBIt9MpXZv1DuQU+hTRMc45bY3btOVdA7oycvmEv8g5UcIVvVr5aDfeQuDM8fNwOGXUNtdl5Rd5BDkoqi5KCFRSbhnQnqPHi7nrvE44paS5xT/cgE6NeXjwSbz6u39n7e4jBXyyaBdbDuR6JK1r21DL0eK9x8A7R9HfO47QpkEN9ucU0rV5HVcVsgLTZB0vBA6kh+3+tGd+91gtDnp1geu14X9Iy/R1Zp+wcFCbNQFDA6lfw72HYvLyfezJPs6oczqy6UAurRt4Os73ZvsKm9wTnvd5rIwRSFYczi3EKbV9IZHApbUUl/qkGvEWAtFeqR/MKVRCIEZQQqCSUq9mIs8MD14Z6Z7zOzNqYEfmbz1MQXEpD0zyrV/7nJcN9z/nd+LSU7WsmMmJnhbBF2Zu4YKT3QVZbpq4jJsHpALw8OAu/N8XWqKx4lInD01ey5OX6jUVHLiifIpKHQEnoT1HCsgpKPGprwCwZGc2Dqf0qNNw7EQJrerX8NhJwcyOSwAAEslJREFUvWx3NofzCmlaJ4VHpmipkpftymb57qMeEVgA09fup12jmrSol8KSnVpyLm9hlxFibQc7jPxoCTsyj1M7OYFvb+tPj9ZhFIS3IK9QEwJmram8CgUlxcdR7HByMLfQN4Wwosx8/OdOluzMdvn/ygPlE4gBkhLiGHJKc67o1ZqdL1zM1ueH8tWt/bihfzvL/jec2Y4uzbViIVY1BS54zTPS6LO/d1M7OYELu3lW65qyKp2ez852rd7fnLOdUoeT71dY263NvPjrZpdz9rTW9WhYy72y/3tHFoUlDl6fvY3h7yxixe6jNK7tWyj+942HPN4v330UgMUWabqb1knmu1FnUkfflLYz053yO7VRTUvTVFnZoV8jv6iUiX/tCtLbPnm6ADNrXv72OXhHDe3IzC9TJFTNZE1zvP3LlR77V2KRZbuyeWzqunLdsf78jM3M2XwoeMcIooRAjBEXJ0hOiOfszo0ZM6wr467ozsZnhvDilT14+rJu3DWoI01MYaoJ8XHMeXAgL191Ki9d5Zk694mL3ZkfLz1Vy9Ey6/6BPDzYq76vTn5RKZ2e+NXlXwjEpBX7WJ+Rw5W9WjHtnrNZ9eRF3HimJrRu+GQZXZ/8jbfnbmdteg4Zx04w+JTmrmNPaqbttP5u+V7XhGjmx9UZ1K+ZyPIn3InAGtXS7vkDC4d6m4Y12edlMioudXIk3zNVx5gp6/hk0S4Kiks5nFvI32lZQe/TwG4FOimlpV9k+yG3P2feFq1iq9m8t8PCtAaaye2bpXsBbU/GBa/9wcPf+2qLh/MKOfPFucxc71nsr7DE4RpPflGpx9j++9N6W/dksCEjhwEvzq0yezKu+XAx3y7bx6gvV3oIAqdTsmDr4bCEw8EAGzuz8n1Tw5QHSgjEMLWSE7iuXztqJScwsm9bbjmrPY8M7eqTLbRT0zr8q08brunTlt3jL2Hp4xfwwQ1ncNvADrx89ancf2FnXrxSExBdmtfhnvM789PdZzHnwXM5uUVdmtZJ5vs7/GdCvfqM1njPgcb/jzmi6PGLvdIN63RoUotr+rTh8p6aCevSU1sSJ2BDRi49xvqWeCwodtC7XQOa1HELOyMkdkDHxq57AbiiVyvaNqzp4zcY/cNaznh+Dr+s28+8LdrK7Lvl+3jul02cNX4efV+Yy7UfL3UJCmNi+HuHtWBICCAE9mUXuFbsszcd4mTT3hDQJuKsfPeq/+XftgKwfFc2ifHaeR+dst7D8W8w9M0/efzH9Rw9XsyE+VoN4OkWez0WbM3kQE4hd33tGXU1+I2FrvFsOZDrsZ9kX/YJxs3YZHuPwsRFu9ifU8jzMzbz4OQ1OJ2SbYc8x2zlxA+FUPZLTF+7n4cmuwVi2uF8l4CSUrp+o7M3HWKTKbHhpBX7uPnT5Yz8aAmpY2Z4+KzMHMkvYtyMTS7N68fV6fR/ca6PppqVX8T7f+xgqW6qhLL/HUJB+QQUPjSrm8IQfeX9r97WNWJ76qmxf73vHFca6pF92/Dtsn08dWk3khPjqF8jiVKnk+E9W/HqP0/jcF4h2w7mc/0n7oima/q4c8GnJMYz/Z6z+Mc7WsHx7eOGkRjvXqe00h2+UkKwNVjvVM9oqtFDurhe//OM1mTmFZGVX8TjF5/M9yv28fXSvaSOmcGpretxx7kdXZFDRgrr54a7q0GZo5UO5BTicEr6vjDX1VYnJYE/H/HMBT970yFG9j1G91b1PLSC9KMFnPPyfO67oDMPXHQSf+naxe8bD9K9VT0Kikvp9tQsj2R/oO0H2Xooj97tGrp2DO/NLqBL8zoe4bsG3yzby7sL3KUSzxo/jz8fOc8VZfTYVPeqfsnOIyTGC3q2aeASjpf+bxETrvWt5fzRn7s4vW0DzurcmGmrM7iuXzuKHU5SEuMpcTjZuD+XGonxdGleh2R9T4yx4XDqKi1cuWGtJEb0acPt53bktGc0ob78iQs5kHOCU1tr9/3DynQKSxxc78fECbAzM5/zX/uDf/VuzUODuwR1XN/7rfbd3jmoI52a1nZtuNw9/hIf8+CSndmc0lLz6RjJHA3/0jvz0vjvpd1cfTfuz2HB1kx2ZOYzdVUGZ7RrwNDuLfjsr92A5iv6+Z6zXT6ihyav9TGtnShxePz2o4kSAooyY2gWL155Ki9eearffk3rpNC0Tgq7XryYnVnH6dC4lo9Wcmrr+vz5yHkkxAuff4KLe7RgwvwdDOnejC7Na3PHV6toVjeZBy48ibzCUjYdyCW/qJTZmw5xjUl41UqKp01Dd8WqhPg47r2gs+v9sB4teHKaVpJwXXqOz2oYcH3uzaX/860TnVdYSs9nPXPzHzlezPAJmnC7rl9bbjkrlXfn73CF/r41dzv3XdDZlSxv1d5jrEs/5hKIq/dqE3uLeikcyCnk5k+XA3DzgFSe/kc3hr75J7fpTvvzuvgW3nll1laP9xnHTrAjM5/5Ww+T2qiWhyN/hJ6LaNkTnlW4rPZ1AGw9lMed+t9sxvoDLNmZzYZnhjB2+kZ+0Pc17B5/CXuzrUuvZh8v5t0FO2jXyP0d9Rk3B4ANzwyhdnKCy4R1ff92fLl4N09O28jn/+7LuSc14USxA4l0mckmr0hn8op0n/BYh1Oy58hxWjWo4RJAABe+/odP3xyv6LHP/t7FrWe318/juUr/eNEulxA4kl/Ele/+TVGpk9P0Sf7lWVu5qFtz1qa7tbtf1u+nR+t67D1SYOlbKSx22Co2FQmUEFCUO0IIOjap7fdz84Rt5pSW9Vz/rF2b17WMgS8oLiX7eDENdEfziv9eGHRF1bh2Mh/ecAajvlzpaktKiKNvakPaNqrpsqkDPH95d0b2bUtmXhH9X5xrdToXfVMbsmx3tk/710v38rV+zqmmWhIDxs8jUzcvLUrLYtE7vqalL2/t55EipFfb+qQ28nTuz9+aSbcWdT1MGFZc9IZnzerHL+7qSuQH8MXf2p6M09vWZ9XeYzzzsxZl9ut953jsSXlzjruIjLE6fmjyGmaZHPenPPWbTw4sb75Z5lvnNyuviALTHo4DOSdcAvmur1Zybb+2fPTnLprWSeay03zrQEspKSrV9roMenU++7JP0LNNfdZ4aUt7jrgFVInD6bLPf3/Hmfzz/cXsyz7Bsl3ZFJU6eHtemsexDWsl8ePqdH5df9BVMRBwTfo7M4/zySLPGgM79F3zA1+Z79E+/soejJm63jJUOlqIypyrvXfv3nLFihUVPQxFNSPtcB5tGtYkOSGe3MISflyVwRWntyI5Ic5jX8W2Q3nknCjhxZmbGdm3LVee3pr8olJW7M7mlVlb+ejG3kxdlcGUVem0aViDzLwith0Knujvgq5Nmauvag1SG9Xk5gGp3HyWtho9eryYEqeTJrWTEUJw51cr+XWDVpOhW4u6XNe/LX1SG1JU4iS1cU2X72T2AwOZtfGgz96SBy86ibvP6+SxS9zgi3/35caJy1zvd4+/hFkbD5J7ooTRP6yz+VfVqJEYH3CC69S0NimJcRw9XkLGsRP0aFXPlbcqGDWT4j32r5zVqRF/pWmmstNa1/NYiQeice1klxD4/YGBTF2Vwft/7CA+Trg0pppJ8ZzZoRF7sgtCSt44/soerE0/xrfL9vHK1ae6/n5dmtXhnWt7sf1wPnd9vYrf7j/Hp1RtKAghVkopbcWZKiGgUJQTTqckr7CUzQdzqZOSQIfGtVm+O5vOzWrTtE4Ke7MLOJhTSP8ODck9UUqxw0mfcXMY0acN46/yb2YDzdQhpSTBj9azck82aYfzXT6YkR8uYfHOI7Sol8LjF5/MoC5NqJOSyKHcQo7kF/PugjT+3J7FI0O7cF2/dlz57l+s2nuMt0b0ZHjPVq7zTl6+j5dnbeW7Uf1o37g2i9Ky+GrJHmbrK+L/O7s9U1alu/woy564gKy8YrKPFzN700GG9WjBsl3Z/JWWxfqMHL7+v370atuA1XuPuna9h8LNA1LJPVHioWH545vb+tG+cS3OfHGe3z5LHruA5vVSSB0zw+ez3eMv4aOFOxk3czMpiXE8NuxkaiUn8MbsbWTlF7mc6Pdf2NmlLb01oiftG9dymfkAbj+3A2P0gI0FWw+7TH2/3neOT4EluyghoFDECA6nRIBPmoiyUlzq5NiJYmonJ1DTIimgN9nHi/lze6aHAPBHqcPJDZ8so1vLujw8uAuJ8YKf1+2nTYOaPg57A6dTetzjiWIHIz9awpaDubRvXJtGtZK44cx25BSU8MiUdbx//Rk8NnUdg7s158HBJ7H5QC5fLt7Dq/88jfo1E3nul838se0we7MLXKVT1z49mMR4wX3frSFeCP53bS8S4+N4e+52pITth/PYl13g0hjaNqzJ/IcHER8n+G7ZXnZk5rM/p5AZ6w5w6akteOfa0zl6vJinpm/k9oEd6N7KvRmwsMTBkDcXcu/5nflHz5Y8NnU9u7OO881t/UlKiOP2L1cwa+MhVyizYbIsKnUw+vt1TF+7n1Na1uXne84O67tXQkChUCjQhOirv2/lun5tad3A2tfkTX5RKQu3ZTKse3OfwAXQ/E5J8XF+tS47FJU6OJxbRJM6yZaZhP/YlklivGBAx8Zhnb9SCwEhxFDgLSAe+FhKOd5fXyUEFAqFInRCEQLlullMCBEPTACGAd2AkUKIboGPUigUCkW0KO8dw32BNCnlTillMfAdMLycx6BQKBQKnfIWAq0AczBwut7mQggxSgixQgixIjMzthNUKRQKRUVT3kLAys3t4ZSQUn4opewtpezdpInvzkeFQqFQRI7yFgLpgDkZTWvAunK5QqFQKKJOeQuB5UBnIUR7IUQSMAKYXs5jUCgUCoVOueYOklKWCiHuAWahhYhOlFJaZ+ZSKBQKRdQp9wRyUsqZgG+CEoVCoVCUO5V6x7AQIhPYU4ZTNAbsl3+KHdR9Vy/UfVc/gt17OymlrciaSi0EyooQYoXdXXOxhLrv6oW67+pHJO9dlZdUKBSKaowSAgqFQlGNiXUh8GFFD6CCUPddvVD3Xf2I2L3HtE9AoVAoFIGJdU1AoVAoFAFQQkChUCiqMTEpBIQQQ4UQW4UQaUKIMRU9nkgihGgjhJgvhNgshNgohLhPb28ohJgthNiuPzfQ24UQ4m39b7FOCHF6xd5B2RBCxAshVgshftHftxdCLNXve5KejgQhRLL+Pk3/PLUix11WhBD1hRA/CCG26N/9mdXhOxdCPKD/zjcIIb4VQqTE4ncuhJgohDgshNhgagv5+xVC3KT33y6EuMnOtWNOCFSDwjWlwENSypOB/sDd+v2NAeZKKTsDc/X3oP0dOuuPUcB75T/kiHIfsNn0/iXgDf2+jwK36u23AkellJ2AN/R+VZm3gN+klF2B09D+BjH9nQshWgH3Ar2llN3RUs2MIDa/88+AoV5tIX2/QoiGwNNAP7TaLU8bgiMgUsqYegBnArNM7x8DHqvocUXxfqcBFwFbgRZ6Wwtgq/76A2Ckqb+rX1V7oGWdnQucD/yClpo8C0jw/u7R8lOdqb9O0PuJir6HMO+7LrDLe/yx/p3jrj/SUP8OfwGGxOp3DqQCG8L9foGRwAemdo9+/h4xpwlgo3BNrKCru72ApUAzKeUBAP25qd4tlv4ebwKPAP/f3hm82BxFcfxzikZGMaxGFryNLVYTFkKzmMRmdorwD9jKyl62NmQhWWCSbCywJlNCiDcRI8yUjLIa+Vrc8xuv6XneezO83r3nU6/37rmnfr9zv6/O7557+92f3t4AfJX0w9uNsS3E7f1z7t+P1IBZ4JKXwi6Y2SCZay7pA3AWeAd8JGk4SRmaQ+f6dqV7jkngrwfX5ICZrQFuACclfWvl2sTWd+NhZgeAGUmTjeYmrmqjr99YAewAzkvaDnznd2mgGVnE7qWMQ8AWYCMwSCqFLCZHzVvxpzi7ij/HJJD9wTVmtpKUAK5ImnDzZzMb9v5hYMbtuYzHLuCgmb0lnU29lzQzWGdm1dtwG2NbiNv71wJf/ucNLyPTwLSkB96+TkoKuWu+H3gjaVbSPDAB7KQMzaFzfbvSPcckkPXBNWZmwEXghaRzDV23gGo3wFHSWkFlP+I7CkaAuWqK2U9IOiVpk6TNJE3vSToM3AfG3W1x3NV4jLt/Xz4VSvoEvDezrW7aBzwnc81JZaARM1vt//sq7uw1dzrV9w4wamZDPosadVtrer0Y8o8WWMaAV8AUcLrX97PMse0mTfGeAI/9M0aqfd4FXvv3evc30m6pKeApaadFz+NY4hjsAW777xrwEKgD14ABt6/ydt37a72+7yXGvA145LrfBIZK0Bw4A7wEngGXgYEcNQeuktY95klP9Ce60Rc47vHXgWPtXDteGxEEQVAwOZaDgiAIgjaJJBAEQVAwkQSCIAgKJpJAEARBwUQSCIIgKJhIAkEQBAUTSSAIgqBgfgEixs37lz4z+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"][20:], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"][20:], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:42.045478Z",
     "start_time": "2020-05-27T17:05:42.042270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum for the val_loss is at epoch: 977\n"
     ]
    }
   ],
   "source": [
    "print(\"The minimum for the val_loss is at epoch:\",np.array(history.history[\"val_loss\"]).argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And let's check the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:42.349868Z",
     "start_time": "2020-05-27T17:05:42.046867Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alatus/anaconda3/envs/10_days_AI/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "\n",
    "train_predictions = model.predict(rolled_train_x)\n",
    "test_predictions  = model.predict(rolled_test_x)\n",
    "\n",
    "\n",
    "out_layer_result_train = pd.Series(train_predictions.flatten())\n",
    "out_layer_result_test = pd.Series(test_predictions.flatten())\n",
    "\n",
    "idx = train_data.index[10:]\n",
    "idx = list(idx)\n",
    "idx.append(train_data.index[-1]+1)\n",
    "\n",
    "# Don't ask why this index shit is necessary :-(\n",
    "\n",
    "out_layer_result_train.index = pd.Index(idx)\n",
    "\n",
    "out_layer_result_test.index =test_data.index[1:] \n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.plot(train_data[\"#Passengers\"], label=\"Train data\", color=\"black\")\n",
    "plt.plot(out_layer_result_train, label=\"Train prediction\", color=\"purple\")\n",
    "plt.plot(out_layer_result_test, label=\"Predictions\", color=\"orange\")\n",
    "plt.plot(test_data[\"#Passengers\"], label=\"Test data\", color=\"blue\")\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.annotate('train first window ends', xy=(10, 140), xytext=(10, 210),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05),)\n",
    "ax.annotate('test first window ends', xy=(130, 340), xytext=(122, 270),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05),)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this absurdly small dataset and a ridiculously small NN we reached quite a nice result!\n",
    "\n",
    "But what if we look into more complex data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1XwzXqbCv5_Rx1za2K-nWuKLX_ucNho79\" width=35%>\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1vpyYQQuvmrqVLrfn8EnNmpZQ4n1co5Js\" width=35%>\n",
    "\n",
    "[source](https://www.researchgate.net/publication/3421369_Analysis_of_the_predictive_ability_of_time_delay_neural_networks_applied_to_the_SP_500_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basicrnn\"></a>\n",
    "# Basic recurrence \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Our unquestioned assumption (that even caused some headache in the prior data preparation case) is that for every neural model the dimensionality of the input has to be fixed, or only small deviations were allowed (for example in ConvNets we could use some padding, but not too much).\n",
    "\n",
    "What if my data is not of uniform length, dynamically sized - for example because it comes from a (time) series of non-fixed or unknown length?\n",
    "\n",
    "Or as an alternative formulation of this: From  prior knowledge we know, that just as in case of ConvNets for spatial invariance, we have a time seris, that implies that has a temporal structure we would like to learn.\n",
    "\n",
    "As defined before, we interpret our data as time series in the form of $\\{x_{t_0}, x_{t_1}, x_{t_2} ... x_{t_n}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of recurrent networks - \"classic\" or \"vanilla\" RNN\n",
    "\n",
    "We would like to define a neural network architecture, that in case of an input data point  $x_{t}$ can take into account the effect of prior datapoints without providing those as explicit inputs (as in the feedforward case), but as **(hidden) state**, using the activations of the NN itslef.\n",
    "\n",
    "Till this point we only used the activation for backpropagation, but now we'll use it also for something else.\n",
    "\n",
    "**Basic idea:**\n",
    "\n",
    "<a href=\"https://cdn-images-1.medium.com/max/1400/1*lQ4izz9ZbhKYD8NClZpsmQ.png\"><img src=\"https://drive.google.com/uc?export=view&id=197zCScRaBJypUb0giZzBh_0plHAOzlYJ\"></a>\n",
    "\n",
    "As a naive solution we could store the activations at $x_{t_-1}$ for all neurons and use a common $\\lambda$ \"dampening factor\" before adding them to the activations arising at $x_{t}$\n",
    "\n",
    "$$ f(x_t) = \\sigma(w x_t +\\lambda a_{t-1} + b)$$ \n",
    "\n",
    "This is not a complete recurrent network, but something along that direction (it's worth trying whether it works :-)\n",
    "\n",
    "But if we have a complete neural architecture with weight matrices, why shouldn't we do this in a more clever way?\n",
    "\n",
    "### Elman network\n",
    "\n",
    "The first real recurrent network:\n",
    "\n",
    "[Elman 1990](https://crl.ucsd.edu/~elman/Papers/fsit.pdf): \n",
    "Jeffrey L. Elman: Finding structure in time, Cognitive Science 14, p179-p211\n",
    "<a href=\"https://cdn-images-1.medium.com/max/1400/1*E6OMkLY8vbPdJ7b5R27FQA.jpeg\"><img src=\"https://drive.google.com/uc?export=view&id=17s60w9qBrwdrazopSAIPHjQ6ttiBgtTn\"></a>\n",
    "\n",
    "**The general notation for recurrent networks:**\n",
    "\n",
    "**$$h_t=\\sigma(Wx_t+Uh_{t-1})$$**\n",
    "\n",
    "\"Legend\":\n",
    "\n",
    "|Symbol| Meaning|\n",
    "|:---|:---|\n",
    "|$h_t$| \"hidden state\" at time $t$ |\n",
    "|$\\sigma$| activation function (typically sigmoid or tanh)|\n",
    "|$x_t$| input at time $t$ |\n",
    "|$W$| input to hidden weigth matrix|\n",
    "|$U$| hidden to hidden weigth matrix|\n",
    "|$h_{t-1}$| \"hidden state\" at time $t-1$ |\n",
    "\n",
    "\n",
    "**In this model we learn two weigth matrices $W$ and $U$.**\n",
    "\n",
    "Summary  [here](https://medium.com/lingvo-masino/introduction-to-recurrent-neural-network-d77a3fe2c56c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through time (BPTT)\n",
    "\n",
    "Question: How can we teach recurrent neural networks?\n",
    "\n",
    "Luckily enough, the gradient based methods we have learned are appropriate for this - only with a slight modification.\n",
    "\n",
    "### \"Unrolling\"\n",
    "\n",
    "In order to understand the gradient calculation of recurrent nets we can imagine RNN-s as deep feedforward neural nets \"unrolled\" in time.\n",
    "\n",
    "<a href=\"https://cdn-images-1.medium.com/max/1400/1*icP_8Q-I87k4Nyq0vdSl8A.png\"><img src=\"https://drive.google.com/uc?export=view&id=1BvAx4puhnqLu0rLM6-7ZV2qzSAFeQwO7\"></a>\n",
    "\n",
    "This is all the more useful, since traditionally we implement RNN-s in this \"unrolled\" way. Nowdays this is not necessarily true, or at least depends on the framework we utilize for training, since some of them solves it with iterations.\n",
    "\n",
    "In the \"unrolled\" network $U$ and $W$ parameters are the same, so we can understand this as a form of \"weight sharing\", just as in case of ConvNets, but not through space, but through time.\n",
    "\n",
    "Sensible description [here](https://machinelearningmastery.com/gentle-introduction-backpropagation-time/).\n",
    "\n",
    "### Problems with this approach\n",
    "\n",
    "In default case we calculate through the whole unrolled network for each and every timestep.\n",
    "\n",
    "This has quite serious implications:\n",
    "1. We have to \"see\" the whole data at once (very \"un-streaming like\")\n",
    "2. The number of calculated gradients - thus the amount of calculation - rises exponentially with the length of the dataset. This easily makes training intractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vanish\"></a>\n",
    "# Exploding and vanishing gradients\n",
    "\n",
    "(The hard problems)\n",
    "\n",
    "<a href=\"http://www.wildml.com/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png\"><img src=\"https://drive.google.com/uc?export=view&id=1IOC6XYlMRWRADH04Wh8iDVG1gXjTdeQA\" height=400 width=400></a>\n",
    "\n",
    "But the exploding computational need is just only one part of the problems with RNNs. Since they are extremely deep (in temporal sense) the gradient flow being propagated backward **\"vanishes\"** most of the time. In practice it results in the effect of signals far away in the past to disappear, as well as for convergence to grind to a halt.\n",
    "\n",
    "The flipside of this is the effect of **exploding gradients** where the gradient signal gets multiplied while moving backwards in time, getting practically infinite.\n",
    "\n",
    "These problems in practice are the same as in case of very deep feedforward networks.\n",
    "\n",
    "A good description can be found [here](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)\n",
    "\n",
    "### Suggested solutions\n",
    "\n",
    "#### Careful initialization\n",
    "\n",
    "Multiple scholars, amongst them one of Hinton's famous collaborators Quoc Le suggested a solution for RNN-s composed of ReLU nodes whereby we initialize the $U$ matrix with a scaled version of the identity matrix.\n",
    "\n",
    "<a href=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e1a4218ab6975ad1809415aa168ab6371b91bafc\"><a href=\"http://drive.google.com/uc?export=view&id=1RPPmiqzRPY6uU5n0FLFjPgLFFaV0zn-C\"><img src=\"https://drive.google.com/uc?export=view&id=1m99E3knMZ4gmvD1UHlZiX-4jruXPVxy-\" width=450></a></a>\n",
    "\n",
    "Details can be found [here](https://arxiv.org/abs/1504.00941)\n",
    "\n",
    "#### Gradient clipping\n",
    "\n",
    "As the name implies, it is a procedure whereby we artificially limit, \"clip\" the gradients during backprop. This is kind of  a\"brute force\" and semi-effective solution.\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1jK47FvUp7TcUlB2hC4rWDXoxfQNrqhRr\"><img src=\"https://drive.google.com/uc?export=view&id=1MBc8Vx-1Iyeh0TwKxdKiJd37kn9bOyF9\" heigth=300 width=300></a>\n",
    "\n",
    "[Pascanu and Mikolov 2012](https://arxiv.org/pdf/1211.5063.pdf)\n",
    "\n",
    "\n",
    "#### Teacher forcing\n",
    "\n",
    "Originally, the concept was to let the hidden state of the network \"travel\" in time, so that during the learning procedure the network can learn to memorize relevant data. In practice, if we always feed back the prediction of the network to itself, it can \"drift away\" from target.\n",
    "\n",
    "Here is where teacher forcing comes in:\n",
    "\n",
    "\"Teacher forcing works by using the **actual or expected output from the training dataset** at the current time step $y_t$ as input in the next time step $X_{t+1}$, **rather than the output generated by the network $\\hat{y_t}$**.\"\n",
    "\n",
    "<a href=\"http://cnyah.com/2017/11/01/professor-forcing/non-teacher-teacher-forcing.png\"><img src=\"https://drive.google.com/uc?export=view&id=1zfWZRKEeHRevsa7l3PABGknZIl5TwfOh\" width=45%></a>\n",
    "\n",
    "Though in practice this makes convergence easier, but as a tradeoff it also limits the usage of memory capacity. It can work well with unbounded memory capacity models (see later).\n",
    "\n",
    "For it to work it is necessary for the data to be defined in each step.\n",
    "\n",
    "It can be considered a move away from the Recursive Multi-step Forecast strategy.\n",
    "\n",
    "A good walkthrough of teacher forcing can be found [here](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/).\n",
    "\n",
    "#### Truncated BPTT\n",
    "\n",
    "The main idea of this approach is that we should not be so fanaticly following signals back into the past, we can do $k1$ steps of forward passes, then do backprop only for the last $k2$ steps back in time, that is:\n",
    "- We show $k1$ steps for the network\n",
    "- We unroll the net and calculate $k2$ steps back and aggregate gradients\n",
    "- We roll up the net and update weigths\n",
    "\n",
    "**Two parameters:**\n",
    "- $k1$ decides how many forward passes happen between backprops (kind of \"batch size\") and influences the speed of training (as well as many other factors, **for the newest research in regard to batch size see: [Smith, Kindermans, Ying and Lee 2017](https://arxiv.org/abs/1711.00489)**\n",
    "- $k2$ influences the temporal depth of backprop. If too small, our \"window\" will not contain all relevant timesteps, if too big, gradients can vanish.\n",
    "\n",
    "A nice summary again [here](https://machinelearningmastery.com/gentle-introduction-backpropagation-time/).\n",
    "\n",
    "**Notice, that we could not effectively get rid of those ugly windows!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If someone would like to analyse a TensorFlow RNN implementation in detail, it can be done [here](https://www.kdnuggets.com/2017/04/build-recurrent-neural-network-tensorflow.html).\n",
    "\n",
    "##### Fair warning:\n",
    "\n",
    "Though BPTT would be a theoretically more sound solution, practically it is quite unfeasible. And event he truncated version is implemented sometimes in really strange ways, eg. not letting you control over $k1$ and $k2$ separately, so in practice, much of the potential of LSTM-s may get \"sabotaged\".\n",
    "\n",
    "For example you can read about the struggles with Truncated BPTT in Keras [here](https://machinelearningmastery.com/truncated-backpropagation-through-time-in-keras/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anticipated Reweighted Backpropagation through time (ARTBP)\n",
    "\n",
    "As we might have guessed, the Truncated BPTT approach gives no chance for gradients to flow from the really distant past - outside of the truncation window, so we have to come up with something.\n",
    "\n",
    "A recent approach is **Anticipated Reweighted Backpropagation through time**\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1AAS4b6-T1Cxl3l_U2DNpDcoUBa4z7jLJ\"><img src=\"https://drive.google.com/uc?export=view&id=1hqCEld-IFPF79PQm_f7jiko0qC0POcor\" heigth=900 width=900></a>\n",
    "\n",
    "\"Like truncated BPTT, ARTBP splits the initial sequence into subsequences, and only performs backpropagation through time on subsequences. However, contrary to the latter, it **does not split the sequence evenly**. The length of each subsequence is sampled according to a specific probability distribution. Then the backpropagation equation is modified by introducing a suitable reweighting factor at every step to ensure unbiasedness.\n",
    "\n",
    "In ARTBP, since random truncations are introduced, gradient computations flow from $t$ to $t'$ with a certain probability, decreasing with $t − t'$. To restore balance, ARTBP rescales gradient flows by their inverse probability. Informally, if a flow has a probability $p$ to occur, multiplication of the flow by $1/p$ restores balance on average.\"\n",
    "\n",
    "Full paper [here](https://arxiv.org/pdf/1705.08209.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small sidenote: [Echo state networks](http://www.columbia.edu/cu/biology/courses/w4070/Reading_List_Yuste/haas_04.pdf)\n",
    "\n",
    "Interestingly enough, all these struggles with keeping RNN learning stable proved so burdensome, that some even suggested to forego training the recurrent connections altogether in favor of a kind of carefully initialized random \"connectome\", that is basically realizing a form of random hashing. \n",
    "\n",
    "The main idea is: we take a randomly initialized neural system which may _not_ be ordered in layer structures. Inputs just \"perturb\" the inner state of these networks, we leave some \"settle time\" for it to get to a stable state, and use a learned one layer feedforward network to generate predictions (maybe with some \"skip\" connections from the input).\n",
    "\n",
    "<a href=\"http://www.simbrain.net/Documentation/docs/Images/ESNDiagram.png\"><img src=\"https://drive.google.com/uc?export=view&id=1UWsp0ne1yE_xNOHTdLig_KLewYcJekrP\" heigth=500 width=500></a>\n",
    "\n",
    "As a metaphor we can understand that this method has some resemblance to decomposition methods, since it builds up a kind of **\"reservoir\"** of oscillators (hence the alternative name \"reservoir computing\"), and the last layer learns only a weighting scheme over the decomposition produced by the oscillators.\n",
    "\n",
    "Formally the idea was never disproven to work, but the tuning of \"settle time\", or even more the fact that it was extremely hard to ensure that a diverse and stable set of oscillators are formed during random initialization made it unpopular (though much effort has been invested in solving these issues without a simple and general solution).\n",
    "\n",
    "The method has some deep connections with [Bolzmann machines](https://en.wikipedia.org/wiki/Boltzmann_machine), but those are out of scope for this training.\n",
    "\n",
    "Interestingly ESN-s were nearly forgotten, but in 2017 they have found their way into some interesting physics applications modeling chaotic processes like [this](https://arxiv.org/abs/1710.07313)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lstm\"></a>\n",
    "# Long short-term memory networks (LSTM)\n",
    "\n",
    "Get ready to be Schmidhubered! :-)\n",
    "\n",
    "<a href=\"https://www.xing.com/img/custom/content/klartext/asset_images/images/000/157/804/x137/image.png?1453288186\"><img src=\"https://drive.google.com/uc?export=view&id=1Ea5cmpxJnHZmZTPNO2DwVr7rfxMAw_wi\"></a>\n",
    "\n",
    "Or more famously [Hochreiter and Schmidhuber 1997](http://www.bioinf.jku.at/publications/older/2604.pdf), in which the heroes are strongly inspired by human short term memory, and would like to create a network which can store signals for arbitrary, but learned length of time, enabling it to effectively infinitely \"memorize\" them.\n",
    "\n",
    "(The joke term \"to be Schmidhubered\" comes from the fact that Prof. Schmidhuber has a long time feud with the Hinton group, and he tries to diminish the importance of their findings, claiming that others - amongst them he-  invented key methods before the \"deep learning conspiracy\". Disturbingly he is sometimes even right. see [this](http://people.idsia.ch/~juergen/deep-learning-conspiracy.html) :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "**Gold standard explanation: [Colah's Blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)** The personal blog of the researcher Chris Olah.\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\"><img src=\"https://drive.google.com/uc?export=view&id=1UOtmNeaimbcn3H7CBSeIUfOcjRaubXgY\" heigth=300 width=600></a>\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "Cell state \"travels\" through the process.\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png\"><img src=\"https://drive.google.com/uc?export=view&id=1IQEqkYz9ThTT1p_9EnO1NJ8xVLQwRsDv\"></a>\n",
    "\n",
    "\"Gates\" are to be understood as combinations of non-linearities (sigmoid or tanh) and pointwise operations (addition or multiplication).\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png\"><img src=\"https://drive.google.com/uc?export=view&id=1tUFbRRllulugrK5OBmPGBVidOnqUIMWF\"></a>\n",
    "\n",
    "**Some help: Let us imagine if a vector gets multiplied pointwise with something between 0 and 1, this is equivalent to \"deleting\" (0) or \"leaving intact\" (1) some parts of the data.**\n",
    "\n",
    "### 1. step: What would we like to \"forget\"?\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png\"><img src=\"https://drive.google.com/uc?export=view&id=1J1_LbATvWLASY4OJsJ95txk9SCWjeYHR\"></a>\n",
    "\n",
    "### 2. step: What and where would we like to store?\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png\"><img src=\"https://drive.google.com/uc?export=view&id=1ZpIjdziGKlIacF4M7GpO9GRvxVPxGK7j\"></a>\n",
    "\n",
    "### 3. step: Update the cell state!\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png\"><img src=\"https://drive.google.com/uc?export=view&id=1jjM4MSIqgqNIz69K4jQUZtVjzTskezF_\"></a>\n",
    "\n",
    "### 4. step: Choose and produce the output!\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png\"><img src=\"https://drive.google.com/uc?export=view&id=1_gjSEe6CW1yc_QTCPhGEqM5Bst3D0SId\"></a>\n",
    "\n",
    "#### Alternative explanation [here](http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/)\n",
    "\n",
    "This may be worth reading through, since it shows in detail each vector's dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Animated illustration\n",
    "\n",
    "<a href=\"https://miro.medium.com/max/1425/1*GjehOa513_BgpDDP6Vkw2Q.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1w42nZqQKTl8Mqsc0PTTOk0GAyvNizixi\" width=75%></a>\n",
    "<a href=\"https://miro.medium.com/max/1425/1*TTmYy7Sy8uUXxUXfzmoKbA.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1pPO0OsgGRjJsjTCDSTJanmZMc_k7zKqn\" width=75%></a>\n",
    "<a href=\"https://miro.medium.com/max/1425/1*S0rXIeO_VoUVOyrYHckUWg.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1T5USGg1LHTFkWQcTVulrcfmH3GjbMWcm\" width=75%></a>\n",
    "<a href=\"https://miro.medium.com/max/1425/1*VOXRGhOShoWWks6ouoDN3Q.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1hsXLmHrT6pKG1iVr9Ccav4HrU7woBFuW\" width=75%></a>\n",
    "\n",
    "[source](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties\n",
    "\n",
    "- \"Unreasonably effective\" Andrej Karpathy's famous blogpost [here](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "\n",
    "- Not jsut effective, but \"Turing complete\"\n",
    "\n",
    "Based on this Jann LeCun (the pioneer of \"backpropaganda\" and big name in ConvNets) talks not just about \"deep learning\", but \"differentiable computing\". LSTM blocks combined - amongst themselves or ConvNets, seq2seq models or memory networks (see later) are making this position more and more plausible.)\n",
    "\n",
    "- It's inner state can effectively summarize long sequences of signals\n",
    "\n",
    "We can imagine it that way, as the final hidden state of activation of an LSTM at the end of a sequence is the dense vector representation summarizing the totality of singals for that sequence. This is a _huge_ advantage for us (for sequence classification or for more advanced operations - see seqseq class).\n",
    "\n",
    "- Does not formally solve exploding gradients, but for that we have brute force grad clipping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Variants\n",
    "\n",
    "### \"Peephole connections\"\n",
    "[Recurrent nets that time and count](http://ieeexplore.ieee.org/document/861302/)\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-peepholes.png\"><img src=\"https://drive.google.com/uc?export=view&id=166ktVxHa3c2b7hGeuI6MYFTe3Fv5cuwT\"></a>\n",
    "\n",
    "The idea is really similar to \"highway\" or \"skip\" connections in case of ConvNets, essentially easing the gradient flow with direct links, as well as adding information for the local decisions of the gates.\n",
    "\n",
    "Details again at the [blog of Chris Olah](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
    "\n",
    "### Gated recurrent unit\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png\"><img src=\"https://drive.google.com/uc?export=view&id=1a6tOZ35ZgeJtxMluZ9tSAJomrq_Cmfen\"></a>\n",
    "\n",
    "[Cho et al. 2014](https://arxiv.org/abs/1406.1078)\n",
    "\n",
    "+ combines the forget gate and input gate into an \"update gate\"\n",
    "+ merges the cell state and hidden state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8IYutdnW_SG"
   },
   "source": [
    "## LSTM as layers\n",
    "\n",
    "+ An LSTM - how ever strange that may sound - can be considered to be a complete layer. The most important parameter of it is the \"number of (memory) units\", which is the length of the hidden state vector, thus, the memory capacity. **Warning: this does not have any relationship to input size, thus can be considered a freely chosen parameter.**\n",
    "+ It is quite widespread to use multiple LSTM layers (\"stacked LSTMs\") -- as in the case of ConvNets the hope is, that the layers learn a hierarchy of abstract representations:\n",
    "\n",
    "<a href=\"http://wenchenli.github.io/assets/img/GNMT_residual.png\"><img src=\"https://drive.google.com/uc?export=view&id=1cbf6VvnPTkQwJZjv2jZfpC2-w3zxLSbq\" width=60%></a>\n",
    "\n",
    "(on the right side a network is shown with skip/residual connections!)\n",
    "\n",
    "In this case it makes sense, that we do not only get on top of the LSTM a final prediction $h$ (or even prediction + inner state vector $c$) for a sequence, but **we ask it to output the whole sequence of predictions**, so that the next layer can also operate on full sequences. Please bear this in mind during implementation, since this can be a common source of failure.  \n",
    "\n",
    "Also worth noting, that the practicality of multi layer LSTMs have been recently questioned by some researchers, since they aruge, that one layer of LSTM can learn nearly everything a multi layer one can in practice - given the right \"treatment\". See more [here]( https://arxiv.org/abs/1909.00021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LSTM example\n",
    "\n",
    "Let us go through a **basic** LSTM  example based on a [publicly available property manintenance dataset](# https://combed.github.io/).\n",
    "\n",
    "**This is _not_ a full datascience project, only the demonstration of some data preparation and training concepts!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:43.382488Z",
     "start_time": "2020-05-27T17:05:42.351439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-27 19:05:42--  https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/Power.csv?inline=false\n",
      "Resolving gitlab.com (gitlab.com)... 172.65.251.78\n",
      "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘Power.csv’\n",
      "\n",
      "Power.csv               [  <=>               ]   2.98M  7.74MB/s    in 0.4s    \n",
      "\n",
      "2020-05-27 19:05:43 (7.74 MB/s) - ‘Power.csv’ saved [3128452]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/Power.csv?inline=false -O Power.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:43.421042Z",
     "start_time": "2020-05-27T17:05:43.385299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.401595e+12</td>\n",
       "      <td>58.694874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.401595e+12</td>\n",
       "      <td>58.465698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.401595e+12</td>\n",
       "      <td>58.090099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.401595e+12</td>\n",
       "      <td>58.260864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.401595e+12</td>\n",
       "      <td>58.002567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp      Power\n",
       "0  1.401595e+12  58.694874\n",
       "1  1.401595e+12  58.465698\n",
       "2  1.401595e+12  58.090099\n",
       "3  1.401595e+12  58.260864\n",
       "4  1.401595e+12  58.002567"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: Dataset / Academic / Power sockets / 3\n",
    "\n",
    "df = pd.read_csv(\"Power.csv\", header=None)\n",
    "df.columns = [\"Timestamp\",\"Power\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:43.556173Z",
     "start_time": "2020-05-27T17:05:43.422885Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deZwU1bX4vweGHVGUUQmog4pG9CkiGo3LzzUg+lOTvLzoy4vGmPD0p0nM8hKML8Y9xrg9jdFoRCVRXILbExcWFRDZBmSXZYABBhCGbdiHWe7vj66eqe6p7q7qruqurj7fz6c/XX3r1q3TtZx777nnnivGGBRFUZTSoF2hBVAURVHyhyp9RVGUEkKVvqIoSgmhSl9RFKWEUKWvKIpSQpQVWoBM9OrVy1RUVBRaDEVRlKJh9uzZm40x5U77Qq/0KyoqqKysLLQYiqIoRYOIrE61T807iqIoJYQqfUVRlBJClb6iKEoJoUpfURSlhFClryiKUkKo0lcURSkhVOkriqKUEJFU+u/OX0/dnoZCi6EoihI6Iqf0127dwy0vf84to+cEUv6cNdvYVd8YSNmKoihBEzmlX9/YBMD67Xt9L3vHvga+9ZfPuOXlYCoURVGUoImc0g+S+oZmABauqyuwJIqiKNkRWaW/onZ3S6tfURRFiRFZpQ/w8ow1hRZBURQlVERa6Tc2uVv0/bR7xjN8lEbyVBQl+kRa6btly+79jFu8sdBiKIqiBE5GpS8iI0Vkk4gstKW9KiJzrU+1iMy10itEZK9t39O2Y04TkQUiUiUij4uIBPOXFEVRlFS4aem/AAy1JxhjvmuMGWiMGQiMAd6w7V4R32eMudGW/hQwHOhvfRLK9I/o1yUNTc28MacGY9yZrxRFUeJkVPrGmMnAVqd9Vmv934DR6coQkd5AD2PMNBPTVKOAq7yLG13O+sNE/jZlpau8T32ygl+8No935q0PWCpFUaJGrjb9c4GNxpjltrR+IvK5iEwSkXOttD5AjS1PjZXmiIgMF5FKEamsra3NWjhD8bSEN9Tt496xX7jKW7uzHoC6vdELNbF3fxO/e2uhznouEbbsqmfmKsc2pRIQuSr9a0hs5W8AjjTGnAr8AnhZRHrgbHNJqZGNMc8YYwYbYwaXlzuu7atElBenVfP36at56pOqQoui5IF/fXoa//bXab6X+/dp1bw9d53v5YaBxqZmho+qZN7a7Vkdn/XC6CJSBnwLOC2eZoypB+qt7dkisgI4jljLvq/t8L6A2iZCyAcLv6Rvzy6c1OfAgpy/qTnWFmgunk6akgOrNu8OpNzfvb0IgCsHpjQoFC1rt+1l3OKNLNu4k0/+6wLPx+fS0r8YWGKMaTHbiEi5iLS3to8mNmC70hizAdgpImda4wDXAm/ncG4lIG78x2wuf+LTQouhKEpAuHHZHA1MA44XkRoRucHadTVtB3DPA+aLyDzgn8CNxpi4we4m4G9AFbACeN8H+R3kDaJURVGUaJDRvGOMuSZF+g8c0sYQc+F0yl8JnORRPkVRFMVHdEauouTAovV1VIwYy9SqzYUWRQmYQfeM59nJ7tyqw0yklX6muUtVm3axW10DlRyYsTJmvRw1rbqgcijBs3X3fu57z51bdZiJtNLPxMWPTOL652cVWgzmZul6VerU7W0IzbX7cNFGVm8JxhNFCZaKEWP5zT/nF1qMvFHSSh9gZnXhJ4Zc9eTUQotQlFw3ciZXPTk1NOEoNtTtK7QISpa8Wrm20CLkjZJX+kHR2NTc4nOuBENYWvlBsqu+kfk10f+fSv6InNIPi8fmsbe/z7D/mVJoMZQi56Z/zOaKP09l735dBU7xh8gp/TCxdOPOQotQVDQ1G5q1d5TA3DWxVn5Dc3OBJVGiQtZhGBTFb77+wEQ27qgvtBiKEmki3dL32macsryWT5cXj791pvHLPfsbi2pcoRgVvs4AV4qNSCt9r3z/uZn8x3MzCi1GRtwqmgF3fMjPX50brDA+0dCk5gtFyQeq9CNOsSy08srMNVkfGxKPTddyvDprDeN1TWalQKhNXwkF+xq8t/RFwqPwvfCbMQsAqH7gsgJLopQikWvp63rriqIoqYmc0lcURVFSo0pfUUJMEVqvlJATaaVfjPZepbjIlzFRjZaKX0Ra6SuKoiiJqNJXFEUpIdyskTtSRDaJyEJb2p0isk5E5lqfYbZ9t4lIlYgsFZEhtvShVlqViIzw/68opUpYrHgmNJIoSmrctPRfAIY6pD9qjBlofd4DEJEBxBZMP9E65i8i0l5E2gNPApcCA4BrrLy+o7bP0kHvtaJ4x83C6JNFpMJleVcCrxhj6oFVIlIFnGHtqzLGrAQQkVesvIs9S6yUBDoIryjBkItN/xYRmW+Zf3paaX0A+xI0NVZaqnRHRGS4iFSKSGVtbW0OIiqKoih2slX6TwHHAAOBDcDDVrpTj9ukSXfEGPOMMWawMWZweXl5liKqjVUJHp0BrhQbWcXeMca0RIsSkWeBd62fNcARtqx9gXjEr1TpiqKkICzr/yrRIauWvoj0tv38JhD37HkHuFpEOolIP6A/MBOYBfQXkX4i0pHYYO872YutgCqEUkJ7FIpfZGzpi8ho4Hygl4jUAL8HzheRgcRMNNXAfwIYYxaJyGvEBmgbgZuNMU1WObcAHwLtgZHGmEW+/5sSQV9/RVGyxY33zjUOyc+lyX8fcJ9D+nvAe56kywJtEJUesR5PCG68dryUIkBn5CpFSymZPNSUp/iFKn1FCTGlVLEp+SHSSl8bR0rQqE5WCkW26i3SSl9RFCVq5NrOUKWvKCFGbfmK36jSV5QiQG37il9ETulLGFz3lLwSlrZwWORQlHRETukrxUk2DVmt3hXFO6r0FUVRSghV+oqSA9rbUIoNVfqKoiglhCp9RVGUEkKVvqIoSgkROaVfSu7M6iIYffQeK34TOaVfCuhEnUTCMmk1SDn0jit+EWmlr1PYo43WfYrinUgrfUVRFCWRjEpfREaKyCYRWWhL+5OILBGR+SLypogcZKVXiMheEZlrfZ62HXOaiCwQkSoReVzURqFEAX2MlSLDTUv/BWBoUtp44CRjzMnAMuA2274VxpiB1udGW/pTwHBii6X3dyhTUVowOoSpKIGQUekbYyYDW5PSxhljGq2f04G+6coQkd5AD2PMNBMztI8CrspOZEVRFCVb/LDp/xB43/a7n4h8LiKTRORcK60PUGPLU2OlKYqiKHmkLJeDReR2oBF4yUraABxpjNkiIqcBb4nIiTh7nKXsv4vIcGKmII488shcRFQURVFsZN3SF5HrgMuB71kmG4wx9caYLdb2bGAFcByxlr3dBNQXWJ+qbGPMM8aYwcaYweXl5dmKGBr/bSVYwmL/D4scipKOrJS+iAwFfgNcYYzZY0svF5H21vbRxAZsVxpjNgA7ReRMy2vnWuDtnKVXShpdMEdRvJPRvCMio4HzgV4iUgP8npi3TidgvOV5Od3y1DkPuFtEGoEm4EZjTHwQ+CZinkBdiI0B2McBFKUo0WpHyTe59iczKn1jzDUOyc+lyDsGGJNiXyVwkifpFEVRFEeybXBEbkauzpVRFEVJTeSUvqIoipIaVfpFjHonFR69BUqxEWmlry9kaaCVn6K4J9JKX4k4IRu/0cpHKQZU6StKDgRd72hFoviNKn1FKQLUK03xi8gpfQ3TryiKkprIKX1FURQlNar0FUVRSohIK30dBFMUJapkq94irfQVRVGiRq6jlqr0laIlDEP2dr8B7VgqxYAqfUVRlBIicko/DK0/RfELXY1L8ZvIKX1FiSK6SpjiF6r0FUVRSohIK33tGhcxeusUJRBcKX0RGSkim0RkoS3tYBEZLyLLre+eVrqIyOMiUiUi80VkkO2Y66z8y0XkOv//TmmherF00AaM4hduW/ovAEOT0kYAE40x/YGJ1m+AS4H+1mc48BTEKglii6p/DTgD+H28ovCTUng1NLxQIoWchBe0rV1t+YrfuFL6xpjJwNak5CuBF63tF4GrbOmjTIzpwEEi0hsYAow3xmw1xmwDxtO2IlEU14St8jM6BVwpAnKx6R9mjNkAYH0faqX3Adba8tVYaanS2yAiw0WkUkQqa2trPQkVMj2gKIoSKoIYyHXSuyZNettEY54xxgw2xgwuLy/3VThFKSbUlq/4TS5Kf6NltsH63mSl1wBH2PL1BdanSVcURVHyRC5K/x0g7oFzHfC2Lf1ay4vnTKDOMv98CHxDRHpaA7jfsNICQ02siqIoiZS5ySQio4HzgV4iUkPMC+cB4DURuQFYA3zHyv4eMAyoAvYA1wMYY7aKyD3ALCvf3caY5MFhRVEUJUBcKX1jzDUpdl3kkNcAN6coZyQw0rV0iuKCQtq9w+ZBpCiZiPSMXCXahM2HXa2JSjEQOaWvLa9wYYzhhhdmMWlZetdbXdBeUfJD5JS+Ei72NzUzcckmfvxiZaFFURSFiCt97W4riqIkEmmlryjFjrodK36jSl8JFFVaihIuVOkr+SGi47QR/VtKhFGlX8RoVMcYehkUxT2RU/ph890OglL4j24InZenVj5KERA5pa+Ek7DpZ0UpVaKt9LXfryiKkkC0lb5ScLTeVZRwoUpfyQuhs78rSomiSl9RciBflVkhekxrtuzhrc/X5f/ESqC4Cq1cTGiLMlxkG/bYy1FqQQqGy5+Ywo59jVx1quNS1kqRoi19JS8E4Waq9Xuw7NjXWGgRlABQpa8oPqGLmCvFQKSVvr6CiqJElWzHebJW+iJyvIjMtX12iMitInKniKyzpQ+zHXObiFSJyFIRGZLtuQuFtuS8oy6biuIvuY5bZj2Qa4xZCgyMCSHtgXXAm8QWQn/UGPOQPb+IDACuBk4EvgJMEJHjjDFN2cqgFA86wK4o4cAv885FwApjzOo0ea4EXjHG1BtjVgFVwBk+nT8vaMwbJRl9JpRiwy+lfzUw2vb7FhGZLyIjRaSnldYHWGvLU2OltUFEhotIpYhU1tamX1u1zbGecitBo9YdRQkXOSt9EekIXAG8biU9BRxDzPSzAXg4ntXhcEedYIx5xhgz2BgzuLy8PFcRlRAQZGUc5RDT0f1nSqHwo6V/KTDHGLMRwBiz0RjTZIxpBp6l1YRTAxxhO64vsN6H85ccah+PIXohFMUzfij9a7CZdkSkt23fN4GF1vY7wNUi0klE+gH9gZk+nD8lEW4AFg1uW+FRUN/6vCnFQE5hGESkK3AJ8J+25AdFZCCxnml1fJ8xZpGIvAYsBhqBm9Vzp3TQVrmihIOclL4xZg9wSFLa99Pkvw+4L5dzKoqiKNkT6Rm5SuGJvMVDOzBKnsnVjBg9pa8vYSjR26Io/pKtxTR6Sl9R8knkuzJK1FClrwRKPjxaVO8GS5TnQZQikVb6GiAtRARg3ykJk5E+wopFQ1MzHyzckPMjEWml7wcVI8Zy/fOBTidQIoI2iJUgeXzicm78xxw+XrIpp3JU6bvg46Xe4v8oSpTQyiwcrNu+F4Bte/bnVI4qfYWzH/iI/5mwPJjCo64wSsLGpESJyCl9DXXrnXXb9/LohGWBnkPvSm5Eve5U3KN++ooSZUJQW2qFEy1U6SuBkg8PKrU5K6VErmGsIq30o64Miun/BRJwLQStYEXJN2reKUFKQdfphCBFScSv8UpV+kqglJLuDuSvhuD6aQUcDvwyleYUWrlYMcbw/NTqQotRUkQ1nH5E/5YSYSLX0nejXOas2cbd7y4OXhhFURSfUPNODtQ3NhdahJJBDQPFj97DaFGSSl/JP2oGUaLCL1+bx9qtewp2/lxt+zkrfRGpFpEFIjJXRCqttINFZLyILLe+e1rpIiKPi0iViMwXkUG5nj8d2kIpEfRGK3lkzJwafvvmgkKLkTV+tfQvMMYMNMYMtn6PACYaY/oDE63fAJcC/a3PcOApn86vlCDae8gP6rwTLnK17Qdl3rkSeNHafhG4ypY+ysSYDhwkIr0DkkEJAaXk7ldK/1UpHAU37xDrXI8TkdkiMtxKO8wYswHA+j7USu8DrLUdW2OlJSAiw0WkUkQqa2v9D2usQdlaaW7Oj6LKNCO3WF06A5lpbEMXAlLi+PWo+eGnf7YxZr2IHAqMF5ElafI6id3mqTbGPAM8AzB48GB96gNk577GQoughByteMKBXx3JnFv6xpj11vcm4E3gDGBj3GxjfceXeqkBjrAd3hdYn6sMSvY0B2ySUHWhKP4St1Rk++rmpPRFpJuIHBDfBr4BLATeAa6zsl0HvG1tvwNca3nxnAnUxc1AQaAm1sw05ekiFan1RlFCQ1jMO4cBb1p2zTLgZWPMByIyC3hNRG4A1gDfsfK/BwwDqoA9wPU5nl/JkaBb+oqihIuclL4xZiVwikP6FuAih3QD3JzLOf2gWAcNgyBonZ+POqVQNmdjTN4GwguJtgvCxZbd9TkdX5IB14Jk2+79lLXPT63ih7Jrypv3ThBlFrb2vm/sF/zt01UFlSFIRFThh5HRM9dmzpQGVfo+c+o94+nasX2g5/BT1+VL6UeRUdNWJ/zWK6kUAxp7JwD27G8qtAiuCdy8E2FVGOX/pkQXVfolTv4GcqM3kJJP00chZvtG744VN37dj0gr/VQtMX2YW8nWZXPb7v0s+XKHz9IoYUL7MeHCr/sRaaWvZCZb75Mrn5zK0Mem+CxNcVEqSlEHc6OFKv0Sx67zf/fWQtfHrXEbTzwfLpuqlAJBe8ThQs07eaZmW6uS27xrf2S8Xuz/4+/TV6fJmRvBuGz6X6YXovIMKKWFKn2XnPPHjxN+T1q2KUXO4iKbgdw9+zVIWymhXkrRoiSVfqEn9YSJbEwjt7z8ufvyvRdftETNzKTvSTSJvNL/4QuzeGTcUt/LbReRFyIb752Plnjv5Xi9WlFToIoSFqKt9E1MQT3+UZUvxa212fXL2kXj0qldWslElCvgvUU0kdIvoqG58sRam8dKRHQ+E77YGGj5UVYY+aCQ1y8afdn0nHDHB4UWIe9ERHXlhy279rdsj1sUrLLMFxu2783p+P+d524NnIhYwxSl6ImU0r/8iSk8NmGZ4759Da3duGwV0Lya7S3bL3xWnV0hPrChbp9vZdU3Nud0/AcLv/RJkuzRzoSSb4q5BxupKJsL1+1g4brW0AB2e3Xd3gY6d8gt+uXbcwu/suOCmjrenR9bbMyPB8+r0l+8PjH0wvJNO9PmD9LdTzsP+aGI9Vuk8Ku3HKmWfjKzVm9r2Z60tLaAkvjHitpdvpa336PSX7iuLuH3so3u5BFV0UWHmuRSU8zXJjJKf61DWIAdextatuubcjNjOPHhosKbNnLlrGMO8ZR/0fq6zJkc+HLHPj5O4+pZxO+QDW0TlwrFbN7JWumLyBEi8rGIfCEii0TkZ1b6nSKyTkTmWp9htmNuE5EqEVkqIkP8+ANxpq/c0iZt577WmaNe4sq45f73vsjp+E0793HMb9/zdIzf5pKv9TvYU/4Xp3kL1WB/OZ6dstLTsUowbKjbS8WIsVRWb3WVvxBhneNs37OflR57t2u2uIwLVaLkYtNvBH5pjJkjIgcAs0VkvLXvUWPMQ/bMIjIAuBo4EfgKMEFEjjPG+OIo62Sb3rwrt7UkM9HYlNvLMHnZZs9+8u8v8Ld3kc9u6mcr2lbMSv6ZuSqm7F+ctprBFakr/ZhJrrBN2oF3x1RK9QOXuT7mvD99nDlTCZN1S98Ys8EYM8fa3gl8AfRJc8iVwCvGmHpjzCqgCjgj2/Mn48Xf3K+GS2NzYkXjtUX09tx1nvIvXFfHuMX+uorqVPvSo4vl0OBkEg0r+xqaOO6/3+e9BRsKLQqgNn1EpAI4FZhhJd0iIvNFZKSI9LTS+gD2FX1rSFFJiMhwEakUkcra2tgA7NIvd6Z0xwT4pAADtcmt9P0exw3Ku3fylH91UrfVj7rLSz3ltZIKkrHzN7BtT2zMppDmB680eHxGgvhn8TLnrt2eNl+QMgDUN7rv5K/bvpf9jc089KH/IVWyIQyPXO3O7CwZOSt9EekOjAFuNcbsAJ4CjgEGAhuAh+NZHQ53vHTGmGeMMYONMYPLy8sB+PZTn/HYhOUJ/vbZ4peSaExS+vv2e3uhvQ6i7k6KbpkuQqZbr5w1W3e7Pv/PXpnrOm+coN6Nm1+eE1DJwdL/9vcLLYL7QfOAW7Nf/8NHrvO2POo+ylTsIUj2ZqkLc1L6ItKBmMJ/yRjzBoAxZqMxpskY0ww8S6sJpwY4wnZ4X8C143u8Fd1sTGjiZWzf05DwO1kpZ2LBOm+eMJ3KEm9XujGFm/4x21WZP391nicZlOzx6h4bFB3ah8Npb8vu/ZkzWezYF3vXMun86s3uGzFz1mzLnCmC5OK9I8BzwBfGmEds6b1t2b4JxN1m3gGuFpFOItIP6A/MdC2odbcH3zuBE+74IPBB2mzY47EyGjO7xlP+bh0Tx93XpwmhMNHmHvnwuKVUjBjr2bSg+EsQHmTZ8NKMNZ7yh8GUsdHFLPSF6+o4/6FPXJf5naenuc775Mf+BG3MBb/muuRS5Z8NfB+4MMk980ERWSAi84ELgJ8DGGMWAa8Bi4EPgJvdeu40Nxv2NcQUVlyx3vW/i3MQPRi8mp52e6wkunZMnFGcbF5KxRNWlNE99W3P17lDcK2+j5duYp5Lu3EUyKQcX61cmz5DurKzPrItQQfZc0Py2sx1Sb3mZG56KbM5z8/wJMn8KQRjCZlmv7sla5dNY8ynOPe2UjqeG2PuA+7zei6nmO+HdOvotRhqtu2hb8+ugdmZn5q0IqCSY3RMMu8c7PEaOA00t/fJDaF2Zz0Hde2QYDq4/vlZvpTtF4+MW8qAr/Rg6Em9M2cOCW7uzl8nraBLx/Zce1aFqzIP6dbRk2nFb/bsb+S9JNfjHfsaOLBrh4zHrqhNbb5Ztdnf2ephY84afxpQ4TDuZcBxBDiLPqcfg8DpGDvfmzvZ4T06e8rfvl3ilZhatdnT8cmVBsAJvXs45n1i4nL++60Frsrd19DE6fdN4NL/meJJnnxijOHxj6q48R/BDQDn0pLPhT+8v4Q73l7kOn8hFT7Af7+5kF+9njiWNHt17vb1eWuzmy1eahSH0ndojXp1jwR4x6eAaQNsinL4qEomL0vtLppusOg7g/u6Pqcxhm/+5bOEtEVJwc/clJHMlac6T614ePwy/jHdne33X5+OyVW1KbwtLT+USiYK4TbslT+8n8Uscp+7xqsd5gf87u3cxzvKD/DmAp0LyXN0iomiUPpOjJ651nNrP5eJTUNPPLxl+8fn9Uso89qRqcejv5WkqO2kekh37mtoE9is1oeBa0cXtQzX0I0vtT2yaZy6vc422s9WbKZixFjW5RDHP9ke7OYpsM/YXlm7i4oRY5lfU/zjDV7fgb9Och8KIyiPTac1HOwhU7Iln5PNVqYxM82v2c4vXwuvV1zRKn2ANR5v8pIvYwMh2Xgj9D+se8v2Vw9vaxKpb2zinGN7pTzeaaAqlU3+zPsncvkTn7ZRbrmy22EgN9Mp/vDekqzOFZ/qn8yd78TMELNS7I8zfVXqkA3VWxJfuPetWZr1jU289fk6R0VoD6s93qr8HxmferKf33zm0RQXJ9MTsLM+d2WZb9YHNODq1XsuF9INhV3x56mMmVPDb/45P62HXaEoaqXvl7nmtKN6ZszT2Gzof2hM8Tu10K99biafWi/2oCMPStg3euYaTrl7HOOSonI6+dlPX7mlxavHPoDtNDfB3vtww1yHlm2mlmK2i8Wk8kmPh2JONrfcmeSNlW62YXLl9TvLnj181GxufXUuE75oG82zp22QMO66mk9zTLaTyTJNIGqwXeeqTTvZuMN/hRrkmgh+4mUJ01wnaLo5/NXKtXz9AfcT0Lxy0VcPzeq4olb68Za7lxZxQ1NzwkzWn17Un5E/OD3jcY1Nzbx9y9l88qvz6eUQPmGGreX6g7P7Jey77Y3YgOjfpydGqLz11bYzXO3hoO2rUjl1J4ecdFhGue0McBi0Dep1rujVNe3+TO5123anduFbX+fceppkja1scxioXPplq7tb8qS6bPDaCzvy4PTXwwk30SXtsWgufmQyX7t/oqdzpKsk8hlf5un/GERjU3NOytjLNc517kEYYu9MXLIpq+tVFEr/+amrHNPHLtjAnDXb2oTs/f6ZRyX8/tag1sHK1Vv2JNipf3HJcfTonNlzdenGXXTtWEZFr24Z857c50DH9CnLvXXxfzL685ZtpynXW9MoRiecWo1BTbzp3in9Nc3kK55uoD6V6ShOQ9Ig28J1dQl+3n/71Pl58kKqSI6pKoN5Nd48S5qbDRc+PCkhbfKyWkZNq05I+50Hr51Gh2vqZlGe3fubXFdyz326KiHkeN2eBle29rJ27Tj29vfpd5u3UON2hnjo+XqJxJncQ7ezfOPOgsZ+8urMAUWg9Besq+Pesak9Dr71l8/4w/utducl9wzlnqtOSshz31X/0rK928EGmuwdVDFiLHV7GxJuppdBonY5NAPsLVI7L81oG8f+nne9TVBz8jgI6nHN5RpkLjv9/uS5B49NWO7r+Y0x1Gxz7m08PTm3uRrGGB78YAkPj287GejakTM9uWYm4zTByU1oiLMf+IgHXU5OuufdxTwzeSX/9fo8rnlmOuc/9DHnPpioYL96+AFtjvMleKCHvKnunzGGLUlOE8P/3jakycYd9UxeVsslj07mnx5n1iczb+32lmCGd76zyNN6ANnUN6FX+l5xWge3i20m64FdOriKTvfo+GUJHigDjzgoTe5E3NgW47FEknk4xeDi1CrngU0vrQwnE1FQrZTfvunOx3/V5t1s3+PsN55qlubxDgPpdpLrm+RexWE9Ws1zdXsbUnoapSLdusKjPvO2yEwyu/c38ZdPVvDkx6krj2zv2YFd2k5+She0zz7t/63PvUVYfX12DdNWbnGMhLrEoWHjpVGV6v/78Sz/8vV5nHbvBFfyLLdclLNpbdu58smp/OyVubwzbz0vfFYd+HoAkVP6yVQcErPzPXHNqQCc/9An/GZMZoX0wmfVLQs4ANx+2QkJ+6f8+oKUx7oJaOVXHJZXZq1tsWVn4iejP6dixNiW33PXbnfVgtu5ryFhYlv/Q7uz7N5L04cFKDIAABEuSURBVB7jxpTV2NTMBQ99wiWPTnbcv2qLs1tcrvHCbrmwf8v2KXeN45S7xnk6Pl0n5sscB1LdzJDOpNu+/9wMx3SnyXlup7vk+r8aMiw4dLeHXmuqMZn5Dia0TTv2uQ5BPKt6K2/MiVVumbxuDuzSgSorLMK2FI0Wr/zUZs51y/4m7x5LkVf6P7Fe8Ndz7IL17JroXnlEmkEjN6YNvyYy3fbGAq4bOZPZq90tfWfnqienuure765vSojzM+7n59GxrB23Xty/Td6KEWMdW0lOM3/jZaZ6KRuamqkYMZZv/WVqQnqmyKCZAlO9mKVHUpwgTbhuPGXStc4hVuE62eB7ObgI9+3Zxb1wORA3LfrRGn/8I2dznZMZ74z7J3L6fRN48IPMrsf/sDlaZPKaajamZQbwhu3+eEx9M8VEyXSMmeN9jYuiU/rVD1zGh7ee57hvxf0ty/Gy8v5hPH/96S2DuEdlGNlPDnGQjNPuqvsuZd7vv8Hiu4cw945LWHbvpcy945IM/yBGLl1Cp3Ok83ZJxqvvsH3g+7+GHN8yBnLDOf0c8yfbcAF6dW+rcHZkMKtstioDzzFHMtS5XircbBaqcFo7+eS+bQf3f/RidrGJnGJRJbN0Y1sTitNxyZFb7SQ7D6ys3UXVpp2ewhfH2Wp5VL3rMVSJE89PrfZ8zKuzMofIsI/3/fvfnHtLLZjWe3rm0d7WmU5Furaik0cawKQs3I6LTukDHH/4AVQ/cBmL7x5C9QOX8fz1p7PoriEJirtdO+GC4w9tUVD2wd0jDu7CdWcdxdJ7h7ak/XrI8QA8+t1T2pxvxf3DHENBlLVvx4FdOtC1YxkHde1Ix7J2HNTVeyA4gCtO+YrrvF0dXtQfjaps2c603sDQxyazaaf71skVf57a0kLraLOtOJkLUnFK37ZjIplMS16WcnxnXuucjYOSbNdu5NxQt5cJizcmzBaesryW0++bkGASc8Mzk1dywwuJCv34w9oOXjrNJ3DTEHaTx6myspty4pc2U6/BzoUPT+LiRyZz/kOfpOzRpeKcP37Mjn0NCR5pufDC1FVUjBjruudwnMP1T8bpfqSi2RhesSqSxz+qomZb7rOB01kITr1nvGO608z2uzNEIC5KpR8nrvwuOP5QumVwEYRYL6H6gcuY8usLuevKk+hU1jrAO/y8o1l5/zC+eWrfhEWYqx+4LGMvwAuplqgrcziH03yAVHntrNue/gHcsa+Rm5ICj/3onH787KK25hpIDKlgfy47uBixXnTXEFb9YRjD/qVtZMtMXg9TlrtvxXyytPWF3WVrsRlj2kyWc6J68x5enx17iedb9+jdea2tUq8hG+zrGUDu5sWFNnu1G0V9mEMwv1Nt1+GP3z7ZdVmp+GiJeyUJsCuLUAs9U0TejE/mc7v61bSVqWd4Z0Pyac/5Y+6Dr9mqmQuS1hAYmcLFveU82Z0meogI7WxXPV5B+M3LDq6XVfddyiCHWcFNKYI6tcvwdPTonPiiOA06J3vM/GrI8fz8kuMcy+tU1s7R0pxJDoBuncoQETq5jNt/+7AT6NA+Vm6mF/rJfx/U+sOW9Re2uCf9bnuP6Sszj3cYTEvlHndt/KZtfscVf57qeJzfpPrHdnODG0XnlMc+SBz3cssl0kdyKzvTouVuxroGJ70HmcTLNEAcFG5MbF4ps3rRx5RnngtkZ5VHc5sq/Tzj9KyUtW/Htwe1jbjp9EL+MoVitmN/IKsfuMxx0Dm595LuffzTd9qavLxyTHl3Xr/xrIz5DKZFOWRaJOb0ilYFYc+ZTbTF5ua25qRUreBs3veT+qR3M/WCG0XtJLs9LX77cxlYTT4y3SSmbMu0i3fZyW17i26j7Z7bvzUuVi7/+acXHhs7bwBLX8ZNp0Gv3atKPyQ4mZAcZ9C6KMvNM9M+yTSTzuPFL+PW6RXuBrzi1yLjLFCbYHaFls1L09Dc3KYlmtzRyiUA3mEHuFs7wY1CcpPH6RrYk+L/NbeWfuLv5GeqTf40T2+7FGMM9v/qZNZ0uwSovdxc/rOXcaw4biuZ+H8JohdhR5V+SHB6oLON2e1GOSX7umfqeedrprkgLWYIt8tBQqJ8DVm0wpqaTBubavLLF5en0AHI3FRqjrOvHVr6qXszLiqfpN+ZxprSEf9Lyae1/3RqGDkFLXTCni+XcYxslL7bRkg8X9Ch+vOu9EVkqIgsFZEqERmR7/OHFSf7eLY33+khS35Y27b0U5NvFRe/FpleFnvvxJ4zOfaOGxqbm9tMjEquPHPpdqeqVJOVq189OadZw/bjpKWl71yYm3Mky96+fe59wjandeidxLZj39m09HNpwHTMYmag28ZLPF+kzDsi0h54ErgUGABcIyID8ilDofFyP7Pt5jkd1zlZ6Se9n27dI724UWZLvEXnpadjf6ndtv7sNDabNv8t+eXLrdvtfN289GbiuGmFOw1w2nsocQWaqqhsWsMdMrT0s6lI7L/sPYkyq9Hi1qZvv865tPQ7ZNHSd3uP489bNs+ZF9Nj1gujZ8kZQJUxZiWAiLwCXAl4ixxWxIyZU+Pa/a+p2XDJI4mRFsvStKbieZ1ehF7dO7HD5jKXPOEp3ev609Gfc7RHj4Jsad9OKO/eia279/PhotaYOcnXARJbz/b1iRsdrlsmbnk50X/8kkcmJbh+Alzx509pL+JaadhlSBXga+hjkxNasG5e+O8+Mz2jKeXHoyrbTEi0r04VP/yml2bTuaxtvCo3//HesV8kTHpanmHS2/eenZ6xzPk1dQnXbff+VpntMbTiz/j1z8+ikwtF/Pma7S3lZnP/4nRyuFbp8kPrc5OJCdbiPrU76z0/v994bLLrsbd8K/0+gH1qXA3wteRMIjIcGA7Q8fBjW9KfvXZwwOL5Q6/uHfnROf2o6NWN/06KsXPhVw+lc4d2ji/IDef047lPV/GtQX2YVb2VE3sf2BK87ciDu1K3t4EfWrH6v/e1I3lpRuIatvbVvTbtqOem849p+X3nFScmLOt4RsXBzKxudWWMm1T+du3glole7/30XF6asboltshJXzmQC44vTzjno989hZ+/Oo+5d1zCSzPW8CfbhKvfDvtqm/944/85hukrtzB37XYG9O7B4g2tM5OPOqQr3zvzSM47rpyLH5nERV89lNVb99CtY3v62MIF1Gzby8HdOnJIt478+Nx+PDtlFV8/5hC6dSpj/OKNnHdcOd07xV5Op+t8YJcOnHX0IXxg8za59KTD2VXfyJTlm+ncoV3LtWys3kaPzmWsqN2dEB1yhRW8bvSPz+SAzmVc/sSnQCyM94yVW9myuz7hfvQ/rDtzVm/n/OPLWyb1QGyiYTKdytrzhXVduncqY1d9I8eUd2NF7W7aCZzQu/WYw3p0blm8x85FXz3U0aRUvXkP15xxBKce2ZNvD+rL3obUvvMrbAH6Tq/oyazqxIVvLj7hMDqWtZ6kT88ubRamOfvYQ1qCBQ74Sg86d2jfEnDtnGN7cW7/Xmyo28emnfv4fM12Bh5xUILcxx1+AP/35N4s3rCTG87ux/NTqzm574F0LmvPzOqtCV5Re/Y3tUxWGnPTWXz7qWkAHN6jM6cemViuMbDScnUc9cMz+N3bC2k2hjMqDmHMnNicivj9W1G7i2YTi/l/0QmH8avX53Fu/17MXLW1xYzW+8DOLfmPOqRbQpA/p6iidvr07ML67Xs59tDuLFy3gwG9e7QJ2mh/jn98bj/OPrYXP3i+dQLgcbZnrbHZkC7sn+QzFrSIfAcYYoz5kfX7+8AZxpifpDpm8ODBprKyMtVuRVEUJQkRmW2McWwl53sgtwY4wva7L+DPmoeKoihKRvKt9GcB/UWkn4h0BK4G3smzDIqiKCVLXm36xphGEbkF+BBoD4w0xmS/FJCiKIriiXwP5GKMeQ/IfiFMRVEUJWt0Rq6iKEoJoUpfURSlhFClryiKUkKo0lcURSkh8jo5KxtEZCeQfl29wtALaDsVMhyobNmhsmVHWGULq1wQvGxHGWPKnXbk3XsnC5ammllWSESkMoxygcqWLSpbdoRVtrDKBYWVTc07iqIoJYQqfUVRlBKiGJT+M4UWIAVhlQtUtmxR2bIjrLKFVS4ooGyhH8hVFEVR/KMYWvqKoiiKT6jSVxRFKSFCq/TztYC6iIwUkU0istCWdrCIjBeR5dZ3TytdRORxS6b5IjLIdsx1Vv7lInKdLf00EVlgHfO4uFxkVkSOEJGPReQLEVkkIj8LkWydRWSmiMyzZLvLSu8nIjOs87xqhc9GRDpZv6us/RW2sm6z0peKyBBbek73X0Tai8jnIvJumGQTkWrrms8VkUorreD31Dr2IBH5p4gssZ67s8Igm4gcb12v+GeHiNwaEtl+br0DC0VktMTejVA8aykxxoTuQyzs8grgaKAjMA8YENC5zgMGAQttaQ8CI6ztEcAfre1hwPvElpQ9E5hhpR8MrLS+e1rbPa19M4GzrGPeBy51KVdvYJC1fQCwjNhi8mGQTYDu1nYHYIZ1zteAq630p4GbrO3/BzxtbV8NvGptD7DubSegn3XP2/tx/4FfAC8D71q/QyEbUA30Skor+D21jn0R+JG13RE4KCyyJemGL4GjCi0bseVfVwFdbM/YD8LyrKWUO9cCgvhYF/9D2+/bgNsCPF8FiUp/KdDb2u5NbIIYwF+Ba5LzAdcAf7Wl/9VK6w0ssaUn5PMo49vAJWGTDegKzCG21vFmoCz5HhJbP+Esa7vMyifJ9zWeL9f7T2xFtonAhcC71rnCIls1bZV+we8p0IOYApOwyZYkzzeAqWGQjdY1vw+2np13gSFhedZSfcJq3nFaQL1PHs9/mDFmA4D1fWgGudKl1zike8LqBp5KrEUdCtkkZj6ZC2wCxhNrkWw3xsRX2raX1yKDtb8OOCQLmd3yGPBroNn6fUiIZDPAOBGZLSLDrbQw3NOjgVrgeYmZxf4mIt1CIpudq4HR1nZBZTPGrAMeAtYAG4g9O7MJz7PmSFiVvpM9LQy+pank8pru/oQi3YExwK3GmB1hkc0Y02SMGUisVX0GcEKa8vImm4hcDmwyxsy2J4dBNouzjTGDgEuBm0XkvDR58ylbGTEz51PGmFOB3cRMJmGQLXbCmG38CuD1TFnzIZs1hnAlMZPMV4BuxO5rqrLyfs2cCKvSL/QC6htFpDeA9b0pg1zp0vs6pLtCRDoQU/gvGWPeCJNscYwx24FPiNlODxKReDwne3ktMlj7DwS2ZiGzG84GrhCRauAVYiaex0IiG8aY9db3JuBNYhVmGO5pDVBjjJlh/f4nsUogDLLFuRSYY4zZaP0utGwXA6uMMbXGmAbgDeDrhORZS0mu9qEgPsRaHSuJ1aDxAYwTAzxfBYk2/T+ROED0oLV9GYkDRDOt9IOJ2UN7Wp9VwMHWvllW3vgA0TCXMgkwCngsKT0MspUDB1nbXYApwOXEWmD2Aaz/Z23fTOIA1mvW9okkDmCtJDZ45cv9B86ndSC34LIRawkeYNv+DBgahntqHTsFON7avtOSKxSyWce/AlwflneB2DjWImLjWkJsIPwnYXjW0sqdawFBfYiNwC8jZiu+PcDzjCZmj2sgVrPeQMzONhFYbn3HHwwBnrRkWgAMtpXzQ6DK+tgfzMHAQuuYP5M0UJZGrnOIdeXmA3Otz7CQyHYy8Lkl20LgDiv9aGJeEFXWg9/JSu9s/a6y9h9tK+t26/xLsXlM+HH/SVT6BZfNkmGe9VkUPzYM99Q6diBQad3Xt4gpxrDI1hXYAhxoSyu4bMBdwBLr2L8TU9wFf9bSfTQMg6IoSgkRVpu+oiiKEgCq9BVFUUoIVfqKoiglhCp9RVGUEkKVvqIoSgmhSl9RFKWEUKWvKIpSQvx/zXBn+2nuk6EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Power.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:43.560275Z",
     "start_time": "2020-05-27T17:05:43.557284Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (86200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:45.150845Z",
     "start_time": "2020-05-27T17:05:43.561360Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "\n",
    "plot_acf(df.Power, lags=100, zero=False)\n",
    "plot_pacf(df.Power, lags=100, zero=False)\n",
    "plt.show()\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.511359Z",
     "start_time": "2020-05-27T17:05:45.151969Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install seglearn > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.515164Z",
     "start_time": "2020-05-27T17:05:46.512736Z"
    }
   },
   "outputs": [],
   "source": [
    "VALID_AND_TEST_SIZE = 0.1\n",
    "TIME_WINDOW=100\n",
    "FORECAST_DISTANCE=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing train-valid-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.524801Z",
     "start_time": "2020-05-27T17:05:46.516853Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_else = train_test_split(df.Power, test_size=VALID_AND_TEST_SIZE*2, shuffle=False)\n",
    "X_valid, X_test= train_test_split(X_else, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling window\n",
    "\n",
    "Using the wonderful [seglearn](https://dmbee.github.io/seglearn/) library to generate rolling windows from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.742494Z",
     "start_time": "2020-05-27T17:05:46.528138Z"
    }
   },
   "outputs": [],
   "source": [
    "from seglearn.transform import FeatureRep, SegmentXYForecast, last\n",
    "\n",
    "segmenter = SegmentXYForecast(width=TIME_WINDOW, step=1, y_func=last, forecast=FORECAST_DISTANCE)\n",
    "\n",
    "X_train_rolled, y_train_rolled,_=segmenter.fit_transform([X_train.values.flatten()],[X_train.values.flatten()])\n",
    "X_valid_rolled, y_valid_rolled,_=segmenter.fit_transform([X_valid.values.flatten()],[X_valid.values.flatten()])\n",
    "X_test_rolled, y_test_rolled,_=segmenter.fit_transform([X_test.values.flatten()],[X_test.values.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.753547Z",
     "start_time": "2020-05-27T17:05:46.748858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68860, 100), (68860,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rolled.shape, y_train_rolled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.759958Z",
     "start_time": "2020-05-27T17:05:46.755409Z"
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(X_train[:TIME_WINDOW].values,X_train_rolled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.772553Z",
     "start_time": "2020-05-27T17:05:46.766777Z"
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(X_train[TIME_WINDOW-1+FORECAST_DISTANCE],y_train_rolled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:05:46.786956Z",
     "start_time": "2020-05-27T17:05:46.777688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Warning, Keras needs a 1D matrix, not a vector, so one must do:\n",
    "\n",
    "X_train_rolled = X_train_rolled[:,:, np.newaxis]\n",
    "X_valid_rolled = X_valid_rolled[:,:, np.newaxis]\n",
    "X_test_rolled = X_test_rolled[:,:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:27:37.313391Z",
     "start_time": "2020-05-27T17:27:37.310265Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#---- Hyperparams and settings ----\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 0.1\n",
    "LSTM_CELL_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:20.013112Z",
     "start_time": "2020-05-27T17:27:39.376598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68860 samples, validate on 8520 samples\n",
      "Epoch 1/30\n",
      "68860/68860 [==============================] - 48s 691us/sample - loss: 5884.7970 - val_loss: 6182.0641\n",
      "Epoch 2/30\n",
      "68860/68860 [==============================] - 39s 570us/sample - loss: 4643.1830 - val_loss: 5918.2724\n",
      "Epoch 3/30\n",
      "68860/68860 [==============================] - 39s 562us/sample - loss: 4318.2682 - val_loss: 5540.1538\n",
      "Epoch 4/30\n",
      "68860/68860 [==============================] - 39s 570us/sample - loss: 3836.3652 - val_loss: 5271.9356\n",
      "Epoch 5/30\n",
      "68860/68860 [==============================] - 39s 568us/sample - loss: 3569.0519 - val_loss: 5015.1448\n",
      "Epoch 6/30\n",
      "68860/68860 [==============================] - 39s 564us/sample - loss: 3232.4642 - val_loss: 4886.2774\n",
      "Epoch 7/30\n",
      "68860/68860 [==============================] - 39s 563us/sample - loss: 3105.7792 - val_loss: 4721.2178\n",
      "Epoch 8/30\n",
      "68860/68860 [==============================] - 39s 571us/sample - loss: 3018.6925 - val_loss: 4697.4197\n",
      "Epoch 9/30\n",
      "68860/68860 [==============================] - 39s 564us/sample - loss: 3026.8636 - val_loss: 4450.6331\n",
      "Epoch 10/30\n",
      "68860/68860 [==============================] - 39s 562us/sample - loss: 2890.5721 - val_loss: 4336.2533\n",
      "Epoch 11/30\n",
      "68860/68860 [==============================] - 39s 561us/sample - loss: 2829.0153 - val_loss: 4285.8083\n",
      "Epoch 12/30\n",
      "68860/68860 [==============================] - 39s 565us/sample - loss: 2830.5372 - val_loss: 4255.6133\n",
      "Epoch 13/30\n",
      "68860/68860 [==============================] - 39s 567us/sample - loss: 2798.0879 - val_loss: 4152.3123\n",
      "Epoch 14/30\n",
      "68860/68860 [==============================] - 39s 564us/sample - loss: 2769.2539 - val_loss: 4090.3308\n",
      "Epoch 15/30\n",
      "68860/68860 [==============================] - 38s 558us/sample - loss: 2763.0400 - val_loss: 4087.6195\n",
      "Epoch 16/30\n",
      "68860/68860 [==============================] - 39s 567us/sample - loss: 2683.6863 - val_loss: 4015.5208\n",
      "Epoch 17/30\n",
      "68860/68860 [==============================] - 39s 572us/sample - loss: 2792.8153 - val_loss: 3970.1660\n",
      "Epoch 18/30\n",
      "68860/68860 [==============================] - 39s 564us/sample - loss: 2677.5659 - val_loss: 3851.6496\n",
      "Epoch 19/30\n",
      "68860/68860 [==============================] - 40s 574us/sample - loss: 2584.1078 - val_loss: 3819.8127\n",
      "Epoch 20/30\n",
      "68860/68860 [==============================] - 39s 573us/sample - loss: 2596.3597 - val_loss: 3696.0231\n",
      "Epoch 21/30\n",
      "68860/68860 [==============================] - 40s 578us/sample - loss: 2549.9657 - val_loss: 3675.1453\n",
      "Epoch 22/30\n",
      "68860/68860 [==============================] - 39s 573us/sample - loss: 2689.3426 - val_loss: 3635.9200\n",
      "Epoch 23/30\n",
      "68860/68860 [==============================] - 40s 574us/sample - loss: 2607.7090 - val_loss: 3570.8580\n",
      "Epoch 24/30\n",
      "68860/68860 [==============================] - 40s 578us/sample - loss: 2523.6084 - val_loss: 3537.7293\n",
      "Epoch 25/30\n",
      "68860/68860 [==============================] - 39s 565us/sample - loss: 2522.6261 - val_loss: 3461.3199\n",
      "Epoch 26/30\n",
      "68860/68860 [==============================] - 39s 560us/sample - loss: 2573.4749 - val_loss: 3513.3092\n",
      "Epoch 27/30\n",
      "68860/68860 [==============================] - 39s 562us/sample - loss: 2503.8907 - val_loss: 3366.3609\n",
      "Epoch 28/30\n",
      "68860/68860 [==============================] - 39s 567us/sample - loss: 2403.2628 - val_loss: 3317.9476\n",
      "Epoch 29/30\n",
      "68860/68860 [==============================] - 39s 565us/sample - loss: 2301.4730 - val_loss: 3203.0238\n",
      "Epoch 30/30\n",
      "68860/68860 [==============================] - 39s 562us/sample - loss: 2260.4253 - val_loss: 3196.2645\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from tensorflow.keras import backend as be\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "column_count=1\n",
    "\n",
    "be.clear_session()\n",
    "\n",
    "input_layer = Input(shape=(TIME_WINDOW,column_count))\n",
    "\n",
    "lstm_layer = LSTM(LSTM_CELL_SIZE)(input_layer)\n",
    "dense_layer = Dense(1)(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=dense_layer)\n",
    "\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "history = model.fit(x=X_train_rolled,y=y_train_rolled, batch_size=BATCH_SIZE, validation_data=(X_valid_rolled,y_valid_rolled), epochs=EPOCHS, verbose=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:20.785872Z",
     "start_time": "2020-05-27T17:47:20.418603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:25.916627Z",
     "start_time": "2020-05-27T17:47:21.221977Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_rolled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T17:47:26.638783Z",
     "start_time": "2020-05-27T17:47:26.262070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.plot(list(X_test[100:]), label=\"Test\")\n",
    "plt.plot(list(predictions), label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is this model to be improved?\n",
    "\n",
    "In many ways this model is too basic, needs heavy improvement.\n",
    "\n",
    "1. Let it run further\n",
    "2. Does not use regularization at all, Dropout should be added. The question is where to put it in RNNs, for this see [here](http://dx.doi.org/10.1109/ICDAR.2015.7333848) and [here](https://arxiv.org/abs/1512.05287)\n",
    "3. Should use some data normalization, details can be found [here](https://machinelearningmastery.com/normalize-standardize-time-series-data-python/)\n",
    "4. Usage of squared loss is also questionable\n",
    "5. It does not solve the transfer of inner **states between minibatches** and on epoch begin (called \"statefulness\" and \"warmup\" respectively). Tips for **Warmup** [here](https://arxiv.org/pdf/1710.03222.pdf), for statefullness [here](https://stackoverflow.com/questions/38241410/tensorflow-remember-lstm-state-for-next-batch-stateful-lstm?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)\n",
    "6. Hyperparameters could be optimized manually or with search techniques\n",
    "7. Multiple LSTM layers can be stacked upon each-other\n",
    "\n",
    "As said, a really basic model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The case for confidence intervals - Probabilistic extension\n",
    "\n",
    "Though RNNs, especially LSTM-s have remarkable properties and capacity for prediction, in practice, their application in real life times series data has been limited mainly because in their default form they are __incapable of producing probabilistic estimates__ such as confidence intervals around the prediction.\n",
    "\n",
    "This limitation of a \"point estimate\" is all the more painful, since in many business relevant predictions - say in sales / inventory related forecsts - the main point of the forecast is not just pure accuracy, but the incorporation of a kind of \"worst case\" scenario, since one has to serve customers even in case of slight prediction discrepancies, thus has to keep a bit of larger stock then the actual prediction would imply. This \"bit\", that is eg. the surplus inventory is the real question.\n",
    "\n",
    "We would be well served, if we would get an \"uncertainity range\" together with our estimate, and in practice we would act upont the appropriate high/low point of that range, or we would just weight predictions accordingly. \n",
    "\n",
    "\n",
    "## The \"quick fix\" way: Monte Carlo dropout\n",
    "\n",
    "The easiest fix for producing some distribution of predictions is to produce a distribution of models. If these are somehow independent, their ensambled output, and especially the __shape of the distribution of their outputs__ can be very telling with respect to prediction uncertainity. \n",
    "\n",
    "The paper describing [Monte Carlo dropout](https://arxiv.org/abs/1506.02142) (for a short explanation see [here](https://towardsdatascience.com/monte-carlo-dropout-7fd52f8b6571)) argues that this is akin to Bayesan inference.\n",
    "\n",
    "The trick is as follows: at inference time override the default behavior of a model having dropout in it (which would be switched off when the training is finished), with dropout turned on, do repeated samples of forward passes, and then collect all the pointwise estimates, that form a distribution. \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1GJ5hspy0c-HR7G9TGC3vKM-N7utysua6\" width=55%>\n",
    "\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1oFV7XGXmfr1kciWnaR3Y5pVjjeMt2r8o\" width=45%>\n",
    "\n",
    "This can basically lead to a \"poor man's probabilistic extension\" of an LSTM model.\n",
    "\n",
    "## Detour: Dropout in LSTM-s\n",
    "\n",
    "As mentioned before in the material, the application of Dropout to LSTM(like) architectures is not at all obvious. As summarized in the excellent overview [here](https://adriangcoder.medium.com/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b) there exeist several alternative mechanisms to apply dropout (or one of it's \"brethren\" like [DropConnect](https://proceedings.mlr.press/v28/wan13.html) or [ZoneOut](https://arxiv.org/abs/1606.01305)) exist, and for a while this became a hotly debated area of research. \n",
    "\n",
    "Thus said, in practice, Tensorflow Keras's default implementation is that of update gate dropout and/or \"recurrent dropout\" as seen [here](https://arxiv.org/abs/1603.05118v2).\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1GvvZJiriLkwGqSDQNgTgpcI3njeYU9jP\" width=65%>\n",
    "\n",
    "\n",
    "\n",
    "## The dedicated way: DeepAR \n",
    "\n",
    "In 2017 Amazon - motivated by it's extensive challenges in predicting customer orders - set out to refine the default LSTM implementation and to add explicit probabilistic capabilities. The resulting [DeepAR](https://arxiv.org/abs/1704.04110) model can be considered as a general extension to RNN-s.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1DKvFQjSKyVVc0yAq9wW4ZGBnyXNVMbnH\" width=75%>\n",
    "\n",
    "In this model the RNN layers are basically outputting parameters for a previously assumed noise distribution, so the final predictions are generated by the sampling of this said distribution. In case of learning, this output is being used to do the parameter updates, in case of prediction, multiple \"monte carlo\" samples are drawn from the distribution to generate the confidence estimates.\n",
    "\n",
    "\n",
    "For a nice short intro see [here](https://www.youtube.com/watch?v=zQvHESgqFcU).\n",
    "\n",
    "As a result, one can not just have pretty accurate point estimations, but reliable confidence bounds for a time series.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1rTzSHE5PnwToJfyovVaSWGpp2SUcbQx0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"necessary\"></a>\n",
    "\n",
    "# Are LSTM-s really necessary?\n",
    "\n",
    "LSTMs, when combined with dropout and other techniques became **hugely successful** and were considered the workhorse of NLP and time series applications, as well as sequence to sequence problems, moreover they serve as basis for all memory network architectures. They were and are still dominant in these fields.\n",
    "\n",
    "None the less as of 2017-8, multiple findings emerged that question the necessity for LSTMs in many fields. The leading field in this regard was neural machine translation, where Facebook Research developed it's [ConvNet based  machine translation](https://code.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation/), as well as Google publishing the [transformer architecture](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html). Both approaches were motivated by the fact that LSTM computation is not easily parallelized, but ConvNets and transformers are, so training can be scaled up rapidly.\n",
    "\n",
    "Based on these networks multiple analyses tried to justify the usage of LSTMs and found, that though they have in theory infinite memory ability, in practice, a limited memory is good enough, which can be modeled by ConvNets, especially 1D and dilated convolutions.\n",
    "\n",
    "For more information see [here](https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0) [here](http://www.offconvex.org/2018/07/27/approximating-recurrent/) [here](http://blog.aylien.com/acl-2018-highlights-understanding-representations-and-evaluation-in-more-challenging-settings/) [here](https://arxiv.org/abs/1803.01271)\n",
    "\n",
    "(Interesting snippets or remarks from the above sources:\n",
    "“LSTMs work in practice, but can they work in theory?”\n",
    "\" “According to Chomsky, sequential recency is not the right bias for learning human language. RNNs thus don’t seem to have the right bias for modeling language, which in practice can lead to statistical inefficiency and poor generalization behaviour.\")\n",
    "\n",
    "\n",
    "Alternative approaches as [\"recursive neural networks\"](https://en.wikipedia.org/wiki/Recursive_neural_network) and [\"recurrent neural network grammars\"](https://arxiv.org/abs/1602.07776) also exist, but not that widespread.\n",
    "\n",
    "\n",
    "## Convolutions for time series\n",
    "\n",
    "We use convolution operators, but only in one dimension over the data.\n",
    "\n",
    "<a href=\"http://mblogthumb2.phinf.naver.net/MjAxNjEyMTBfMjMx/MDAxNDgxMjk1ODk2NDAz.kn9JN93v9X2Xn9vJloqupV5c5GB09YNYwPrvDB8yKU8g.Hh1wT30ySu0JFWNqj2qoSTiX-pRnrjH2VWhMI2EAo30g.PNG.atelierjpro/%EC%8A%AC%EB%9D%BC%EC%9D%B4%EB%93%9C2.PNG?type=w2\"><img src=\"https://drive.google.com/uc?export=view&id=1VlPqHI2s8NyI2kaaHIrjGwtd4FClAbVZ\" width=600 heigth=600></a>\n",
    "\n",
    "Look, look, we have reinvented sliding windows! :-(\n",
    "\n",
    "<a href=\"https://qph.fs.quoracdn.net/main-qimg-523434af0d21bb0b59454aa9563cc90b-c\"><img src=\"https://drive.google.com/uc?export=view&id=1uuL9sC25DnbdL-bD-DmqNp1tFX6-xVaX\" width=600 heigth=600></a>\n",
    "\n",
    "Though if we [calculate the receptive fileds](https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807) of these models, with enough depth they can be formidable!\n",
    "\n",
    "### Slight problems - leaking the future\n",
    "\n",
    "If we look closely at the standard version of a convolutional filter, and you interpret the horizontal axis az time, then we can see, that for a given point in time (horizontal position) some values \"from the right\" of it are also utilized, since it is typically thought of as being \"in the middle of the filter\". \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1btnmA_mRKGkNofrN_QNOToVBQqXBtb7t\" width=35%>\n",
    "\n",
    "This has some pretty obvious drawbacks especially in the \"one step ahead\" prediction, because the filter sees the step it has to predict. That is pretty bad.\n",
    "\n",
    "What can we do?\n",
    "\n",
    "\"Causal convolutions\" to the rescue!\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1jaJ_sXnTb51taJVQc3O2i-9uD-6GnMAk\" width=35%>\n",
    "\n",
    "They are basically modifications of standard filters to be \"right aligned\", that is, they only process past information, so the element they contribute their prediction to is always the \"rightmost\" one, potentially even in the future.\n",
    "\n",
    "The whole setup can visually be summarized as follows:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1G-I0Ckw5F5PCgm_Mct__ZNFs-mYx-CkM\" width=45%> \n",
    "\n",
    "[Source](https://www.youtube.com/watch?v=GiD87DeadYY)\n",
    "\n",
    "### Dilated convolutions\n",
    "\n",
    "The problem with the above \"pure\" causal convolutions is: it is pretty difficult to generate long distance relationships with it, since one either defines really big filters (in the order of tens of timesteps) or one tries to simulate the growth of the \"receptive field\" of units higher up in the hierarchy by stacking layers. Both of these approaches is computationally intensive.\n",
    "\n",
    "What can we do?\n",
    "\n",
    "Dilated convolutions are used to __radically increase the total receptive field of a network__.\n",
    "\n",
    "<a href=\"http://sergeiturukin.com/assets/2017-02-23-155956_803x294_scrot.png\"><img src=\"https://drive.google.com/uc?export=view&id=1x12ed5qvn3Ls-glPeYBArzC6w3Wb2Br9\" width=600 heigth=600></a>\n",
    "\n",
    "\n",
    "<a href=\"https://mlblr.com/images/dilated.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1meYEWWcBbrvJy21PBTSUSUd0oTjAveJh\" width=400 heigth=400></a>\n",
    "\n",
    "In this approach, we basically use an __internal \"skip\"__, or a funny style of __masking__ to only add __every _n_ th unit's output__ as an input to a conv filter in a higher layer.\n",
    "\n",
    "Original paper [here](https://arxiv.org/abs/1511.07122)\n",
    "\n",
    "[Wavenet](http://sergeiturukin.com/2017/03/02/wavenet.html) and other successful models (especially in voice recognition) use this approach effectively.\n",
    "\n",
    "### Convolutional filters and wavelets\n",
    "\n",
    "It is also interesting to note, that convolutions over a timeseries can be understood as generalizations of \"wavelet / shapelet\" approaches, with the added benefit, that here the definition of \"mother wavelet\" is not that problematic.\n",
    "\n",
    "<a href=\"https://www.researchgate.net/profile/Zoltan_German-Sallo/publication/266056525/figure/fig1/AS:295770143117318@1447528505764/The-Continuous-Wavelet-Transform-as-a-convolution-between-data-signal-and-scaled-and.png\"><img src=\"https://drive.google.com/uc?export=view&id=1pxADzQu_mXziCGTy4BIyHGVSntyLkuAV\" width=45%></a>\n",
    "\n",
    "\n",
    "# Neural models for time series similarity\n",
    "\n",
    "Some really successful neural models eg. for time series similarity (like [this](https://arxiv.org/pdf/1812.08306.pdf)) also capitalize on the flexibility of neural models for pattern recognition in timeseries, thus forming effective competition to the tried and true Fourier spectral methods and [Dynamic Time Warping](https://en.wikipedia.org/wiki/Dynamic_time_warping).\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1WrrsD273HFeWQkKnTDGnv-PxP4cWU6Ph\"><img src=\"https://drive.google.com/uc?export=view&id=1945TUDRilACpGXhgGWHXO4kh9JWghL7k\" widht=75%></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
